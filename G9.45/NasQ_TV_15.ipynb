{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliprg0/Google_Colab/blob/main/NasQ_TV_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import multiprocessing\n",
        "import time\n",
        "import glob"
      ],
      "metadata": {
        "id": "BqIra2YIBJsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nasq_syms():\n",
        "  with open(\"watchlist_NASDAQ.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  line = lines[0].split(\",\")\n",
        "  symbols = []\n",
        "  for l in line:\n",
        "    x = l.split(\":\")\n",
        "    symbols.append(x[1])\n",
        "  return symbols\n",
        "def get_binance_syms():\n",
        "  with open(\"binance_tv.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  nlines = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    nlines.append(line.split(\":\")[1])\n",
        "  \n",
        "  return nlines\n",
        "def download_data_p(tv,sym):\n",
        "    data =tv.get_hist(sym,exchange=\"binance\", interval=Interval.in_weekly, n_bars=50000)\n",
        "    try:\n",
        "        data.to_csv(\"data/{}.csv\".format(sym))\n",
        "    except:\n",
        "      pass  \n",
        "def download_data(symbols):\n",
        "  work_with_dir()\n",
        "  tv = TvDatafeed()\n",
        "  for sym in symbols:\n",
        "    print(symbols.index(sym)+1, \"/\", len(symbols))\n",
        "    p = multiprocessing.Process(target=download_data_p, name=\"dd\", args=(tv,sym,))\n",
        "    p.start()\n",
        "    time.sleep(2)\n",
        "    p.terminate()\n",
        "    p.join()"
      ],
      "metadata": {
        "id": "Cku-whunBURi"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_data(get_binance_syms())\n",
        "#download_data(get_nasq_syms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZHam_kdREbf",
        "outputId": "027f2f9d-78e7-45cb-f396-51b076a0ceab"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Folder Removed\n",
            "1 / 574\n",
            "2 / 574\n",
            "3 / 574\n",
            "4 / 574\n",
            "5 / 574\n",
            "6 / 574\n",
            "7 / 574\n",
            "8 / 574\n",
            "9 / 574\n",
            "10 / 574\n",
            "11 / 574\n",
            "12 / 574\n",
            "13 / 574\n",
            "14 / 574\n",
            "15 / 574\n",
            "16 / 574\n",
            "17 / 574\n",
            "18 / 574\n",
            "19 / 574\n",
            "20 / 574\n",
            "21 / 574\n",
            "22 / 574\n",
            "23 / 574\n",
            "24 / 574\n",
            "25 / 574\n",
            "26 / 574\n",
            "27 / 574\n",
            "28 / 574\n",
            "29 / 574\n",
            "30 / 574\n",
            "31 / 574\n",
            "32 / 574\n",
            "33 / 574\n",
            "34 / 574\n",
            "35 / 574\n",
            "36 / 574\n",
            "37 / 574\n",
            "38 / 574\n",
            "39 / 574\n",
            "40 / 574\n",
            "41 / 574\n",
            "42 / 574\n",
            "43 / 574\n",
            "44 / 574\n",
            "45 / 574\n",
            "46 / 574\n",
            "47 / 574\n",
            "48 / 574\n",
            "49 / 574\n",
            "50 / 574\n",
            "51 / 574\n",
            "52 / 574\n",
            "53 / 574\n",
            "54 / 574\n",
            "55 / 574\n",
            "56 / 574\n",
            "57 / 574\n",
            "58 / 574\n",
            "59 / 574\n",
            "60 / 574\n",
            "61 / 574\n",
            "62 / 574\n",
            "63 / 574\n",
            "64 / 574\n",
            "65 / 574\n",
            "66 / 574\n",
            "67 / 574\n",
            "68 / 574\n",
            "69 / 574\n",
            "70 / 574\n",
            "71 / 574\n",
            "72 / 574\n",
            "73 / 574\n",
            "74 / 574\n",
            "75 / 574\n",
            "76 / 574\n",
            "77 / 574\n",
            "78 / 574\n",
            "79 / 574\n",
            "80 / 574\n",
            "81 / 574\n",
            "82 / 574\n",
            "83 / 574\n",
            "84 / 574\n",
            "85 / 574\n",
            "86 / 574\n",
            "87 / 574\n",
            "88 / 574\n",
            "89 / 574\n",
            "90 / 574\n",
            "91 / 574\n",
            "92 / 574\n",
            "93 / 574\n",
            "94 / 574\n",
            "95 / 574\n",
            "96 / 574\n",
            "97 / 574\n",
            "98 / 574\n",
            "99 / 574\n",
            "100 / 574\n",
            "101 / 574\n",
            "102 / 574\n",
            "103 / 574\n",
            "104 / 574\n",
            "105 / 574\n",
            "106 / 574\n",
            "107 / 574\n",
            "108 / 574\n",
            "109 / 574\n",
            "110 / 574\n",
            "111 / 574\n",
            "112 / 574\n",
            "113 / 574\n",
            "114 / 574\n",
            "115 / 574\n",
            "116 / 574\n",
            "117 / 574\n",
            "118 / 574\n",
            "119 / 574\n",
            "120 / 574\n",
            "121 / 574\n",
            "122 / 574\n",
            "123 / 574\n",
            "124 / 574\n",
            "125 / 574\n",
            "126 / 574\n",
            "127 / 574\n",
            "128 / 574\n",
            "129 / 574\n",
            "130 / 574\n",
            "131 / 574\n",
            "132 / 574\n",
            "133 / 574\n",
            "134 / 574\n",
            "135 / 574\n",
            "136 / 574\n",
            "137 / 574\n",
            "138 / 574\n",
            "139 / 574\n",
            "140 / 574\n",
            "141 / 574\n",
            "142 / 574\n",
            "143 / 574\n",
            "144 / 574\n",
            "145 / 574\n",
            "146 / 574\n",
            "147 / 574\n",
            "148 / 574\n",
            "149 / 574\n",
            "150 / 574\n",
            "151 / 574\n",
            "152 / 574\n",
            "153 / 574\n",
            "154 / 574\n",
            "155 / 574\n",
            "156 / 574\n",
            "157 / 574\n",
            "158 / 574\n",
            "159 / 574\n",
            "160 / 574\n",
            "161 / 574\n",
            "162 / 574\n",
            "163 / 574\n",
            "164 / 574\n",
            "165 / 574\n",
            "166 / 574\n",
            "167 / 574\n",
            "168 / 574\n",
            "169 / 574\n",
            "170 / 574\n",
            "171 / 574\n",
            "172 / 574\n",
            "173 / 574\n",
            "174 / 574\n",
            "175 / 574\n",
            "176 / 574\n",
            "177 / 574\n",
            "178 / 574\n",
            "179 / 574\n",
            "180 / 574\n",
            "181 / 574\n",
            "182 / 574\n",
            "183 / 574\n",
            "184 / 574\n",
            "185 / 574\n",
            "186 / 574\n",
            "187 / 574\n",
            "188 / 574\n",
            "189 / 574\n",
            "190 / 574\n",
            "191 / 574\n",
            "192 / 574\n",
            "193 / 574\n",
            "194 / 574\n",
            "195 / 574\n",
            "196 / 574\n",
            "197 / 574\n",
            "198 / 574\n",
            "199 / 574\n",
            "200 / 574\n",
            "201 / 574\n",
            "202 / 574\n",
            "203 / 574\n",
            "204 / 574\n",
            "205 / 574\n",
            "206 / 574\n",
            "207 / 574\n",
            "208 / 574\n",
            "209 / 574\n",
            "210 / 574\n",
            "211 / 574\n",
            "212 / 574\n",
            "213 / 574\n",
            "214 / 574\n",
            "215 / 574\n",
            "216 / 574\n",
            "217 / 574\n",
            "218 / 574\n",
            "219 / 574\n",
            "220 / 574\n",
            "221 / 574\n",
            "222 / 574\n",
            "223 / 574\n",
            "224 / 574\n",
            "225 / 574\n",
            "226 / 574\n",
            "227 / 574\n",
            "228 / 574\n",
            "229 / 574\n",
            "230 / 574\n",
            "231 / 574\n",
            "232 / 574\n",
            "233 / 574\n",
            "234 / 574\n",
            "235 / 574\n",
            "236 / 574\n",
            "237 / 574\n",
            "238 / 574\n",
            "239 / 574\n",
            "240 / 574\n",
            "241 / 574\n",
            "242 / 574\n",
            "243 / 574\n",
            "244 / 574\n",
            "245 / 574\n",
            "246 / 574\n",
            "247 / 574\n",
            "248 / 574\n",
            "249 / 574\n",
            "250 / 574\n",
            "251 / 574\n",
            "252 / 574\n",
            "253 / 574\n",
            "254 / 574\n",
            "255 / 574\n",
            "256 / 574\n",
            "257 / 574\n",
            "258 / 574\n",
            "259 / 574\n",
            "260 / 574\n",
            "261 / 574\n",
            "262 / 574\n",
            "263 / 574\n",
            "264 / 574\n",
            "265 / 574\n",
            "266 / 574\n",
            "267 / 574\n",
            "268 / 574\n",
            "269 / 574\n",
            "270 / 574\n",
            "271 / 574\n",
            "272 / 574\n",
            "273 / 574\n",
            "274 / 574\n",
            "275 / 574\n",
            "276 / 574\n",
            "277 / 574\n",
            "278 / 574\n",
            "279 / 574\n",
            "280 / 574\n",
            "281 / 574\n",
            "282 / 574\n",
            "283 / 574\n",
            "284 / 574\n",
            "285 / 574\n",
            "286 / 574\n",
            "287 / 574\n",
            "288 / 574\n",
            "289 / 574\n",
            "290 / 574\n",
            "291 / 574\n",
            "292 / 574\n",
            "293 / 574\n",
            "294 / 574\n",
            "295 / 574\n",
            "296 / 574\n",
            "297 / 574\n",
            "298 / 574\n",
            "299 / 574\n",
            "300 / 574\n",
            "301 / 574\n",
            "302 / 574\n",
            "303 / 574\n",
            "304 / 574\n",
            "305 / 574\n",
            "306 / 574\n",
            "307 / 574\n",
            "308 / 574\n",
            "309 / 574\n",
            "310 / 574\n",
            "311 / 574\n",
            "312 / 574\n",
            "313 / 574\n",
            "314 / 574\n",
            "315 / 574\n",
            "316 / 574\n",
            "317 / 574\n",
            "318 / 574\n",
            "319 / 574\n",
            "320 / 574\n",
            "321 / 574\n",
            "322 / 574\n",
            "323 / 574\n",
            "324 / 574\n",
            "325 / 574\n",
            "326 / 574\n",
            "327 / 574\n",
            "328 / 574\n",
            "329 / 574\n",
            "330 / 574\n",
            "331 / 574\n",
            "332 / 574\n",
            "333 / 574\n",
            "334 / 574\n",
            "335 / 574\n",
            "336 / 574\n",
            "337 / 574\n",
            "338 / 574\n",
            "339 / 574\n",
            "340 / 574\n",
            "341 / 574\n",
            "342 / 574\n",
            "343 / 574\n",
            "344 / 574\n",
            "345 / 574\n",
            "346 / 574\n",
            "347 / 574\n",
            "348 / 574\n",
            "349 / 574\n",
            "350 / 574\n",
            "351 / 574\n",
            "352 / 574\n",
            "353 / 574\n",
            "354 / 574\n",
            "355 / 574\n",
            "356 / 574\n",
            "357 / 574\n",
            "358 / 574\n",
            "359 / 574\n",
            "360 / 574\n",
            "361 / 574\n",
            "362 / 574\n",
            "363 / 574\n",
            "364 / 574\n",
            "365 / 574\n",
            "366 / 574\n",
            "367 / 574\n",
            "368 / 574\n",
            "369 / 574\n",
            "370 / 574\n",
            "371 / 574\n",
            "372 / 574\n",
            "373 / 574\n",
            "374 / 574\n",
            "375 / 574\n",
            "376 / 574\n",
            "377 / 574\n",
            "378 / 574\n",
            "379 / 574\n",
            "380 / 574\n",
            "381 / 574\n",
            "382 / 574\n",
            "383 / 574\n",
            "384 / 574\n",
            "385 / 574\n",
            "386 / 574\n",
            "387 / 574\n",
            "388 / 574\n",
            "389 / 574\n",
            "390 / 574\n",
            "391 / 574\n",
            "392 / 574\n",
            "393 / 574\n",
            "394 / 574\n",
            "395 / 574\n",
            "396 / 574\n",
            "397 / 574\n",
            "398 / 574\n",
            "399 / 574\n",
            "400 / 574\n",
            "401 / 574\n",
            "402 / 574\n",
            "403 / 574\n",
            "404 / 574\n",
            "405 / 574\n",
            "406 / 574\n",
            "407 / 574\n",
            "408 / 574\n",
            "409 / 574\n",
            "410 / 574\n",
            "411 / 574\n",
            "412 / 574\n",
            "413 / 574\n",
            "414 / 574\n",
            "415 / 574\n",
            "416 / 574\n",
            "417 / 574\n",
            "418 / 574\n",
            "419 / 574\n",
            "420 / 574\n",
            "421 / 574\n",
            "422 / 574\n",
            "423 / 574\n",
            "424 / 574\n",
            "425 / 574\n",
            "426 / 574\n",
            "427 / 574\n",
            "428 / 574\n",
            "429 / 574\n",
            "430 / 574\n",
            "431 / 574\n",
            "432 / 574\n",
            "433 / 574\n",
            "434 / 574\n",
            "435 / 574\n",
            "436 / 574\n",
            "437 / 574\n",
            "438 / 574\n",
            "439 / 574\n",
            "440 / 574\n",
            "441 / 574\n",
            "442 / 574\n",
            "443 / 574\n",
            "444 / 574\n",
            "445 / 574\n",
            "446 / 574\n",
            "447 / 574\n",
            "448 / 574\n",
            "449 / 574\n",
            "450 / 574\n",
            "451 / 574\n",
            "452 / 574\n",
            "453 / 574\n",
            "454 / 574\n",
            "455 / 574\n",
            "456 / 574\n",
            "457 / 574\n",
            "458 / 574\n",
            "459 / 574\n",
            "460 / 574\n",
            "461 / 574\n",
            "462 / 574\n",
            "463 / 574\n",
            "464 / 574\n",
            "465 / 574\n",
            "466 / 574\n",
            "467 / 574\n",
            "468 / 574\n",
            "469 / 574\n",
            "470 / 574\n",
            "471 / 574\n",
            "472 / 574\n",
            "473 / 574\n",
            "474 / 574\n",
            "475 / 574\n",
            "476 / 574\n",
            "477 / 574\n",
            "478 / 574\n",
            "479 / 574\n",
            "480 / 574\n",
            "481 / 574\n",
            "482 / 574\n",
            "483 / 574\n",
            "484 / 574\n",
            "485 / 574\n",
            "486 / 574\n",
            "487 / 574\n",
            "488 / 574\n",
            "489 / 574\n",
            "490 / 574\n",
            "491 / 574\n",
            "492 / 574\n",
            "493 / 574\n",
            "494 / 574\n",
            "495 / 574\n",
            "496 / 574\n",
            "497 / 574\n",
            "498 / 574\n",
            "499 / 574\n",
            "500 / 574\n",
            "501 / 574\n",
            "502 / 574\n",
            "503 / 574\n",
            "504 / 574\n",
            "505 / 574\n",
            "506 / 574\n",
            "507 / 574\n",
            "508 / 574\n",
            "509 / 574\n",
            "510 / 574\n",
            "511 / 574\n",
            "512 / 574\n",
            "513 / 574\n",
            "514 / 574\n",
            "515 / 574\n",
            "516 / 574\n",
            "517 / 574\n",
            "518 / 574\n",
            "519 / 574\n",
            "520 / 574\n",
            "521 / 574\n",
            "522 / 574\n",
            "523 / 574\n",
            "524 / 574\n",
            "525 / 574\n",
            "526 / 574\n",
            "527 / 574\n",
            "528 / 574\n",
            "529 / 574\n",
            "530 / 574\n",
            "531 / 574\n",
            "532 / 574\n",
            "533 / 574\n",
            "534 / 574\n",
            "535 / 574\n",
            "536 / 574\n",
            "537 / 574\n",
            "538 / 574\n",
            "539 / 574\n",
            "540 / 574\n",
            "541 / 574\n",
            "542 / 574\n",
            "543 / 574\n",
            "544 / 574\n",
            "545 / 574\n",
            "546 / 574\n",
            "547 / 574\n",
            "548 / 574\n",
            "549 / 574\n",
            "550 / 574\n",
            "551 / 574\n",
            "552 / 574\n",
            "553 / 574\n",
            "554 / 574\n",
            "555 / 574\n",
            "556 / 574\n",
            "557 / 574\n",
            "558 / 574\n",
            "559 / 574\n",
            "560 / 574\n",
            "561 / 574\n",
            "562 / 574\n",
            "563 / 574\n",
            "564 / 574\n",
            "565 / 574\n",
            "566 / 574\n",
            "567 / 574\n",
            "568 / 574\n",
            "569 / 574\n",
            "570 / 574\n",
            "571 / 574\n",
            "572 / 574\n",
            "573 / 574\n",
            "574 / 574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clmns = [\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if \"symbol\" in data.columns:\n",
        "        data.drop(\"symbol\", axis=1, inplace=True)  \n",
        "    if \"Adj Close\" in data.columns:\n",
        "        data.drop(\"Adj Close\", axis=1, inplace=True)\n",
        "    if \"datetime\" in data.columns:\n",
        "        data.drop(\"datetime\",axis=1,inplace=True)\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)  \n",
        "\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        " \n",
        "        s1 = np.delete(s1, 1)\n",
        "        s1 = np.delete(s1, 1)\n",
        "        s2 = np.delete(s2, 1)\n",
        "        s2 = np.delete(s2, 1)\n",
        "        s3 = np.delete(s3, 1)\n",
        "        s3 = np.delete(s3, 1)\n",
        "        s4 = np.delete(s4, 1)\n",
        "        s4 = np.delete(s4, 1)\n",
        "        s5 = np.delete(s5, 1)\n",
        "        s5 = np.delete(s5, 1)\n",
        "        s6 = np.delete(s6, 1)\n",
        "        s6 = np.delete(s6, 1)\n",
        "        s7 = np.delete(s7, 1)\n",
        "        s7 = np.delete(s7, 1)\n",
        "        s8 = np.delete(s8, 1)\n",
        "        s8 = np.delete(s8, 1)\n",
        "        s9 = np.delete(s9, 1)\n",
        "        s9 = np.delete(s9, 1)\n",
        "        s10 = np.delete(s10, 1)\n",
        "        s10 = np.delete(s10, 1)\n",
        "        s11 = np.delete(s11, 1)\n",
        "        s11 = np.delete(s11, 1)\n",
        "        s12 = np.delete(s12, 1)\n",
        "        s12 = np.delete(s12, 1)     \n",
        "\n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i][0]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ],
      "metadata": {
        "id": "Yc7-yg1RMYBQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        unattached_dfs.append(process(pd.read_csv(address)))\n",
        "     data = np.array(unattached_dfs[0])\n",
        "     for i in unattached_dfs[1:]:\n",
        "           data = np.append(data, np.array(i), axis=0)\n",
        "\n",
        "     unattached_dfs = []\n",
        "     \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        " \n",
        "\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  print(\"Done\")\n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")     "
      ],
      "metadata": {
        "id": "RwcfzqyPMq27"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ],
      "metadata": {
        "id": "nacRKx3ZMy2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(512, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5asREmlN2U-",
        "outputId": "18625584-623e-4c5e-9a25-485b6812f3b6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_86 (Dense)            (None, 512)               12800     \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,852,418\n",
            "Trainable params: 1,852,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xTrain,yTrain,epochs=50,batch_size=32,validation_data=(xTest,yTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pjwc42r1N5yA",
        "outputId": "85d93af9-871a-4b3f-fec5-fa0afdae1433"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1728/1728 [==============================] - 34s 20ms/step - loss: 0.6703 - accuracy: 0.5828 - val_loss: 0.6564 - val_accuracy: 0.5958\n",
            "Epoch 2/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.6325 - accuracy: 0.6290 - val_loss: 0.6581 - val_accuracy: 0.6164\n",
            "Epoch 3/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.6020 - accuracy: 0.6555 - val_loss: 0.6355 - val_accuracy: 0.6257\n",
            "Epoch 4/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.5665 - accuracy: 0.6893 - val_loss: 0.6260 - val_accuracy: 0.6407\n",
            "Epoch 5/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.5279 - accuracy: 0.7196 - val_loss: 0.6337 - val_accuracy: 0.6443\n",
            "Epoch 6/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.4807 - accuracy: 0.7552 - val_loss: 0.6501 - val_accuracy: 0.6491\n",
            "Epoch 7/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.4216 - accuracy: 0.7953 - val_loss: 0.6713 - val_accuracy: 0.6516\n",
            "Epoch 8/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.3629 - accuracy: 0.8311 - val_loss: 0.7979 - val_accuracy: 0.6473\n",
            "Epoch 9/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.2952 - accuracy: 0.8674 - val_loss: 0.8942 - val_accuracy: 0.6584\n",
            "Epoch 10/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.2344 - accuracy: 0.8997 - val_loss: 1.0690 - val_accuracy: 0.6556\n",
            "Epoch 11/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.1789 - accuracy: 0.9260 - val_loss: 1.2799 - val_accuracy: 0.6460\n",
            "Epoch 12/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.1358 - accuracy: 0.9459 - val_loss: 1.3469 - val_accuracy: 0.6583\n",
            "Epoch 13/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.1037 - accuracy: 0.9595 - val_loss: 1.6027 - val_accuracy: 0.6651\n",
            "Epoch 14/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0839 - accuracy: 0.9687 - val_loss: 1.6826 - val_accuracy: 0.6562\n",
            "Epoch 15/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0685 - accuracy: 0.9752 - val_loss: 1.9070 - val_accuracy: 0.6616\n",
            "Epoch 16/50\n",
            "1728/1728 [==============================] - 34s 20ms/step - loss: 0.0604 - accuracy: 0.9780 - val_loss: 1.6143 - val_accuracy: 0.6624\n",
            "Epoch 17/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0502 - accuracy: 0.9819 - val_loss: 1.9098 - val_accuracy: 0.6609\n",
            "Epoch 18/50\n",
            "1728/1728 [==============================] - 34s 19ms/step - loss: 0.0459 - accuracy: 0.9839 - val_loss: 1.8323 - val_accuracy: 0.6622\n",
            "Epoch 19/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0403 - accuracy: 0.9856 - val_loss: 2.0209 - val_accuracy: 0.6658\n",
            "Epoch 20/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 1.8719 - val_accuracy: 0.6602\n",
            "Epoch 21/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 2.2087 - val_accuracy: 0.6579\n",
            "Epoch 22/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 2.0546 - val_accuracy: 0.6634\n",
            "Epoch 23/50\n",
            "1728/1728 [==============================] - 32s 18ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 2.1529 - val_accuracy: 0.6592\n",
            "Epoch 24/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 2.1521 - val_accuracy: 0.6635\n",
            "Epoch 25/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 2.1671 - val_accuracy: 0.6639\n",
            "Epoch 26/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 2.0510 - val_accuracy: 0.6596\n",
            "Epoch 27/50\n",
            "1728/1728 [==============================] - 32s 19ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 2.5012 - val_accuracy: 0.6615\n",
            "Epoch 28/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 2.6166 - val_accuracy: 0.6583\n",
            "Epoch 29/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 2.2208 - val_accuracy: 0.6567\n",
            "Epoch 30/50\n",
            "1728/1728 [==============================] - 33s 19ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 2.4303 - val_accuracy: 0.6593\n",
            "Epoch 31/50\n",
            " 248/1728 [===>..........................] - ETA: 26s - loss: 0.0139 - accuracy: 0.9963"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-4fa873b8d183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"monthly_tvcrypto_73_lkola3.h5\")"
      ],
      "metadata": {
        "id": "poebM4n15D_s"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "    \n",
        "    s1 = np.delete(s1, 1)\n",
        "    s1 = np.delete(s1, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "            \n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ],
      "metadata": {
        "id": "N_tbeIgn59yV"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"btc-usd\",\"1d\")"
      ],
      "metadata": {
        "id": "TZNKG00G5_l_",
        "outputId": "22f01c13-2bfb-4801-9388-44d65d3535c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9015149 , 0.14467987]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 4]\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "    \n",
        "    s1 = np.delete(s1, 1)\n",
        "    s1 = np.delete(s1, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcUSDt',exchange='binance',interval=Interval.in_daily,n_bars=30)\n",
        "   return model.predict(process_for_prediction(data))"
      ],
      "metadata": {
        "id": "WyJrjtlS5Mwp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"s\",\"x\")"
      ],
      "metadata": {
        "id": "gyhFeJ3-5cEX",
        "outputId": "2aa7f95e-5889-44b4-d654-9ad7fc92128a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94422555, 0.09328011]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jdjckGxiBK1S",
        "outputId": "940b6f13-4855-4ce1-8ece-910faca147a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NasQ_TV_15.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
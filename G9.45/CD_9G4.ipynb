{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "16304057-6c36-4235-95b5-7b208a661902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 7.5 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 44.0 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\n",
        "     \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\",     \n",
        "\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]\n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "\n",
        "        \n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i-1][3]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  \n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 50:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "             \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        unattached_dfs.append(process(pd.read_csv(address)))\n",
        "     \n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\"solving...\")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "        \n",
        "     unattached_dfs = []\n",
        "  \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files[426:]:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIAuU_ILbU27",
        "outputId": "1d278950-8e52-47e5-d8dd-6fcb5ce95320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " -- 100 -- 200 -- 300 -- 400 -- 500 -- 600 -- 700 -- 800 -- 900 -- 1000 -- 1100 -- 1200 -- 1300 -- 1400 -- 1500 \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "#symbols = read_txt_list()\n",
        "#symbols = read_syms_from_txt()\n",
        "#symbols = [\"msft\",\"aapl\",\"goog\"]\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"max\",\"1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7qBYzyyUKHQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41896df-5192-4454-b468-262639569598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 1495\n",
            "Processing File:\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  \n",
            "41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  \n",
            "81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  \n",
            "121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160  \n",
            "161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200  \n",
            "201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240  \n",
            "241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280  \n",
            "281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320  \n",
            "321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348  \n",
            "(411058, 242)\n",
            "(328846, 240) (328846, 2)\n",
            "(82212, 240) (82212, 2)\n"
          ]
        }
      ],
      "source": [
        "folder_name = extract_data(600)\n",
        "to_par(folder_name,60)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest = [], [] , [] ,[]"
      ],
      "metadata": {
        "id": "vJfWfqMX1JMy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([pd.read_csv(\"/content/drive/MyDrive/11.csv\"),pd.read_parquet(\"/content/extracted/072222/data.parquet\")])"
      ],
      "metadata": {
        "id": "s7I32w1rxSb0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/data.csv\")"
      ],
      "metadata": {
        "id": "eYKVp4ee1cw4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest = spliting(data)"
      ],
      "metadata": {
        "id": "f2v41YGNx8h0",
        "outputId": "75cffdbb-5e24-4718-c1a7-4bd04b8581da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1449784, 243) (1449784, 2)\n",
            "(362447, 243) (362447, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []"
      ],
      "metadata": {
        "id": "hSqJALEp3AIl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xN93WT9e8ueQ",
        "outputId": "8b7766a8-f2b4-4f44-c33a-ffe0e1cfcf51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              246784    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,496,834\n",
            "Trainable params: 5,496,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(1024, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_SBxPzRd89uy",
        "outputId": "a4d1417b-1ed2-4679-d9de-8c26779f4ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1416/1416 [==============================] - 46s 31ms/step - loss: 0.6379 - accuracy: 0.6173 - val_loss: 0.5862 - val_accuracy: 0.6759\n",
            "Epoch 2/30\n",
            "1416/1416 [==============================] - 42s 30ms/step - loss: 0.5372 - accuracy: 0.7156 - val_loss: 0.5108 - val_accuracy: 0.7372\n",
            "Epoch 3/30\n",
            "1416/1416 [==============================] - 42s 30ms/step - loss: 0.4478 - accuracy: 0.7817 - val_loss: 0.4262 - val_accuracy: 0.7980\n",
            "Epoch 4/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.3436 - accuracy: 0.8475 - val_loss: 0.3474 - val_accuracy: 0.8495\n",
            "Epoch 5/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.2585 - accuracy: 0.8939 - val_loss: 0.2953 - val_accuracy: 0.8814\n",
            "Epoch 6/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.2063 - accuracy: 0.9193 - val_loss: 0.2641 - val_accuracy: 0.8987\n",
            "Epoch 7/30\n",
            "1416/1416 [==============================] - 43s 31ms/step - loss: 0.1748 - accuracy: 0.9337 - val_loss: 0.2432 - val_accuracy: 0.9120\n",
            "Epoch 8/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.1528 - accuracy: 0.9434 - val_loss: 0.2414 - val_accuracy: 0.9137\n",
            "Epoch 9/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.1360 - accuracy: 0.9502 - val_loss: 0.2212 - val_accuracy: 0.9233\n",
            "Epoch 10/30\n",
            "1416/1416 [==============================] - 43s 31ms/step - loss: 0.1233 - accuracy: 0.9553 - val_loss: 0.2175 - val_accuracy: 0.9276\n",
            "Epoch 11/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.1127 - accuracy: 0.9593 - val_loss: 0.2125 - val_accuracy: 0.9310\n",
            "Epoch 12/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.1038 - accuracy: 0.9629 - val_loss: 0.2148 - val_accuracy: 0.9306\n",
            "Epoch 13/30\n",
            "1416/1416 [==============================] - 43s 31ms/step - loss: 0.0961 - accuracy: 0.9654 - val_loss: 0.2092 - val_accuracy: 0.9350\n",
            "Epoch 14/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0897 - accuracy: 0.9677 - val_loss: 0.2010 - val_accuracy: 0.9380\n",
            "Epoch 15/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0834 - accuracy: 0.9699 - val_loss: 0.2054 - val_accuracy: 0.9356\n",
            "Epoch 16/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0780 - accuracy: 0.9715 - val_loss: 0.1974 - val_accuracy: 0.9396\n",
            "Epoch 17/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0740 - accuracy: 0.9727 - val_loss: 0.2103 - val_accuracy: 0.9400\n",
            "Epoch 18/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0691 - accuracy: 0.9742 - val_loss: 0.2068 - val_accuracy: 0.9403\n",
            "Epoch 19/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0656 - accuracy: 0.9754 - val_loss: 0.2105 - val_accuracy: 0.9422\n",
            "Epoch 20/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0626 - accuracy: 0.9763 - val_loss: 0.2090 - val_accuracy: 0.9426\n",
            "Epoch 21/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0599 - accuracy: 0.9771 - val_loss: 0.2146 - val_accuracy: 0.9440\n",
            "Epoch 22/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0566 - accuracy: 0.9780 - val_loss: 0.2159 - val_accuracy: 0.9450\n",
            "Epoch 23/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0547 - accuracy: 0.9785 - val_loss: 0.2213 - val_accuracy: 0.9447\n",
            "Epoch 24/30\n",
            "1416/1416 [==============================] - 43s 30ms/step - loss: 0.0527 - accuracy: 0.9792 - val_loss: 0.2244 - val_accuracy: 0.9449\n",
            "Epoch 25/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0503 - accuracy: 0.9800 - val_loss: 0.2368 - val_accuracy: 0.9453\n",
            "Epoch 26/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0483 - accuracy: 0.9806 - val_loss: 0.2300 - val_accuracy: 0.9470\n",
            "Epoch 27/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0473 - accuracy: 0.9809 - val_loss: 0.2262 - val_accuracy: 0.9461\n",
            "Epoch 28/30\n",
            "1416/1416 [==============================] - 42s 30ms/step - loss: 0.0460 - accuracy: 0.9813 - val_loss: 0.2305 - val_accuracy: 0.9467\n",
            "Epoch 29/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0444 - accuracy: 0.9820 - val_loss: 0.2398 - val_accuracy: 0.9466\n",
            "Epoch 30/30\n",
            "1416/1416 [==============================] - 41s 29ms/step - loss: 0.0433 - accuracy: 0.9821 - val_loss: 0.2360 - val_accuracy: 0.9473\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3966925e10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=30,batch_size=1024,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"CD9G4_9473_c.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6bqkwjROb3lL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b2457bcd-5144-4bcf-ab8f-fd7945e8e3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Open      High       Low     Close  Adj Close  \\\n",
              "Datetime                                                                       \n",
              "2022-04-25 00:00:00+00:00  0.065702  0.065735  0.065565  0.065593   0.065593   \n",
              "2022-04-25 00:15:00+00:00  0.065522  0.065543  0.064642  0.064642   0.064642   \n",
              "2022-04-25 00:30:00+00:00  0.064635  0.064635  0.064298  0.064298   0.064298   \n",
              "2022-04-25 00:45:00+00:00  0.064269  0.064269  0.063579  0.063579   0.063579   \n",
              "2022-04-25 01:00:00+00:00  0.063562  0.063562  0.063211  0.063307   0.063307   \n",
              "...                             ...       ...       ...       ...        ...   \n",
              "2022-05-01 09:00:00+00:00  0.067207  0.067339  0.067112  0.067112   0.067112   \n",
              "2022-05-01 09:15:00+00:00  0.067064  0.067064  0.066849  0.066936   0.066936   \n",
              "2022-05-01 09:30:00+00:00  0.066917  0.067138  0.066881  0.067057   0.067057   \n",
              "2022-05-01 09:45:00+00:00  0.067034  0.067034  0.066971  0.066985   0.066985   \n",
              "2022-05-01 09:48:00+00:00  0.066994  0.066994  0.066994  0.066994   0.066994   \n",
              "\n",
              "                             Volume  \n",
              "Datetime                             \n",
              "2022-04-25 00:00:00+00:00         0  \n",
              "2022-04-25 00:15:00+00:00  15853440  \n",
              "2022-04-25 00:30:00+00:00  13354304  \n",
              "2022-04-25 00:45:00+00:00  14603072  \n",
              "2022-04-25 01:00:00+00:00   9554048  \n",
              "...                             ...  \n",
              "2022-05-01 09:00:00+00:00   7234560  \n",
              "2022-05-01 09:15:00+00:00  11070336  \n",
              "2022-05-01 09:30:00+00:00  12019712  \n",
              "2022-05-01 09:45:00+00:00   1389440  \n",
              "2022-05-01 09:48:00+00:00         0  \n",
              "\n",
              "[617 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdee227a-e315-4f92-90ab-8a420fd11eb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-25 00:00:00+00:00</th>\n",
              "      <td>0.065702</td>\n",
              "      <td>0.065735</td>\n",
              "      <td>0.065565</td>\n",
              "      <td>0.065593</td>\n",
              "      <td>0.065593</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-25 00:15:00+00:00</th>\n",
              "      <td>0.065522</td>\n",
              "      <td>0.065543</td>\n",
              "      <td>0.064642</td>\n",
              "      <td>0.064642</td>\n",
              "      <td>0.064642</td>\n",
              "      <td>15853440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-25 00:30:00+00:00</th>\n",
              "      <td>0.064635</td>\n",
              "      <td>0.064635</td>\n",
              "      <td>0.064298</td>\n",
              "      <td>0.064298</td>\n",
              "      <td>0.064298</td>\n",
              "      <td>13354304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-25 00:45:00+00:00</th>\n",
              "      <td>0.064269</td>\n",
              "      <td>0.064269</td>\n",
              "      <td>0.063579</td>\n",
              "      <td>0.063579</td>\n",
              "      <td>0.063579</td>\n",
              "      <td>14603072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-25 01:00:00+00:00</th>\n",
              "      <td>0.063562</td>\n",
              "      <td>0.063562</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.063307</td>\n",
              "      <td>0.063307</td>\n",
              "      <td>9554048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 09:00:00+00:00</th>\n",
              "      <td>0.067207</td>\n",
              "      <td>0.067339</td>\n",
              "      <td>0.067112</td>\n",
              "      <td>0.067112</td>\n",
              "      <td>0.067112</td>\n",
              "      <td>7234560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 09:15:00+00:00</th>\n",
              "      <td>0.067064</td>\n",
              "      <td>0.067064</td>\n",
              "      <td>0.066849</td>\n",
              "      <td>0.066936</td>\n",
              "      <td>0.066936</td>\n",
              "      <td>11070336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 09:30:00+00:00</th>\n",
              "      <td>0.066917</td>\n",
              "      <td>0.067138</td>\n",
              "      <td>0.066881</td>\n",
              "      <td>0.067057</td>\n",
              "      <td>0.067057</td>\n",
              "      <td>12019712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 09:45:00+00:00</th>\n",
              "      <td>0.067034</td>\n",
              "      <td>0.067034</td>\n",
              "      <td>0.066971</td>\n",
              "      <td>0.066985</td>\n",
              "      <td>0.066985</td>\n",
              "      <td>1389440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 09:48:00+00:00</th>\n",
              "      <td>0.066994</td>\n",
              "      <td>0.066994</td>\n",
              "      <td>0.066994</td>\n",
              "      <td>0.066994</td>\n",
              "      <td>0.066994</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>617 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdee227a-e315-4f92-90ab-8a420fd11eb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdee227a-e315-4f92-90ab-8a420fd11eb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdee227a-e315-4f92-90ab-8a420fd11eb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "yf.download(\"trx-usd\",period=\"7d\",interval=\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -2\n",
        "        row = []\n",
        "        if len(pd.DataFrame(data).columns) == 7:\n",
        "          data = data.iloc[: , 1:]        \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"100d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "bbbc80bf-0556-4240-d08d-8e3f9af68500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00256593, 0.99454415]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "make_prediction(\"trx-usd\",\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        row = []\n",
        "        data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='trxusd',exchange='binance',interval=Interval.in_15_minute,n_bars=100)\n",
        "   return model.predict(process_for_prediction(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgPS4HGIpgT",
        "outputId": "42730465-832f-49a5-ad17-2fe3189fddc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65548486, 0.32150912]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "a2f8f55e-67de-482d-e8cb-45c63f93a627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yf.download(\"trx\",period=\"1d\",interval=\"5m\")"
      ],
      "metadata": {
        "id": "WHX3ea8fINEe",
        "outputId": "f1b7b45f-7c81-44fe-e407-d5fdc4156273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Open     High       Low     Close  Adj Close  \\\n",
              "Datetime                                                                      \n",
              "2022-04-29 09:30:00-04:00  0.298000  0.30270  0.290000  0.300849   0.300849   \n",
              "2022-04-29 09:35:00-04:00  0.302490  0.30260  0.301201  0.302400   0.302400   \n",
              "2022-04-29 09:40:00-04:00  0.300000  0.30120  0.300000  0.301200   0.301200   \n",
              "2022-04-29 09:45:00-04:00  0.300101  0.30230  0.300000  0.302300   0.302300   \n",
              "2022-04-29 09:50:00-04:00  0.302000  0.30220  0.302000  0.302200   0.302200   \n",
              "...                             ...      ...       ...       ...        ...   \n",
              "2022-04-29 15:35:00-04:00  0.288000  0.28800  0.288000  0.288000   0.288000   \n",
              "2022-04-29 15:40:00-04:00  0.288500  0.29439  0.288500  0.291500   0.291500   \n",
              "2022-04-29 15:50:00-04:00  0.291200  0.29120  0.288500  0.290199   0.290199   \n",
              "2022-04-29 15:55:00-04:00  0.291100  0.29110  0.289900  0.291100   0.291100   \n",
              "2022-04-29 16:00:00-04:00  0.296000  0.29600  0.296000  0.296000   0.296000   \n",
              "\n",
              "                           Volume  \n",
              "Datetime                           \n",
              "2022-04-29 09:30:00-04:00   86764  \n",
              "2022-04-29 09:35:00-04:00    6708  \n",
              "2022-04-29 09:40:00-04:00    1359  \n",
              "2022-04-29 09:45:00-04:00   12800  \n",
              "2022-04-29 09:50:00-04:00    1306  \n",
              "...                           ...  \n",
              "2022-04-29 15:35:00-04:00     455  \n",
              "2022-04-29 15:40:00-04:00   34299  \n",
              "2022-04-29 15:50:00-04:00   10698  \n",
              "2022-04-29 15:55:00-04:00    4647  \n",
              "2022-04-29 16:00:00-04:00       0  \n",
              "\n",
              "[73 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bf012c9-bb0b-4d41-bdc5-027611c3c805\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:30:00-04:00</th>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.30270</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.300849</td>\n",
              "      <td>0.300849</td>\n",
              "      <td>86764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:35:00-04:00</th>\n",
              "      <td>0.302490</td>\n",
              "      <td>0.30260</td>\n",
              "      <td>0.301201</td>\n",
              "      <td>0.302400</td>\n",
              "      <td>0.302400</td>\n",
              "      <td>6708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:40:00-04:00</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.30120</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.301200</td>\n",
              "      <td>0.301200</td>\n",
              "      <td>1359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:45:00-04:00</th>\n",
              "      <td>0.300101</td>\n",
              "      <td>0.30230</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>12800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:50:00-04:00</th>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.30220</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.302200</td>\n",
              "      <td>0.302200</td>\n",
              "      <td>1306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 15:35:00-04:00</th>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.28800</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 15:40:00-04:00</th>\n",
              "      <td>0.288500</td>\n",
              "      <td>0.29439</td>\n",
              "      <td>0.288500</td>\n",
              "      <td>0.291500</td>\n",
              "      <td>0.291500</td>\n",
              "      <td>34299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 15:50:00-04:00</th>\n",
              "      <td>0.291200</td>\n",
              "      <td>0.29120</td>\n",
              "      <td>0.288500</td>\n",
              "      <td>0.290199</td>\n",
              "      <td>0.290199</td>\n",
              "      <td>10698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 15:55:00-04:00</th>\n",
              "      <td>0.291100</td>\n",
              "      <td>0.29110</td>\n",
              "      <td>0.289900</td>\n",
              "      <td>0.291100</td>\n",
              "      <td>0.291100</td>\n",
              "      <td>4647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 16:00:00-04:00</th>\n",
              "      <td>0.296000</td>\n",
              "      <td>0.29600</td>\n",
              "      <td>0.296000</td>\n",
              "      <td>0.296000</td>\n",
              "      <td>0.296000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bf012c9-bb0b-4d41-bdc5-027611c3c805')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bf012c9-bb0b-4d41-bdc5-027611c3c805 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bf012c9-bb0b-4d41-bdc5-027611c3c805');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CD_9G4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
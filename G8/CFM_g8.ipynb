{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "b43c6857-a402-4a8b-de64-3117964a575c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 17.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 44.9 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 25.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\"a\",\n",
        "    \"Open 1-2\", \"Open 2-3\", \"Open 3-4\", \"Open 4-5\", \"Open 5-6\", \"Open 6-7\", \"Open 7-8\", \"Open 8-9\", \"Open 9-10\", \"Open 10-11\", \"Open 11-12\", \"Open 12-13\", \"Open 13-14\", \"Open 14-15\", \"Open 15-16\",\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\", \"Close 8-9\", \"Close 9-10\", \"Close 10-11\", \"Close 11-12\", \"Close 12-13\", \"Close 13-14\", \"Close 14-15\", \"Close 15-16\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \"Low 3-4\", \"Low 4-5\", \"Low 5-6\", \"Low 6-7\", \"Low 7-8\", \"Low 8-9\", \"Low 9-10\", \"Low 10-11\", \"Low 11-12\", \"Low 12-13\", \"Low 13-14\", \"Low 14-15\", \"Low 15-16\",\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "        s1 = []\n",
        "        s2 = []\n",
        "        s3 = []\n",
        "        s4 = []\n",
        "        \n",
        "        s1 = [\n",
        "                data[i][0]   - data[i-1][0],\n",
        "                data[i-1][0] - data[i-2][0],\n",
        "                data[i-2][0] - data[i-3][0],\n",
        "                data[i-3][0] - data[i-4][0],\n",
        "                data[i-4][0] - data[i-5][0],\n",
        "                data[i-5][0] - data[i-6][0],\n",
        "                data[i-6][0] - data[i-7][0],\n",
        "                data[i-7][0] - data[i-8][0],\n",
        "                data[i-8][0] - data[i-9][0],\n",
        "                data[i-9][0] - data[i-10][0],\n",
        "                data[i-10][0] - data[i-11][0],\n",
        "                data[i-11][0] - data[i-12][0],\n",
        "                data[i-12][0] - data[i-13][0],\n",
        "                data[i-13][0] - data[i-14][0],\n",
        "                data[i-14][0]- data[i-15][0],\n",
        "                data[i-15][0] - data[i-16][0],\n",
        "           ]\n",
        "        \n",
        "        s2 = [\n",
        "                data[i-1][1] - data[1-2][1],\n",
        "                data[i-2][1] - data[1-3][1],\n",
        "                data[i-3][1] - data[1-4][1],\n",
        "                data[i-4][1] - data[1-5][1],\n",
        "                data[i-5][1] - data[1-6][1],\n",
        "                data[i-6][1] - data[1-7][1],\n",
        "                data[i-7][1] - data[1-8][1],\n",
        "                data[i-8][1] - data[1-9][1],\n",
        "                data[i-9][1] - data[1-10][1],\n",
        "                data[i-10][1] - data[1-11][1],\n",
        "                data[i-11][1] - data[1-12][1],\n",
        "                data[i-12][1] - data[1-13][1],\n",
        "                data[i-13][1] - data[1-14][1],\n",
        "                data[i-14][1] - data[1-15][1],\n",
        "                data[i-15][1] - data[1-16][1],\n",
        "           ]\n",
        "\n",
        "        s3 = [\n",
        "                data[i-1][2] - data[i-2][2],\n",
        "                data[i-2][2] - data[i-3][2],\n",
        "                data[i-3][2] - data[i-4][2],\n",
        "                data[i-4][2] - data[i-5][2],\n",
        "                data[i-5][2] - data[i-6][2],\n",
        "                data[i-6][2] - data[i-7][2],\n",
        "                data[i-7][2] - data[i-8][2],\n",
        "                data[i-8][2] - data[i-9][2],\n",
        "                data[i-9][2] - data[i-10][2],\n",
        "                data[i-10][2] - data[i-11][2],\n",
        "                data[i-11][2] - data[i-12][2],\n",
        "                data[i-12][2] - data[i-13][2],\n",
        "                data[i-13][2] - data[i-14][2],\n",
        "                data[i-14][2]- data[i-15][2],\n",
        "                data[i-15][2] - data[i-16][2],\n",
        "           ]\n",
        "\n",
        "        s4 = [\n",
        "                data[i-1][3] - data[i-2][3],\n",
        "                data[i-2][3] - data[i-3][3],\n",
        "                data[i-3][3] - data[i-4][3],\n",
        "                data[i-4][3] - data[i-5][3],\n",
        "                data[i-5][3] - data[i-6][3],\n",
        "                data[i-6][3] - data[i-7][3],\n",
        "                data[i-7][3] - data[i-8][3],\n",
        "                data[i-8][3] - data[i-9][3],\n",
        "                data[i-9][3] - data[i-10][3],\n",
        "                data[i-10][3] - data[i-11][3],\n",
        "                data[i-11][3] - data[i-12][3],\n",
        "                data[i-12][3] - data[i-13][3],\n",
        "                data[i-13][3] - data[i-14][3],\n",
        "                data[i-14][3] - data[i-15][3],\n",
        "                data[i-15][3] - data[i-16][3],\n",
        "           ]\n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        \n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i-1][3]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        grow = np.vstack((s1,s2,s3,s4))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  \n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 12:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "             \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        unattached_dfs.append(process(pd.read_csv(address)))\n",
        "     data = np.array(unattached_dfs[0])\n",
        "     for i in unattached_dfs[1:]:\n",
        "           data = np.append(data, np.array(i), axis=0)\n",
        "        \n",
        "     unattached_dfs = []\n",
        "  \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIAuU_ILbU27",
        "outputId": "2a47ae8c-db96-45ac-dd59-8fe8ec596898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 5\n",
            "Data Folder Removed\n",
            " \n",
            "Files In Data : 5\n",
            "Processing File:\n",
            "1 2 3 4 5  \n",
            "(2017, 63)\n",
            "(1613, 61) (1613, 2)\n",
            "(404, 61) (404, 2)\n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "#symbols = read_txt_list()\n",
        "#symbols = read_syms_from_txt()\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"xrp-usd\",\"ltc-usd\"]\n",
        "\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"2d\",\"5m\")\n",
        "folder_name = extract_data(1)\n",
        "to_par(folder_name,1)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xN93WT9e8ueQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72b41b6-d66a-45aa-ab2c-eaaa45377cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 1234)              76508     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1234)              1523990   \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1500)              1852500   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1500)              2251500   \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 2)                 3002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,851,440\n",
            "Trainable params: 14,851,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(1234, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1234, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "22eb8b18-609d-457d-ba55-a2774ccdb808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 10.7454 - accuracy: 0.8971 - val_loss: 12.8379 - val_accuracy: 0.8564\n",
            "Epoch 2/250\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 13.1516 - accuracy: 0.8487 - val_loss: 4.7169 - val_accuracy: 0.9431\n",
            "Epoch 3/250\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 6.4322 - accuracy: 0.9175 - val_loss: 12.0007 - val_accuracy: 0.8416\n",
            "Epoch 4/250\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 5.1724 - accuracy: 0.9188 - val_loss: 4.8407 - val_accuracy: 0.8886\n",
            "Epoch 5/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 3.4373 - accuracy: 0.9101 - val_loss: 6.1328 - val_accuracy: 0.8317\n",
            "Epoch 6/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.4998 - accuracy: 0.9200 - val_loss: 1.7177 - val_accuracy: 0.9356\n",
            "Epoch 7/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3605 - accuracy: 0.9783 - val_loss: 1.9973 - val_accuracy: 0.9084\n",
            "Epoch 8/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.8554 - accuracy: 0.9436 - val_loss: 2.4125 - val_accuracy: 0.8540\n",
            "Epoch 9/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.7884 - accuracy: 0.9343 - val_loss: 1.3680 - val_accuracy: 0.8936\n",
            "Epoch 10/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2148 - accuracy: 0.9746 - val_loss: 0.7234 - val_accuracy: 0.9233\n",
            "Epoch 11/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0424 - accuracy: 0.9926 - val_loss: 0.6005 - val_accuracy: 0.9109\n",
            "Epoch 12/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0693 - accuracy: 0.9833 - val_loss: 0.6399 - val_accuracy: 0.8911\n",
            "Epoch 13/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1054 - accuracy: 0.9764 - val_loss: 0.6516 - val_accuracy: 0.8738\n",
            "Epoch 14/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1180 - accuracy: 0.9665 - val_loss: 0.5543 - val_accuracy: 0.8762\n",
            "Epoch 15/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0835 - accuracy: 0.9727 - val_loss: 0.4217 - val_accuracy: 0.8762\n",
            "Epoch 16/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 0.3190 - val_accuracy: 0.9035\n",
            "Epoch 17/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.2754 - val_accuracy: 0.9158\n",
            "Epoch 18/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.2875 - val_accuracy: 0.9109\n",
            "Epoch 19/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.3135 - val_accuracy: 0.9084\n",
            "Epoch 20/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0217 - accuracy: 0.9975 - val_loss: 0.3289 - val_accuracy: 0.9084\n",
            "Epoch 21/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.3368 - val_accuracy: 0.9084\n",
            "Epoch 22/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.3448 - val_accuracy: 0.9109\n",
            "Epoch 23/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.3534 - val_accuracy: 0.9134\n",
            "Epoch 24/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.3647 - val_accuracy: 0.9109\n",
            "Epoch 25/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3789 - val_accuracy: 0.9084\n",
            "Epoch 26/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3954 - val_accuracy: 0.9084\n",
            "Epoch 27/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4141 - val_accuracy: 0.9109\n",
            "Epoch 28/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4349 - val_accuracy: 0.9109\n",
            "Epoch 29/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9109\n",
            "Epoch 30/250\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 6.6835e-04 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9109\n",
            "Epoch 31/250\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 3.8529e-04 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9134\n",
            "Epoch 32/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 2.3636e-04 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.9084\n",
            "Epoch 33/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.3883e-04 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.9158\n",
            "Epoch 34/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 9.1739e-05 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.9158\n",
            "Epoch 35/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.5936e-05 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9183\n",
            "Epoch 36/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.5787e-05 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.9183\n",
            "Epoch 37/250\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 2.4546e-05 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.9183\n",
            "Epoch 38/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.7180e-05 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.9183\n",
            "Epoch 39/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.2372e-05 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.9183\n",
            "Epoch 40/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 9.0976e-06 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.9183\n",
            "Epoch 41/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 6.6884e-06 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.9183\n",
            "Epoch 42/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 5.1170e-06 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.9183\n",
            "Epoch 43/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.9784e-06 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.9183\n",
            "Epoch 44/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.1473e-06 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.9183\n",
            "Epoch 45/250\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 2.5604e-06 - accuracy: 1.0000 - val_loss: 0.8346 - val_accuracy: 0.9183\n",
            "Epoch 46/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 2.1710e-06 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.9183\n",
            "Epoch 47/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.8531e-06 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.9183\n",
            "Epoch 48/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.6498e-06 - accuracy: 1.0000 - val_loss: 0.8646 - val_accuracy: 0.9183\n",
            "Epoch 49/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.4697e-06 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.9183\n",
            "Epoch 50/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.3372e-06 - accuracy: 1.0000 - val_loss: 0.8793 - val_accuracy: 0.9183\n",
            "Epoch 51/250\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 1.2174e-06 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.9183\n",
            "Epoch 52/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.1258e-06 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.9183\n",
            "Epoch 53/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.0563e-06 - accuracy: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.9183\n",
            "Epoch 54/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 9.9148e-07 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.9183\n",
            "Epoch 55/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 9.4026e-07 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.9183\n",
            "Epoch 56/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 8.9082e-07 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.9183\n",
            "Epoch 57/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 8.5166e-07 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.9183\n",
            "Epoch 58/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 8.1471e-07 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.9183\n",
            "Epoch 59/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.8056e-07 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.9183\n",
            "Epoch 60/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.5322e-07 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.9183\n",
            "Epoch 61/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 7.2543e-07 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.9183\n",
            "Epoch 62/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 7.0090e-07 - accuracy: 1.0000 - val_loss: 0.9258 - val_accuracy: 0.9183\n",
            "Epoch 63/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 6.7725e-07 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.9183\n",
            "Epoch 64/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.5442e-07 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.9183\n",
            "Epoch 65/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.3793e-07 - accuracy: 1.0000 - val_loss: 0.9328 - val_accuracy: 0.9183\n",
            "Epoch 66/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 6.1746e-07 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.9183\n",
            "Epoch 67/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 6.0165e-07 - accuracy: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.9183\n",
            "Epoch 68/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.8399e-07 - accuracy: 1.0000 - val_loss: 0.9391 - val_accuracy: 0.9183\n",
            "Epoch 69/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.7009e-07 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.9183\n",
            "Epoch 70/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.5302e-07 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.9183\n",
            "Epoch 71/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.3957e-07 - accuracy: 1.0000 - val_loss: 0.9449 - val_accuracy: 0.9183\n",
            "Epoch 72/250\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 5.2826e-07 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.9183\n",
            "Epoch 73/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.1334e-07 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.9183\n",
            "Epoch 74/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.0255e-07 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.9183\n",
            "Epoch 75/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 4.9006e-07 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.9183\n",
            "Epoch 76/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 4.7749e-07 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.9183\n",
            "Epoch 77/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 4.6700e-07 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9183\n",
            "Epoch 78/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 4.5614e-07 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.9183\n",
            "Epoch 79/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 4.4727e-07 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.9183\n",
            "Epoch 80/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 4.3788e-07 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.9183\n",
            "Epoch 81/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 4.2768e-07 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.9183\n",
            "Epoch 82/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 4.1904e-07 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.9183\n",
            "Epoch 83/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 4.0980e-07 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.9183\n",
            "Epoch 84/250\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 4.0130e-07 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9183\n",
            "Epoch 85/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.9347e-07 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9183\n",
            "Epoch 86/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.8534e-07 - accuracy: 1.0000 - val_loss: 0.9703 - val_accuracy: 0.9183\n",
            "Epoch 87/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.7802e-07 - accuracy: 1.0000 - val_loss: 0.9719 - val_accuracy: 0.9183\n",
            "Epoch 88/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 3.6996e-07 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.9183\n",
            "Epoch 89/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 3.6317e-07 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9183\n",
            "Epoch 90/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.5570e-07 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.9183\n",
            "Epoch 91/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.4920e-07 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.9183\n",
            "Epoch 92/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.4358e-07 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.9183\n",
            "Epoch 93/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.3567e-07 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.9183\n",
            "Epoch 94/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 3.2932e-07 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.9183\n",
            "Epoch 95/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.2355e-07 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.9183\n",
            "Epoch 96/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 3.1772e-07 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.9183\n",
            "Epoch 97/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 3.1239e-07 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.9183\n",
            "Epoch 98/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 3.0648e-07 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.9183\n",
            "Epoch 99/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 3.0072e-07 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.9183\n",
            "Epoch 100/250\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 2.9540e-07 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.9183\n",
            "Epoch 101/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 2.9044e-07 - accuracy: 1.0000 - val_loss: 0.9918 - val_accuracy: 0.9183\n",
            "Epoch 102/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.8446e-07 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.9183\n",
            "Epoch 103/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 2.7988e-07 - accuracy: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.9183\n",
            "Epoch 104/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 2.7515e-07 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.9183\n",
            "Epoch 105/250\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 2.7020e-07 - accuracy: 1.0000 - val_loss: 0.9971 - val_accuracy: 0.9183\n",
            "Epoch 106/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 2.6480e-07 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.9183\n",
            "Epoch 107/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 2.6110e-07 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.9183\n",
            "Epoch 108/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 2.5719e-07 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.9183\n",
            "Epoch 109/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 2.5261e-07 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.9183\n",
            "Epoch 110/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.4758e-07 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.9183\n",
            "Epoch 111/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 2.4366e-07 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.9183\n",
            "Epoch 112/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 2.3975e-07 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.9183\n",
            "Epoch 113/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 2.3620e-07 - accuracy: 1.0000 - val_loss: 1.0073 - val_accuracy: 0.9183\n",
            "Epoch 114/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 2.3280e-07 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.9183\n",
            "Epoch 115/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.2888e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9183\n",
            "Epoch 116/250\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 2.2548e-07 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.9183\n",
            "Epoch 117/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 2.2149e-07 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.9183\n",
            "Epoch 118/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.1876e-07 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.9183\n",
            "Epoch 119/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.1491e-07 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.9183\n",
            "Epoch 120/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.1174e-07 - accuracy: 1.0000 - val_loss: 1.0157 - val_accuracy: 0.9183\n",
            "Epoch 121/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 2.0834e-07 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.9183\n",
            "Epoch 122/250\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 2.0568e-07 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.9183\n",
            "Epoch 123/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 2.0235e-07 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.9183\n",
            "Epoch 124/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.9917e-07 - accuracy: 1.0000 - val_loss: 1.0202 - val_accuracy: 0.9183\n",
            "Epoch 125/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.9659e-07 - accuracy: 1.0000 - val_loss: 1.0214 - val_accuracy: 0.9183\n",
            "Epoch 126/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.9326e-07 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.9183\n",
            "Epoch 127/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.9097e-07 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.9183\n",
            "Epoch 128/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.8779e-07 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.9183\n",
            "Epoch 129/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.8521e-07 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.9183\n",
            "Epoch 130/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.8254e-07 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.9183\n",
            "Epoch 131/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.7974e-07 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.9183\n",
            "Epoch 132/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.7767e-07 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.9183\n",
            "Epoch 133/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.7471e-07 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.9183\n",
            "Epoch 134/250\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.7242e-07 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.9183\n",
            "Epoch 135/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.7028e-07 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.9183\n",
            "Epoch 136/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.6806e-07 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.9183\n",
            "Epoch 137/250\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 1.6533e-07 - accuracy: 1.0000 - val_loss: 1.0341 - val_accuracy: 0.9183\n",
            "Epoch 138/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.6289e-07 - accuracy: 1.0000 - val_loss: 1.0351 - val_accuracy: 0.9183\n",
            "Epoch 139/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.6119e-07 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.9183\n",
            "Epoch 140/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.5926e-07 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.9183\n",
            "Epoch 141/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 1.5646e-07 - accuracy: 1.0000 - val_loss: 1.0381 - val_accuracy: 0.9183\n",
            "Epoch 142/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.5498e-07 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.9183\n",
            "Epoch 143/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.5269e-07 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.9183\n",
            "Epoch 144/250\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.5106e-07 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.9183\n",
            "Epoch 145/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.4847e-07 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.9183\n",
            "Epoch 146/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.4685e-07 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 0.9183\n",
            "Epoch 147/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 1.4485e-07 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.9183\n",
            "Epoch 148/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.4338e-07 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.9183\n",
            "Epoch 149/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.4153e-07 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.9183\n",
            "Epoch 150/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.3916e-07 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.9183\n",
            "Epoch 151/250\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 1.0476 - val_accuracy: 0.9183\n",
            "Epoch 152/250\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 1.3606e-07 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.9183\n",
            "Epoch 153/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 1.3436e-07 - accuracy: 1.0000 - val_loss: 1.0495 - val_accuracy: 0.9183\n",
            "Epoch 154/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.3281e-07 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.9183\n",
            "Epoch 155/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.3089e-07 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.9183\n",
            "Epoch 156/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.2963e-07 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.9183\n",
            "Epoch 157/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.2823e-07 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.9183\n",
            "Epoch 158/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.2726e-07 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.9183\n",
            "Epoch 159/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.2534e-07 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.9183\n",
            "Epoch 160/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.2379e-07 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.9183\n",
            "Epoch 161/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.2194e-07 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.9183\n",
            "Epoch 162/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.2076e-07 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.9183\n",
            "Epoch 163/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.1936e-07 - accuracy: 1.0000 - val_loss: 1.0584 - val_accuracy: 0.9183\n",
            "Epoch 164/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.1803e-07 - accuracy: 1.0000 - val_loss: 1.0593 - val_accuracy: 0.9183\n",
            "Epoch 165/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.1677e-07 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.9183\n",
            "Epoch 166/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.1492e-07 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.9183\n",
            "Epoch 167/250\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.1367e-07 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.9183\n",
            "Epoch 168/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.1189e-07 - accuracy: 1.0000 - val_loss: 1.0628 - val_accuracy: 0.9183\n",
            "Epoch 169/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.1056e-07 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.9183\n",
            "Epoch 170/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.0945e-07 - accuracy: 1.0000 - val_loss: 1.0645 - val_accuracy: 0.9183\n",
            "Epoch 171/250\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 1.0834e-07 - accuracy: 1.0000 - val_loss: 1.0654 - val_accuracy: 0.9183\n",
            "Epoch 172/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.0679e-07 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.9183\n",
            "Epoch 173/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.0598e-07 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.9183\n",
            "Epoch 174/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.0465e-07 - accuracy: 1.0000 - val_loss: 1.0679 - val_accuracy: 0.9183\n",
            "Epoch 175/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.0369e-07 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.9183\n",
            "Epoch 176/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.0265e-07 - accuracy: 1.0000 - val_loss: 1.0695 - val_accuracy: 0.9183\n",
            "Epoch 177/250\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.0155e-07 - accuracy: 1.0000 - val_loss: 1.0703 - val_accuracy: 0.9183\n",
            "Epoch 178/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.0022e-07 - accuracy: 1.0000 - val_loss: 1.0712 - val_accuracy: 0.9183\n",
            "Epoch 179/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 9.9402e-08 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9183\n",
            "Epoch 180/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 9.8294e-08 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.9183\n",
            "Epoch 181/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 9.7333e-08 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.9183\n",
            "Epoch 182/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 9.6372e-08 - accuracy: 1.0000 - val_loss: 1.0744 - val_accuracy: 0.9183\n",
            "Epoch 183/250\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 9.5337e-08 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.9183\n",
            "Epoch 184/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 9.4229e-08 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.9183\n",
            "Epoch 185/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 9.3194e-08 - accuracy: 1.0000 - val_loss: 1.0768 - val_accuracy: 0.9183\n",
            "Epoch 186/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 9.2012e-08 - accuracy: 1.0000 - val_loss: 1.0776 - val_accuracy: 0.9183\n",
            "Epoch 187/250\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 9.0829e-08 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 0.9183\n",
            "Epoch 188/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 9.0238e-08 - accuracy: 1.0000 - val_loss: 1.0791 - val_accuracy: 0.9183\n",
            "Epoch 189/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 8.9425e-08 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.9183\n",
            "Epoch 190/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 8.8612e-08 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.9183\n",
            "Epoch 191/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 8.7651e-08 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.9183\n",
            "Epoch 192/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 8.6691e-08 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9183\n",
            "Epoch 193/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 8.5952e-08 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.9183\n",
            "Epoch 194/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 8.5065e-08 - accuracy: 1.0000 - val_loss: 1.0836 - val_accuracy: 0.9183\n",
            "Epoch 195/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 8.4473e-08 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.9183\n",
            "Epoch 196/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 8.3587e-08 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.9183\n",
            "Epoch 197/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 8.2921e-08 - accuracy: 1.0000 - val_loss: 1.0858 - val_accuracy: 0.9183\n",
            "Epoch 198/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 8.1813e-08 - accuracy: 1.0000 - val_loss: 1.0866 - val_accuracy: 0.9183\n",
            "Epoch 199/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 8.1148e-08 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.9183\n",
            "Epoch 200/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 8.0261e-08 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.9183\n",
            "Epoch 201/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.9226e-08 - accuracy: 1.0000 - val_loss: 1.0888 - val_accuracy: 0.9183\n",
            "Epoch 202/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.8192e-08 - accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 0.9183\n",
            "Epoch 203/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 7.7748e-08 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.9183\n",
            "Epoch 204/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.6861e-08 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.9183\n",
            "Epoch 205/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.6270e-08 - accuracy: 1.0000 - val_loss: 1.0916 - val_accuracy: 0.9183\n",
            "Epoch 206/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 7.5309e-08 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.9183\n",
            "Epoch 207/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 7.4422e-08 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.9183\n",
            "Epoch 208/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.3831e-08 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.9183\n",
            "Epoch 209/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.3092e-08 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.9183\n",
            "Epoch 210/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.2501e-08 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.9183\n",
            "Epoch 211/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 7.1836e-08 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.9183\n",
            "Epoch 212/250\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 7.1171e-08 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.9183\n",
            "Epoch 213/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7.0579e-08 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.9183\n",
            "Epoch 214/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.0136e-08 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.9183\n",
            "Epoch 215/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.9175e-08 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.9183\n",
            "Epoch 216/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 6.8732e-08 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.9183\n",
            "Epoch 217/250\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 6.7919e-08 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.9183\n",
            "Epoch 218/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 6.7180e-08 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.9183\n",
            "Epoch 219/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 6.6662e-08 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.9183\n",
            "Epoch 220/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 6.6293e-08 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.9183\n",
            "Epoch 221/250\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 6.5702e-08 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.9183\n",
            "Epoch 222/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 6.5036e-08 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.9183\n",
            "Epoch 223/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.4371e-08 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.9183\n",
            "Epoch 224/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 6.4002e-08 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.9183\n",
            "Epoch 225/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 6.3484e-08 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.9183\n",
            "Epoch 226/250\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 6.2819e-08 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.9183\n",
            "Epoch 227/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 6.2376e-08 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.9183\n",
            "Epoch 228/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 6.1711e-08 - accuracy: 1.0000 - val_loss: 1.1071 - val_accuracy: 0.9183\n",
            "Epoch 229/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.1267e-08 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.9183\n",
            "Epoch 230/250\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 6.0750e-08 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9183\n",
            "Epoch 231/250\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 6.0233e-08 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.9183\n",
            "Epoch 232/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 5.9420e-08 - accuracy: 1.0000 - val_loss: 1.1096 - val_accuracy: 0.9183\n",
            "Epoch 233/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.8902e-08 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.9183\n",
            "Epoch 234/250\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 5.8163e-08 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.9183\n",
            "Epoch 235/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.7868e-08 - accuracy: 1.0000 - val_loss: 1.1115 - val_accuracy: 0.9183\n",
            "Epoch 236/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 5.7498e-08 - accuracy: 1.0000 - val_loss: 1.1121 - val_accuracy: 0.9183\n",
            "Epoch 237/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.7129e-08 - accuracy: 1.0000 - val_loss: 1.1127 - val_accuracy: 0.9183\n",
            "Epoch 238/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 5.6611e-08 - accuracy: 1.0000 - val_loss: 1.1133 - val_accuracy: 0.9183\n",
            "Epoch 239/250\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 5.6242e-08 - accuracy: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.9183\n",
            "Epoch 240/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 5.5872e-08 - accuracy: 1.0000 - val_loss: 1.1144 - val_accuracy: 0.9183\n",
            "Epoch 241/250\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 5.5577e-08 - accuracy: 1.0000 - val_loss: 1.1150 - val_accuracy: 0.9183\n",
            "Epoch 242/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 5.4912e-08 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.9183\n",
            "Epoch 243/250\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 5.4468e-08 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.9183\n",
            "Epoch 244/250\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 5.4025e-08 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.9183\n",
            "Epoch 245/250\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 5.3581e-08 - accuracy: 1.0000 - val_loss: 1.1173 - val_accuracy: 0.9183\n",
            "Epoch 246/250\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 5.3138e-08 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.9183\n",
            "Epoch 247/250\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 5.2768e-08 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.9183\n",
            "Epoch 248/250\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 5.2473e-08 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.9183\n",
            "Epoch 249/250\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 5.2029e-08 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.9183\n",
            "Epoch 250/250\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 5.1734e-08 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.9183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9187eb0810>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=250,batch_size=1000,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"ts4.h5\")"
      ],
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6bqkwjROb3lL",
        "outputId": "a483d56d-3d0b-48ea-8136-d1393920d979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Open      High       Low     Close  Adj Close  \\\n",
              "Datetime                                                                       \n",
              "2022-04-27 00:00:00+00:00  0.061926  0.061926  0.061871  0.061871   0.061871   \n",
              "2022-04-27 00:05:00+00:00  0.061900  0.061982  0.061900  0.061977   0.061977   \n",
              "2022-04-27 00:10:00+00:00  0.061956  0.062089  0.061956  0.062075   0.062075   \n",
              "2022-04-27 00:15:00+00:00  0.062080  0.062080  0.062053  0.062062   0.062062   \n",
              "2022-04-27 00:20:00+00:00  0.062061  0.062084  0.062061  0.062084   0.062084   \n",
              "...                             ...       ...       ...       ...        ...   \n",
              "2022-04-27 05:25:00+00:00  0.062855  0.062869  0.062850  0.062869   0.062869   \n",
              "2022-04-27 05:30:00+00:00  0.062861  0.062890  0.062861  0.062879   0.062879   \n",
              "2022-04-27 05:35:00+00:00  0.062890  0.062909  0.062890  0.062908   0.062908   \n",
              "2022-04-27 05:40:00+00:00  0.062922  0.062934  0.062922  0.062934   0.062934   \n",
              "2022-04-27 05:45:00+00:00  0.062932  0.062932  0.062932  0.062932   0.062932   \n",
              "\n",
              "                            Volume  \n",
              "Datetime                            \n",
              "2022-04-27 00:00:00+00:00        0  \n",
              "2022-04-27 00:05:00+00:00  1606464  \n",
              "2022-04-27 00:10:00+00:00   611264  \n",
              "2022-04-27 00:15:00+00:00  1377920  \n",
              "2022-04-27 00:20:00+00:00   103488  \n",
              "...                            ...  \n",
              "2022-04-27 05:25:00+00:00   439168  \n",
              "2022-04-27 05:30:00+00:00   213760  \n",
              "2022-04-27 05:35:00+00:00   256576  \n",
              "2022-04-27 05:40:00+00:00  1160320  \n",
              "2022-04-27 05:45:00+00:00        0  \n",
              "\n",
              "[70 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1fa7eec-b7f7-459f-a9bd-997d708d67e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-27 00:00:00+00:00</th>\n",
              "      <td>0.061926</td>\n",
              "      <td>0.061926</td>\n",
              "      <td>0.061871</td>\n",
              "      <td>0.061871</td>\n",
              "      <td>0.061871</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 00:05:00+00:00</th>\n",
              "      <td>0.061900</td>\n",
              "      <td>0.061982</td>\n",
              "      <td>0.061900</td>\n",
              "      <td>0.061977</td>\n",
              "      <td>0.061977</td>\n",
              "      <td>1606464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 00:10:00+00:00</th>\n",
              "      <td>0.061956</td>\n",
              "      <td>0.062089</td>\n",
              "      <td>0.061956</td>\n",
              "      <td>0.062075</td>\n",
              "      <td>0.062075</td>\n",
              "      <td>611264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 00:15:00+00:00</th>\n",
              "      <td>0.062080</td>\n",
              "      <td>0.062080</td>\n",
              "      <td>0.062053</td>\n",
              "      <td>0.062062</td>\n",
              "      <td>0.062062</td>\n",
              "      <td>1377920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 00:20:00+00:00</th>\n",
              "      <td>0.062061</td>\n",
              "      <td>0.062084</td>\n",
              "      <td>0.062061</td>\n",
              "      <td>0.062084</td>\n",
              "      <td>0.062084</td>\n",
              "      <td>103488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:25:00+00:00</th>\n",
              "      <td>0.062855</td>\n",
              "      <td>0.062869</td>\n",
              "      <td>0.062850</td>\n",
              "      <td>0.062869</td>\n",
              "      <td>0.062869</td>\n",
              "      <td>439168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:30:00+00:00</th>\n",
              "      <td>0.062861</td>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.062861</td>\n",
              "      <td>0.062879</td>\n",
              "      <td>0.062879</td>\n",
              "      <td>213760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:35:00+00:00</th>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.062909</td>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.062908</td>\n",
              "      <td>0.062908</td>\n",
              "      <td>256576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:40:00+00:00</th>\n",
              "      <td>0.062922</td>\n",
              "      <td>0.062934</td>\n",
              "      <td>0.062922</td>\n",
              "      <td>0.062934</td>\n",
              "      <td>0.062934</td>\n",
              "      <td>1160320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:45:00+00:00</th>\n",
              "      <td>0.062932</td>\n",
              "      <td>0.062932</td>\n",
              "      <td>0.062932</td>\n",
              "      <td>0.062932</td>\n",
              "      <td>0.062932</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1fa7eec-b7f7-459f-a9bd-997d708d67e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1fa7eec-b7f7-459f-a9bd-997d708d67e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1fa7eec-b7f7-459f-a9bd-997d708d67e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data = yf.download(\"trx-usd\",period=\"1d\",interval=\"5m\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 5]\n",
        "    grow = []\n",
        "    srow = []\n",
        "    for j in llst:\n",
        "           srow.append([\n",
        "                data[i-1][j] ,\n",
        "                data[i-2][j] ,\n",
        "                data[i-3][j] ,\n",
        "                data[i-4][j] ,\n",
        "                data[i-5][j] ,\n",
        "                data[i-6][j] ,\n",
        "                data[i-7][j] ,\n",
        "                data[i-8][j] ,\n",
        "                data[i-9][j] ,\n",
        "                data[i-10][j] ,\n",
        "                data[i-11][j] ,\n",
        "                data[i-12][j] ,\n",
        "                data[i-13][j] ,\n",
        "                data[i-14][j],\n",
        "                data[i-15][j] ,\n",
        "           ])\n",
        "\n",
        "    for lst in srow:\n",
        "            mm = np.array(lst)\n",
        "            mm = np.reshape(mm, (-1, 1))\n",
        "            grow.append(scaler(mm))\n",
        "\n",
        "        \n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "eccc04f5-e465-4bc5-98d9-46bf3d04738f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.225143e-04, 9.998231e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "make_prediction(\"trx-usd\",\"5m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = TvDatafeed()\n",
        "tv.get_hist(symbol='TRXUSDT',exchange='BINANCE',interval=Interval.in_5_minute,n_bars=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qu46wjZZkV4I",
        "outputId": "9eb818e1-b7ca-45b1-cbf6-a2ccdf8b7887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              symbol     open     high      low    close  \\\n",
              "datetime                                                                   \n",
              "2022-04-27 03:25:00  BINANCE:TRXUSDT  0.06263  0.06264  0.06257  0.06258   \n",
              "2022-04-27 03:30:00  BINANCE:TRXUSDT  0.06259  0.06261  0.06247  0.06260   \n",
              "2022-04-27 03:35:00  BINANCE:TRXUSDT  0.06260  0.06261  0.06254  0.06257   \n",
              "2022-04-27 03:40:00  BINANCE:TRXUSDT  0.06256  0.06257  0.06244  0.06247   \n",
              "2022-04-27 03:45:00  BINANCE:TRXUSDT  0.06246  0.06250  0.06232  0.06237   \n",
              "2022-04-27 03:50:00  BINANCE:TRXUSDT  0.06238  0.06245  0.06236  0.06239   \n",
              "2022-04-27 03:55:00  BINANCE:TRXUSDT  0.06239  0.06244  0.06235  0.06243   \n",
              "2022-04-27 04:00:00  BINANCE:TRXUSDT  0.06244  0.06258  0.06242  0.06258   \n",
              "2022-04-27 04:05:00  BINANCE:TRXUSDT  0.06258  0.06270  0.06257  0.06267   \n",
              "2022-04-27 04:10:00  BINANCE:TRXUSDT  0.06267  0.06275  0.06261  0.06269   \n",
              "2022-04-27 04:15:00  BINANCE:TRXUSDT  0.06269  0.06275  0.06268  0.06275   \n",
              "2022-04-27 04:20:00  BINANCE:TRXUSDT  0.06275  0.06277  0.06268  0.06271   \n",
              "2022-04-27 04:25:00  BINANCE:TRXUSDT  0.06272  0.06289  0.06270  0.06287   \n",
              "2022-04-27 04:30:00  BINANCE:TRXUSDT  0.06288  0.06289  0.06280  0.06281   \n",
              "2022-04-27 04:35:00  BINANCE:TRXUSDT  0.06282  0.06288  0.06278  0.06284   \n",
              "2022-04-27 04:40:00  BINANCE:TRXUSDT  0.06283  0.06290  0.06280  0.06290   \n",
              "2022-04-27 04:45:00  BINANCE:TRXUSDT  0.06289  0.06296  0.06287  0.06293   \n",
              "2022-04-27 04:50:00  BINANCE:TRXUSDT  0.06293  0.06293  0.06285  0.06292   \n",
              "2022-04-27 04:55:00  BINANCE:TRXUSDT  0.06292  0.06294  0.06292  0.06293   \n",
              "2022-04-27 05:00:00  BINANCE:TRXUSDT  0.06292  0.06295  0.06289  0.06294   \n",
              "2022-04-27 05:05:00  BINANCE:TRXUSDT  0.06294  0.06294  0.06284  0.06291   \n",
              "2022-04-27 05:10:00  BINANCE:TRXUSDT  0.06290  0.06293  0.06283  0.06292   \n",
              "2022-04-27 05:15:00  BINANCE:TRXUSDT  0.06291  0.06293  0.06286  0.06289   \n",
              "2022-04-27 05:20:00  BINANCE:TRXUSDT  0.06290  0.06291  0.06282  0.06283   \n",
              "2022-04-27 05:25:00  BINANCE:TRXUSDT  0.06282  0.06288  0.06281  0.06287   \n",
              "2022-04-27 05:30:00  BINANCE:TRXUSDT  0.06287  0.06291  0.06283  0.06288   \n",
              "2022-04-27 05:35:00  BINANCE:TRXUSDT  0.06288  0.06296  0.06287  0.06292   \n",
              "2022-04-27 05:40:00  BINANCE:TRXUSDT  0.06292  0.06294  0.06289  0.06294   \n",
              "2022-04-27 05:45:00  BINANCE:TRXUSDT  0.06294  0.06299  0.06290  0.06293   \n",
              "2022-04-27 05:50:00  BINANCE:TRXUSDT  0.06292  0.06294  0.06291  0.06292   \n",
              "\n",
              "                        volume  \n",
              "datetime                        \n",
              "2022-04-27 03:25:00  2061266.9  \n",
              "2022-04-27 03:30:00  1849872.2  \n",
              "2022-04-27 03:35:00  1510140.0  \n",
              "2022-04-27 03:40:00  1886170.3  \n",
              "2022-04-27 03:45:00  4534167.0  \n",
              "2022-04-27 03:50:00  2950322.6  \n",
              "2022-04-27 03:55:00  1285161.3  \n",
              "2022-04-27 04:00:00  2453782.8  \n",
              "2022-04-27 04:05:00  3556572.9  \n",
              "2022-04-27 04:10:00  3442136.3  \n",
              "2022-04-27 04:15:00   893940.3  \n",
              "2022-04-27 04:20:00  2653767.5  \n",
              "2022-04-27 04:25:00  4005698.2  \n",
              "2022-04-27 04:30:00  3558952.4  \n",
              "2022-04-27 04:35:00  2964952.7  \n",
              "2022-04-27 04:40:00  2724885.6  \n",
              "2022-04-27 04:45:00  3173579.7  \n",
              "2022-04-27 04:50:00  2308373.4  \n",
              "2022-04-27 04:55:00   762503.6  \n",
              "2022-04-27 05:00:00  2630011.8  \n",
              "2022-04-27 05:05:00  4737668.3  \n",
              "2022-04-27 05:10:00  3328776.2  \n",
              "2022-04-27 05:15:00  2228840.3  \n",
              "2022-04-27 05:20:00  2659646.3  \n",
              "2022-04-27 05:25:00  1998214.8  \n",
              "2022-04-27 05:30:00  4395278.4  \n",
              "2022-04-27 05:35:00  4216617.8  \n",
              "2022-04-27 05:40:00  3603137.2  \n",
              "2022-04-27 05:45:00  3259100.2  \n",
              "2022-04-27 05:50:00   264429.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1aa91141-8103-4cb8-bbe8-5a0a4116b9ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:25:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.06264</td>\n",
              "      <td>0.06257</td>\n",
              "      <td>0.06258</td>\n",
              "      <td>2061266.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:30:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06259</td>\n",
              "      <td>0.06261</td>\n",
              "      <td>0.06247</td>\n",
              "      <td>0.06260</td>\n",
              "      <td>1849872.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:35:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06260</td>\n",
              "      <td>0.06261</td>\n",
              "      <td>0.06254</td>\n",
              "      <td>0.06257</td>\n",
              "      <td>1510140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:40:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06256</td>\n",
              "      <td>0.06257</td>\n",
              "      <td>0.06244</td>\n",
              "      <td>0.06247</td>\n",
              "      <td>1886170.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:45:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06246</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>0.06232</td>\n",
              "      <td>0.06237</td>\n",
              "      <td>4534167.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:50:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06238</td>\n",
              "      <td>0.06245</td>\n",
              "      <td>0.06236</td>\n",
              "      <td>0.06239</td>\n",
              "      <td>2950322.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 03:55:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06239</td>\n",
              "      <td>0.06244</td>\n",
              "      <td>0.06235</td>\n",
              "      <td>0.06243</td>\n",
              "      <td>1285161.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:00:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06244</td>\n",
              "      <td>0.06258</td>\n",
              "      <td>0.06242</td>\n",
              "      <td>0.06258</td>\n",
              "      <td>2453782.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:05:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06258</td>\n",
              "      <td>0.06270</td>\n",
              "      <td>0.06257</td>\n",
              "      <td>0.06267</td>\n",
              "      <td>3556572.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:10:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06267</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>0.06261</td>\n",
              "      <td>0.06269</td>\n",
              "      <td>3442136.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:15:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06269</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>0.06268</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>893940.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:20:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>0.06277</td>\n",
              "      <td>0.06268</td>\n",
              "      <td>0.06271</td>\n",
              "      <td>2653767.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:25:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06272</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>0.06270</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>4005698.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:30:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06288</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>0.06280</td>\n",
              "      <td>0.06281</td>\n",
              "      <td>3558952.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:35:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06282</td>\n",
              "      <td>0.06288</td>\n",
              "      <td>0.06278</td>\n",
              "      <td>0.06284</td>\n",
              "      <td>2964952.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:40:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06283</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>0.06280</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>2724885.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:45:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>0.06296</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>3173579.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:50:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>0.06285</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>2308373.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 04:55:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>762503.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:00:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>0.06295</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>2630011.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:05:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06284</td>\n",
              "      <td>0.06291</td>\n",
              "      <td>4737668.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:10:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>0.06283</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>3328776.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:15:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06291</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>0.06286</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>2228840.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:20:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>0.06291</td>\n",
              "      <td>0.06282</td>\n",
              "      <td>0.06283</td>\n",
              "      <td>2659646.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:25:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06282</td>\n",
              "      <td>0.06288</td>\n",
              "      <td>0.06281</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>1998214.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:30:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>0.06291</td>\n",
              "      <td>0.06283</td>\n",
              "      <td>0.06288</td>\n",
              "      <td>4395278.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:35:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06288</td>\n",
              "      <td>0.06296</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>4216617.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:40:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06289</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>3603137.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:45:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06299</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>0.06293</td>\n",
              "      <td>3259100.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-27 05:50:00</th>\n",
              "      <td>BINANCE:TRXUSDT</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>0.06294</td>\n",
              "      <td>0.06291</td>\n",
              "      <td>0.06292</td>\n",
              "      <td>264429.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1aa91141-8103-4cb8-bbe8-5a0a4116b9ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1aa91141-8103-4cb8-bbe8-5a0a4116b9ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1aa91141-8103-4cb8-bbe8-5a0a4116b9ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 4]\n",
        "    grow = []\n",
        "    srow = []\n",
        "    for j in llst:\n",
        "           srow.append([\n",
        "                data[i-1][j] ,\n",
        "                data[i-2][j] ,\n",
        "                data[i-3][j] ,\n",
        "                data[i-4][j] ,\n",
        "                data[i-5][j] ,\n",
        "                data[i-6][j] ,\n",
        "                data[i-7][j] ,\n",
        "                data[i-8][j] ,\n",
        "                data[i-9][j] ,\n",
        "                data[i-10][j] ,\n",
        "                data[i-11][j] ,\n",
        "                data[i-12][j] ,\n",
        "                data[i-13][j] ,\n",
        "                data[i-14][j],\n",
        "                data[i-15][j] ,\n",
        "           ])\n",
        "\n",
        "    for lst in srow:\n",
        "            mm = np.array(lst)\n",
        "            mm = np.reshape(mm, (-1, 1))\n",
        "            grow.append(scaler(mm))\n",
        "\n",
        "        \n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='TRXUSDT',exchange='BINANCE',interval=Interval.in_5_minute,n_bars=30)\n",
        "   return model.predict(process_for_prediction(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgPS4HGIpgT",
        "outputId": "a3df9c9c-2b0e-4d7a-f82b-6247d927acbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9994200e-01, 2.1633506e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "93fc5a3e-46fc-4c03-d290-5848e9413deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CFM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_5bxbCoe9do9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0efbb1-46ed-4bc3-aec3-dea21200a5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sys import getsizeof\n",
        "from datetime import datetime\n",
        "import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [ '12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume',\"suggestion\"]\n",
        "clmnsws = ['12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume']\n",
        "def read_syms_from_txt():  \n",
        "  with open(\"syms.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   #'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "   'all_cryptocurrencies_us','all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   #print(len(symbols))\n",
        "   #pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"suggestion\"],axis=1)\n",
        "  y = data[\"suggestion\"]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape,end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape,end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def extract_data(df):\n",
        "    rows = []\n",
        "    for each in range(13,df.shape[0]-1):\n",
        "        sugg = 0\n",
        "        if df[each][3] > df[each][0]:\n",
        "          sugg = 1\n",
        "        row = [\n",
        "                df[each-12][0],\n",
        "                df[each-12][1],\n",
        "                df[each-12][2],\n",
        "                df[each-12][3],\n",
        "                df[each-12][4],\n",
        "                df[each-11][0],\n",
        "                df[each-11][1],\n",
        "                df[each-11][2],\n",
        "                df[each-11][3],\n",
        "                df[each-11][4],\n",
        "                df[each-10][0],\n",
        "                df[each-10][1],\n",
        "                df[each-10][2],\n",
        "                df[each-10][3],\n",
        "                df[each-10][4],\n",
        "                df[each-9][0],\n",
        "                df[each-9][1],\n",
        "                df[each-9][2],\n",
        "                df[each-9][3],\n",
        "                df[each-9][4],\n",
        "                df[each-8][0],\n",
        "                df[each-8][1],\n",
        "                df[each-8][2],\n",
        "                df[each-8][3],\n",
        "                df[each-8][4],\n",
        "                df[each-7][0],\n",
        "                df[each-7][1],\n",
        "                df[each-7][2],\n",
        "                df[each-7][3],\n",
        "                df[each-7][4],\n",
        "                df[each-6][0],\n",
        "                df[each-6][1],\n",
        "                df[each-6][2],\n",
        "                df[each-6][3],\n",
        "                df[each-6][4],\n",
        "                df[each-5][0],\n",
        "                df[each-5][1],\n",
        "                df[each-5][2],\n",
        "                df[each-5][3],\n",
        "                df[each-5][4],\n",
        "                df[each-4][0],\n",
        "                df[each-4][1],\n",
        "                df[each-4][2],\n",
        "                df[each-4][3],\n",
        "                df[each-4][4],\n",
        "                df[each-3][0],\n",
        "                df[each-3][1],\n",
        "                df[each-3][2],\n",
        "                df[each-3][3],\n",
        "                df[each-3][4],\n",
        "                df[each-2][0],\n",
        "                df[each-2][1],\n",
        "                df[each-2][2],\n",
        "                df[each-2][3],\n",
        "                df[each-2][4],\n",
        "                df[each-1][0],\n",
        "                df[each-1][2],\n",
        "                df[each-1][1],\n",
        "                df[each-1][3],\n",
        "                df[each-1][4],\n",
        "                sugg\n",
        "        ]\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "def row_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(-6,6))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  scaled = pd.DataFrame(scaler.fit_transform(df.T).T,dtype=object,columns = clmnsws)\n",
        "  scaled[\"suggestion\"] = last_column\n",
        "  return scaled\n",
        "def column_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  df_scaled = scaler.fit_transform(df.to_numpy())\n",
        "  df_scaled = pd.DataFrame(df_scaled,columns = clmnsws)\n",
        "  df_scaled[\"suggestion\"] = last_column\n",
        "  return df_scaled\n",
        "def process(df): \n",
        "      df = df.dropna()\n",
        "      df = np.array(df)\n",
        "      df = extract_data(df)\n",
        "      df = pd.DataFrame(df,columns = clmns)\n",
        "      df = row_scaler(df)\n",
        "      #df = column_scaler(df)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hIAuU_ILbU27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b8170b-4c04-4a8a-8b50-7f452b2d5f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 Failed download:\n",
            "- XNO-AUD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- OXEN-AUD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- VAL-AUD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- ICP-CAD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- XNO-CAD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- OXEN-CAD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- VAL-CAD: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- ICP-EUR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- XNO-EUR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- OXEN-EUR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- VAL-EUR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- ICP-GBP: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- XNO-GBP: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- OXEN-GBP: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- VAL-GBP: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- ICP-INR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- XNO-INR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- OXEN-INR: No data found for this date range, symbol may be delisted\n",
            "\n",
            "1 Failed download:\n",
            "- VAL-INR: No data found, symbol may be delisted\n",
            "(886805, 60) (886805,)\n",
            "(98534, 60) (98534,)\n",
            "(985339, 61)\n"
          ]
        }
      ],
      "source": [
        "def get_data(symbols):\n",
        "    unattached_dfs = []\n",
        "    for symbol in symbols:\n",
        "           data = yf.download(symbol,period=\"730d\",interval=\"1d\",progress=False)\n",
        "           if data.empty :\n",
        "              pass\n",
        "           else:\n",
        "               if data.shape[0] > 14:\n",
        "                   unattached_dfs.append(process(data))\n",
        "    symbols = []\n",
        "    symbol = []\n",
        "    data = []\n",
        "\n",
        "    data = pd.concat(unattached_dfs)\n",
        "    data = data.astype(float)\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = spliting(data)\n",
        "    print(data.shape)\n",
        "    data.to_csv(f\"{random.randint(1,1000)}.csv\")\n",
        "    data = []\n",
        "    return xTrain, xTest, yTrain, yTest\n",
        "\n",
        "#symbols = [\"MSFT\",\"AAPL\",\"GOOG\",\"TSLA\",\"AMZN\"]\n",
        "#symbols = [\"BTC-USD\",\"LTC-USD\",\"TRX-USD\",\"XRP-USD\",\"ETH-USD\",\"BNB-USD\",\"DASH-USD\",\"VET-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"SOL-USD\",\"BCH-USD\",\"FTT-USD\",\"FIL-USD\",\"XMR-USD\"]\n",
        "#symbols = [\"AAPL\",\"MSFT\",\"TSLA\",\"GOOG\"]\n",
        "#symbols = [\"BTC-USD\",\"ETH-USD\"]\n",
        "#symbols = [\"BTC-USD\"]\n",
        "#symbols = read_syms_from_txt()\n",
        "symbols = get_crypto_syms()\n",
        "\n",
        "#pieces = 10\n",
        "#new_arrays = np.array_split(symbols, pieces)\n",
        "#for symbols in new_arrays:\n",
        "#   get_data(symbols)\n",
        "    \n",
        "xTrain, xTest, yTrain, yTest= get_data(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/12.csv\")\n",
        "data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "xTrain, xTest, yTrain, yTest= spliting(data)\n",
        "data"
      ],
      "metadata": {
        "id": "3MCpAhCyydmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN93WT9e8ueQ",
        "outputId": "82d569aa-6dd9-4534-88d7-c0b4a7898e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 2000)              122000    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1000)              2001000   \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1500)              1501500   \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1500)              2251500   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 1501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,878,501\n",
            "Trainable params: 6,878,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(2000, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "e57775af-17c9-40cd-a759-f83c8c52323d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 0.7243 - accuracy: 0.5387 - val_loss: 0.6699 - val_accuracy: 0.5795\n",
            "Epoch 2/100\n",
            "89/89 [==============================] - 20s 226ms/step - loss: 0.6545 - accuracy: 0.6000 - val_loss: 0.6356 - val_accuracy: 0.6220\n",
            "Epoch 3/100\n",
            "89/89 [==============================] - 20s 226ms/step - loss: 0.6249 - accuracy: 0.6332 - val_loss: 0.6031 - val_accuracy: 0.6555\n",
            "Epoch 4/100\n",
            "89/89 [==============================] - 20s 226ms/step - loss: 0.5947 - accuracy: 0.6607 - val_loss: 0.5818 - val_accuracy: 0.6701\n",
            "Epoch 5/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.5715 - accuracy: 0.6803 - val_loss: 0.5550 - val_accuracy: 0.6943\n",
            "Epoch 6/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.5353 - accuracy: 0.7111 - val_loss: 0.5282 - val_accuracy: 0.7179\n",
            "Epoch 7/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.4920 - accuracy: 0.7452 - val_loss: 0.4873 - val_accuracy: 0.7505\n",
            "Epoch 8/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 0.4369 - accuracy: 0.7838 - val_loss: 0.4423 - val_accuracy: 0.7848\n",
            "Epoch 9/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.3816 - accuracy: 0.8196 - val_loss: 0.4007 - val_accuracy: 0.8154\n",
            "Epoch 10/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.3192 - accuracy: 0.8564 - val_loss: 0.3673 - val_accuracy: 0.8381\n",
            "Epoch 11/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.2705 - accuracy: 0.8832 - val_loss: 0.3157 - val_accuracy: 0.8691\n",
            "Epoch 12/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.2291 - accuracy: 0.9046 - val_loss: 0.2926 - val_accuracy: 0.8856\n",
            "Epoch 13/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 0.1956 - accuracy: 0.9215 - val_loss: 0.2629 - val_accuracy: 0.9017\n",
            "Epoch 14/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.1652 - accuracy: 0.9359 - val_loss: 0.2632 - val_accuracy: 0.9067\n",
            "Epoch 15/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.1462 - accuracy: 0.9446 - val_loss: 0.2406 - val_accuracy: 0.9195\n",
            "Epoch 16/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.1294 - accuracy: 0.9518 - val_loss: 0.2367 - val_accuracy: 0.9234\n",
            "Epoch 17/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.1168 - accuracy: 0.9571 - val_loss: 0.2329 - val_accuracy: 0.9264\n",
            "Epoch 18/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.1054 - accuracy: 0.9617 - val_loss: 0.2307 - val_accuracy: 0.9313\n",
            "Epoch 19/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 0.0963 - accuracy: 0.9651 - val_loss: 0.2257 - val_accuracy: 0.9337\n",
            "Epoch 20/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0882 - accuracy: 0.9683 - val_loss: 0.2321 - val_accuracy: 0.9337\n",
            "Epoch 21/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0836 - accuracy: 0.9699 - val_loss: 0.2241 - val_accuracy: 0.9360\n",
            "Epoch 22/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 0.2232 - val_accuracy: 0.9389\n",
            "Epoch 23/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0732 - accuracy: 0.9734 - val_loss: 0.2323 - val_accuracy: 0.9378\n",
            "Epoch 24/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0707 - accuracy: 0.9742 - val_loss: 0.2294 - val_accuracy: 0.9404\n",
            "Epoch 25/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0663 - accuracy: 0.9757 - val_loss: 0.2291 - val_accuracy: 0.9406\n",
            "Epoch 26/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0654 - accuracy: 0.9756 - val_loss: 0.2334 - val_accuracy: 0.9412\n",
            "Epoch 27/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 0.0620 - accuracy: 0.9767 - val_loss: 0.2434 - val_accuracy: 0.9410\n",
            "Epoch 28/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0615 - accuracy: 0.9766 - val_loss: 0.2393 - val_accuracy: 0.9397\n",
            "Epoch 29/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0589 - accuracy: 0.9776 - val_loss: 0.2450 - val_accuracy: 0.9416\n",
            "Epoch 30/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0576 - accuracy: 0.9778 - val_loss: 0.2476 - val_accuracy: 0.9419\n",
            "Epoch 31/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0562 - accuracy: 0.9782 - val_loss: 0.2493 - val_accuracy: 0.9432\n",
            "Epoch 32/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0561 - accuracy: 0.9782 - val_loss: 0.2499 - val_accuracy: 0.9419\n",
            "Epoch 33/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0541 - accuracy: 0.9788 - val_loss: 0.2566 - val_accuracy: 0.9431\n",
            "Epoch 34/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0520 - accuracy: 0.9795 - val_loss: 0.2475 - val_accuracy: 0.9434\n",
            "Epoch 35/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0523 - accuracy: 0.9794 - val_loss: 0.2543 - val_accuracy: 0.9429\n",
            "Epoch 36/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0510 - accuracy: 0.9799 - val_loss: 0.2590 - val_accuracy: 0.9433\n",
            "Epoch 37/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0490 - accuracy: 0.9805 - val_loss: 0.2533 - val_accuracy: 0.9421\n",
            "Epoch 38/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0485 - accuracy: 0.9805 - val_loss: 0.2635 - val_accuracy: 0.9442\n",
            "Epoch 39/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0473 - accuracy: 0.9810 - val_loss: 0.2687 - val_accuracy: 0.9433\n",
            "Epoch 40/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0486 - accuracy: 0.9806 - val_loss: 0.2669 - val_accuracy: 0.9435\n",
            "Epoch 41/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0462 - accuracy: 0.9815 - val_loss: 0.2614 - val_accuracy: 0.9440\n",
            "Epoch 42/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0452 - accuracy: 0.9817 - val_loss: 0.2796 - val_accuracy: 0.9442\n",
            "Epoch 43/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0435 - accuracy: 0.9823 - val_loss: 0.2690 - val_accuracy: 0.9453\n",
            "Epoch 44/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0422 - accuracy: 0.9828 - val_loss: 0.2748 - val_accuracy: 0.9453\n",
            "Epoch 45/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0438 - accuracy: 0.9823 - val_loss: 0.2832 - val_accuracy: 0.9439\n",
            "Epoch 46/100\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 0.0439 - accuracy: 0.9820 - val_loss: 0.2823 - val_accuracy: 0.9470\n",
            "Epoch 47/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 0.0423 - accuracy: 0.9827 - val_loss: 0.2782 - val_accuracy: 0.9461\n",
            "Epoch 48/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0414 - accuracy: 0.9830 - val_loss: 0.2795 - val_accuracy: 0.9469\n",
            "Epoch 49/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0409 - accuracy: 0.9832 - val_loss: 0.2815 - val_accuracy: 0.9455\n",
            "Epoch 50/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0406 - accuracy: 0.9832 - val_loss: 0.2783 - val_accuracy: 0.9465\n",
            "Epoch 51/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0377 - accuracy: 0.9845 - val_loss: 0.2876 - val_accuracy: 0.9462\n",
            "Epoch 52/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0394 - accuracy: 0.9838 - val_loss: 0.2855 - val_accuracy: 0.9453\n",
            "Epoch 53/100\n",
            "89/89 [==============================] - 21s 234ms/step - loss: 0.0396 - accuracy: 0.9836 - val_loss: 0.2842 - val_accuracy: 0.9475\n",
            "Epoch 54/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0375 - accuracy: 0.9843 - val_loss: 0.2956 - val_accuracy: 0.9458\n",
            "Epoch 55/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0376 - accuracy: 0.9844 - val_loss: 0.2953 - val_accuracy: 0.9465\n",
            "Epoch 56/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0365 - accuracy: 0.9849 - val_loss: 0.3028 - val_accuracy: 0.9475\n",
            "Epoch 57/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0385 - accuracy: 0.9841 - val_loss: 0.2922 - val_accuracy: 0.9454\n",
            "Epoch 58/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0390 - accuracy: 0.9841 - val_loss: 0.2867 - val_accuracy: 0.9470\n",
            "Epoch 59/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0361 - accuracy: 0.9849 - val_loss: 0.2908 - val_accuracy: 0.9469\n",
            "Epoch 60/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0364 - accuracy: 0.9849 - val_loss: 0.2953 - val_accuracy: 0.9474\n",
            "Epoch 61/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0350 - accuracy: 0.9853 - val_loss: 0.3003 - val_accuracy: 0.9468\n",
            "Epoch 62/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0364 - accuracy: 0.9848 - val_loss: 0.3005 - val_accuracy: 0.9476\n",
            "Epoch 63/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0353 - accuracy: 0.9854 - val_loss: 0.2943 - val_accuracy: 0.9475\n",
            "Epoch 64/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0346 - accuracy: 0.9855 - val_loss: 0.2947 - val_accuracy: 0.9470\n",
            "Epoch 65/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0342 - accuracy: 0.9856 - val_loss: 0.2990 - val_accuracy: 0.9482\n",
            "Epoch 66/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0348 - accuracy: 0.9854 - val_loss: 0.2920 - val_accuracy: 0.9474\n",
            "Epoch 67/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0352 - accuracy: 0.9854 - val_loss: 0.2919 - val_accuracy: 0.9491\n",
            "Epoch 68/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0329 - accuracy: 0.9860 - val_loss: 0.2984 - val_accuracy: 0.9487\n",
            "Epoch 69/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0351 - accuracy: 0.9854 - val_loss: 0.2971 - val_accuracy: 0.9478\n",
            "Epoch 70/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0332 - accuracy: 0.9861 - val_loss: 0.2955 - val_accuracy: 0.9490\n",
            "Epoch 71/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0314 - accuracy: 0.9867 - val_loss: 0.3062 - val_accuracy: 0.9492\n",
            "Epoch 72/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0331 - accuracy: 0.9861 - val_loss: 0.3112 - val_accuracy: 0.9480\n",
            "Epoch 73/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0345 - accuracy: 0.9856 - val_loss: 0.2915 - val_accuracy: 0.9487\n",
            "Epoch 74/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0328 - accuracy: 0.9863 - val_loss: 0.2961 - val_accuracy: 0.9487\n",
            "Epoch 75/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0319 - accuracy: 0.9865 - val_loss: 0.3031 - val_accuracy: 0.9475\n",
            "Epoch 76/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0314 - accuracy: 0.9866 - val_loss: 0.3032 - val_accuracy: 0.9483\n",
            "Epoch 77/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0323 - accuracy: 0.9865 - val_loss: 0.3043 - val_accuracy: 0.9487\n",
            "Epoch 78/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0320 - accuracy: 0.9866 - val_loss: 0.3058 - val_accuracy: 0.9474\n",
            "Epoch 79/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 0.3050 - val_accuracy: 0.9494\n",
            "Epoch 80/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0303 - accuracy: 0.9871 - val_loss: 0.3081 - val_accuracy: 0.9487\n",
            "Epoch 81/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0305 - accuracy: 0.9871 - val_loss: 0.2981 - val_accuracy: 0.9494\n",
            "Epoch 82/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0318 - accuracy: 0.9867 - val_loss: 0.3013 - val_accuracy: 0.9493\n",
            "Epoch 83/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0312 - accuracy: 0.9868 - val_loss: 0.3085 - val_accuracy: 0.9491\n",
            "Epoch 84/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0312 - accuracy: 0.9868 - val_loss: 0.3082 - val_accuracy: 0.9497\n",
            "Epoch 85/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0302 - accuracy: 0.9871 - val_loss: 0.3167 - val_accuracy: 0.9483\n",
            "Epoch 86/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0306 - accuracy: 0.9871 - val_loss: 0.3087 - val_accuracy: 0.9498\n",
            "Epoch 87/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0302 - accuracy: 0.9872 - val_loss: 0.3063 - val_accuracy: 0.9495\n",
            "Epoch 88/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0301 - accuracy: 0.9873 - val_loss: 0.3129 - val_accuracy: 0.9498\n",
            "Epoch 89/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0305 - accuracy: 0.9870 - val_loss: 0.3102 - val_accuracy: 0.9492\n",
            "Epoch 90/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0296 - accuracy: 0.9875 - val_loss: 0.3061 - val_accuracy: 0.9497\n",
            "Epoch 91/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0287 - accuracy: 0.9878 - val_loss: 0.3094 - val_accuracy: 0.9495\n",
            "Epoch 92/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0296 - accuracy: 0.9873 - val_loss: 0.3215 - val_accuracy: 0.9486\n",
            "Epoch 93/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0308 - accuracy: 0.9870 - val_loss: 0.3169 - val_accuracy: 0.9485\n",
            "Epoch 94/100\n",
            "89/89 [==============================] - 20s 228ms/step - loss: 0.0291 - accuracy: 0.9876 - val_loss: 0.3208 - val_accuracy: 0.9501\n",
            "Epoch 95/100\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 0.0280 - accuracy: 0.9880 - val_loss: 0.3203 - val_accuracy: 0.9495\n",
            "Epoch 96/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 0.3317 - val_accuracy: 0.9496\n",
            "Epoch 97/100\n",
            "23/89 [======>.......................] - ETA: 14s - loss: 0.0270 - accuracy: 0.9885"
          ]
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=100,batch_size=10000,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAKTl3fbHIE6",
        "outputId": "80d2cac3-80cc-41fb-f789-43c19e618c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Crypto_Hour_Trading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "1a179172-af00-4bc9-e1ae-342f32370f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: yahooquery in /usr/local/lib/python3.7/dist-packages (2.2.15)\n",
            "Requirement already satisfied: requests-futures>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: tvdatafeed in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (0.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.2)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (4.1.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (1.26.9)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.20.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.9.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.2.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.1.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium->tvdatafeed) (1.1.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (22.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (37.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1m8zVb-KL6tO",
        "outputId": "82beee5a-c356-4c3d-cdc9-fac71bf1d03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "    \"Open 1\",\"Close 1\",\"Open 2\",\"Close 2\",\"Open 3\",\"Close 3\",\"Open 4\",\"Close 4\",\"Open 5\",\"Close 5\",\"Open 6\",\"Close 6\",\"Open 7\",\"Close 7\",\"Open 8\",\"Close 8\",\"Open 9\",\"Close 9\",\"Open 10\",\"Close 10\",\"Open 11\",\"Close 11\",\"Open 12\",\"Close 12\",\"Open 13\",\"Close 13\",\"Open 14\",\"Close 14\",\"Open 15\",\"Close 15\",\"Open 16\",\"Close 16\",\"Open 17\",\"Close 17\",\"Open 18\",\"Close 18\",\"Open 19\",\"Close 19\",\"Open 20\",\"Close 20\",\"Open 21\",\"Close 21\",\"Open 22\",\"Close 22\",\"Open 23\",\"Close 23\",\"Open 24\",\"Close 24\",\"Open 25\",\"Close 25\",\"Open 26\",\"Close 26\",\"Open 27\",\"Close 27\",\"Open 28\",\"Close 28\",\"Open 29\",\"Close 29\",\"Open 30\",\"Close 30\",\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"buy\",\"sell\"], axis=1)\n",
        "  y = data[[\"buy\",\"sell\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-3,3))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    for i in range(30, data.shape[0]):\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x, 0], data[i-x, 1],\n",
        "                        data[i-x, 2], data[i-x, 3]])\n",
        "        for eeach in grow:\n",
        "            ggrow.append(scaler(np.array(eeach).reshape(-1, 1)))\n",
        "        for eachh in ggrow:\n",
        "            eachh = np.array(eachh).reshape(-1,1)\n",
        "            eachh = np.delete(eachh,1)\n",
        "            eachh = np.delete(eachh, 1)\n",
        "            gggrow.append(eachh)\n",
        "        sugg = \"sell\"\n",
        "        if data[i][3] > data[i-1][3]:\n",
        "            sugg = \"buy\"\n",
        "        arr = np.array(gggrow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "    grow = []\n",
        "    ggrow = []\n",
        "    gggrow = []\n",
        "    arr = []\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rl4JHnPmp5z7"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 30:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")         \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        try:\n",
        "           unattached_dfs.append(process(pd.read_csv(address)))\n",
        "        except:\n",
        "          print(\" EP \")\n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\" Null \")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     unattached_dfs = []\n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files[:100]:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "d82de2fd-dbb5-44fe-9cb5-394e10106721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " -- 100 -- 200 -- 300 -- 400 -- 500 -- 600 -- 700 -- 800 -- 900 -- 1000 -- 1100 -- 1200 -- 1300 -- 1400 -- 1500 \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"730d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT3YU88Edyb3"
      },
      "outputs": [],
      "source": [
        "folder_name = extract_data(500)\n",
        "to_par(folder_name,1)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest = spliting(pd.concat([pd.read_parquet(\"/content/drive/MyDrive/chc_data1.parquet\"),pd.read_parquet(\"/content/drive/MyDrive/chc_data2.parquet\")]))"
      ],
      "metadata": {
        "id": "OO3i7QKiN0AD",
        "outputId": "66cf98e4-67bf-4991-a723-f2a3cc41d499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6079338, 60) (6079338, 2)\n",
            "(675482, 60) (675482, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"CHC_G115.h5\")"
      ],
      "metadata": {
        "id": "PuP_YNNwkUJQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN93WT9e8ueQ",
        "outputId": "5c4a995a-8446-4210-b6cb-8924e8e076ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3000)              183000    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2000)              6002000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1500)              3001500   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1500)              2251500   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1500)              2251500   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 3002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,692,502\n",
            "Trainable params: 13,692,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(3000, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "8cf509f9-968d-4fb7-b0c9-be624b91bf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "244/244 [==============================] - 316s 1s/step - loss: 0.0982 - accuracy: 0.9707 - val_loss: 0.0889 - val_accuracy: 0.9745\n",
            "Epoch 2/10\n",
            "244/244 [==============================] - 304s 1s/step - loss: 0.0622 - accuracy: 0.9821 - val_loss: 0.0947 - val_accuracy: 0.9720\n",
            "Epoch 3/10\n",
            "244/244 [==============================] - 303s 1s/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.1079 - val_accuracy: 0.9683\n",
            "Epoch 4/10\n",
            "197/244 [=======================>......] - ETA: 56s - loss: 0.0439 - accuracy: 0.9863"
          ]
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=10,batch_size=25000,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"CHC_G115.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bqkwjROb3lL"
      },
      "outputs": [],
      "source": [
        "yf.download(\"btc-usd\",period=\"max\",interval=\"1mo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        if len(pd.DataFrame(data).columns) == 7:\n",
        "          data = data.iloc[: , 1:]        \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x, 0], data[i-x, 1],\n",
        "                        data[i-x, 2], data[i-x, 3]])\n",
        "        for eeach in grow:\n",
        "            ggrow.append(scaler(np.array(eeach).reshape(-1, 1)))\n",
        "        for eachh in ggrow:\n",
        "            eachh = np.array(eachh).reshape(-1,1)\n",
        "            eachh = np.delete(eachh,1)\n",
        "            eachh = np.delete(eachh, 1)\n",
        "            gggrow.append(eachh)\n",
        "        arr = np.array(gggrow).flatten().reshape(-1,1)\n",
        "        return arr\n",
        "def make_prediction(symbol,period,timeframe):\n",
        "    raw_data = process_for_prediction(yf.download(symbol,period=period,interval=timeframe))\n",
        "    return  model.predict(np.array(raw_data).reshape(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "da480447-c089-400f-c8b3-4e48507af1ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.99922645, 0.00252116]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "make_prediction(\"btc-usd\",\"max\",\"1mo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        row = []\n",
        "        data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x, 0], data[i-x, 1],\n",
        "                        data[i-x, 2], data[i-x, 3]])\n",
        "        for eeach in grow:\n",
        "            ggrow.append(scaler(np.array(eeach).reshape(-1, 1)))\n",
        "        for eachh in ggrow:\n",
        "            eachh = np.array(eachh).reshape(-1,1)\n",
        "            eachh = np.delete(eachh,1)\n",
        "            eachh = np.delete(eachh, 1)\n",
        "            gggrow.append(eachh)\n",
        "        arr = np.array(gggrow).flatten()\n",
        "        return arr\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcUSD',exchange='bitstamp',interval=Interval.in_monthly,n_bars=100)\n",
        "   return model.predict(np.array(process_for_prediction(data)).reshape(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLgPS4HGIpgT"
      },
      "outputs": [],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CHC_G115.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
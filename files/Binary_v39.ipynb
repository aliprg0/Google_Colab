{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5bxbCoe9do9"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def read_syms_from_txt():  \n",
        "  with open(\"syms.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "  #'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        " 'all_cryptocurrencies_us','all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in']\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   #print(len(symbols))\n",
        "   #pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"sugg\"],axis=1)\n",
        "  y = data[\"sugg\"]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1,random_state=99)\n",
        "  print(xTrain.shape,end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape,end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def extract_data(df):\n",
        "    rows = []\n",
        "    for each in range(11,df.shape[0]-1):\n",
        "        sugg = 0\n",
        "        if df[each+1][3] > df[each][3]:\n",
        "          sugg = 1\n",
        "        row = [\n",
        "                df[each-10][3],\n",
        "                df[each-9][3],\n",
        "                df[each-8][3],\n",
        "                df[each-7][3],\n",
        "                df[each-6][3],\n",
        "                df[each-5][3],\n",
        "                df[each-4][3],\n",
        "                df[each-3][3],\n",
        "                df[each-2][3],\n",
        "                df[each-1][3],\n",
        "                df[each][3], \n",
        "                sugg\n",
        "        ]\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "def row_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  scaled = pd.DataFrame(scaler.fit_transform(df.T).T,dtype=object)\n",
        "  scaled[\"sugg\"] = last_column\n",
        "  return scaled\n",
        "def stick_dfs(dfs):\n",
        "  dataframe = dfs[0]\n",
        "  for i in range(1,len(dfs)):\n",
        "     dataframe = pd.concat([dataframe,dfs[i]], ignore_index = True)\n",
        "  dataframe = dataframe.dropna()\n",
        "  dataframe = dataframe.astype(float)\n",
        "  return dataframe\n",
        "def process(dfs): \n",
        "   fixed_dfs = []\n",
        "   for df in dfs:\n",
        "      df = np.array(df)\n",
        "      df = extract_data(df)\n",
        "      df = pd.DataFrame(df)\n",
        "      df = row_scaler(df)\n",
        "      fixed_dfs.append(df)\n",
        "   df = stick_dfs(fixed_dfs)\n",
        "   return df      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIAuU_ILbU27"
      },
      "outputs": [],
      "source": [
        "#symbols = [\"MSFT\",\"AAPL\",\"GOOG\",\"TSLA\",\"AMZN\"]\n",
        "#symbols = [\"BTC-USD\",\"LTC-USD\",\"TRX-USD\",\"XRP-USD\",\"ETH-USD\",\"BNB-USD\",\"DASH-USD\",\"VET-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"SOL-USD\",\"BCH-USD\",\"FTT-USD\",\"FIL-USD\",\"XMR-USD\"]\n",
        "#symbols = [\"AAPL\",\"MSFT\",\"TSLA\",\"GOOG\"]\n",
        "#symbols = [\"BTC-USD\",\"ETH-USD\"]\n",
        "#symbols = [\"BTC-USD\"]\n",
        "#df = pd.read_parquet(\"/content/drive/MyDrive/Colab Files/250_crypto_1d_scaled_yf.parquet\")\n",
        "\n",
        "symbols = get_crypto_syms()\n",
        "dfs = []\n",
        "for symbol in symbols:\n",
        "           data = yf.download(symbol,period=\"MAX\",interval=\"1d\",progress=False)\n",
        "           if data.empty :\n",
        "             print(\"Passing...\")\n",
        "           else:\n",
        "               dfs.append(data)\n",
        "ndfs = dfs\n",
        "dfs = []\n",
        "for df in ndfs:\n",
        "        if df.shape[0] > 12:\n",
        "          dfs.append(df)\n",
        "data = process(dfs)\n",
        "data.to_csv(\"1d_6pc_10mms.csv\")\n",
        "xTrain, xTest, yTrain, yTest = spliting(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = read_syms_from_txt()\n",
        "len(symbols)\n",
        "pieces = 15\n",
        "new_arrays = np.array_split(symbols, pieces)\n",
        "for i in new_arrays:\n",
        "  dfs = []\n",
        "  for x in i:\n",
        "        data = yf.download(x,period=\"MAX\",interval=\"1d\",progress=False)\n",
        "        if data.empty :\n",
        "             print(\"Passing...\")\n",
        "        else:\n",
        "               dfs.append(data)\n",
        "  ndfs = dfs\n",
        "  dfs = []\n",
        "  for df in ndfs:\n",
        "        if df.shape[0] > 12:\n",
        "          dfs.append(df)\n",
        "  data = process(dfs)\n",
        "  data.to_csv(f\"{x}.csv\")         "
      ],
      "metadata": {
        "id": "IL0Gg7OMYIQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = os.listdir(\"/content/gdrive/MyDrive/Colab Files/\")\n",
        "\n",
        "data = pd.DataFrame()\n",
        "for file in files:\n",
        "  address = f\"/content/gdrive/MyDrive/Colab Files/{file}\"\n",
        "  df = pd.read_csv(address)\n",
        "  data = pd.concat([data,df])"
      ],
      "metadata": {
        "id": "SFwh6-67na1X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, xTest, yTrain, yTest = spliting(data)\n",
        "data"
      ],
      "metadata": {
        "id": "Nu3DTgF_qBLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rI1oRc9VRwO"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=3e-4,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=True,\n",
        "    name=\"Adam\")\n",
        "\n",
        "model.add(Dense(1500, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "#model.add(Dense(1000, activation='relu'))\n",
        "#model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDTaW4WnX330"
      },
      "outputs": [],
      "source": [
        "model.fit(xTrain,yTrain,epochs=100,batch_size=50000,validation_data=(xTest,yTest))\n",
        "model.evaluate(xTest,yTest)\n",
        "model.save(f\"{model.evaluate(xTest,yTest)}.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46M8IzrdKgf8"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(xTrain,yTrain)\n",
        "print(f\"Random Forest :  {clf.score(xTest,yTest)}\")\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(xTrain, yTrain)\n",
        "print(f\"Logistic Regression: {logisticRegr.score(xTest, yTest)}\")\n",
        "nc = NearestCentroid()\n",
        "nc.fit(xTrain,yTrain)\n",
        "print(f\"Nearest Centroid: {nc.score(xTest,yTest)}\")\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(xTrain, yTrain)\n",
        "print(f\"GaussianNB: {gnb.score(xTest,yTest)}\")\n",
        "clf2 = KNeighborsClassifier(n_neighbors=2)\n",
        "clf2.fit(xTrain, yTrain)\n",
        "print(f\"K-Neighbors: {clf2.score(xTest,yTest)}\")\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(xTrain, yTrain)\n",
        "print(f\"Decision Tree: {tree.score(xTest,yTest)}\")\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "   max_depth=1, random_state=0).fit(xTrain, yTrain)\n",
        "gb.fit(xTrain,yTrain)\n",
        "print(f\"Gradient Boost: {gb.score(xTest, yTest)}\")\n",
        "svm = SVC()\n",
        "svm.fit(xTrain,yTrain)\n",
        "print(f\"SVM: {svm.score(xTest,yTest)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": " Binary_v39.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWtLTkUMxTSADzeQFdlSgt"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
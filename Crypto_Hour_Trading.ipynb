{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5bxbCoe9do9"
      },
      "outputs": [],
      "source": [
        "#!pip install yfinance\n",
        "#!pip install yahooquery\n",
        "#from yahooquery import Screener\n",
        "#import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "#from sklearn.svm import SVC\n",
        "#from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.neighbors import NearestCentroid\n",
        "#from sklearn.ensemble import GradientBoostingClassifier\n",
        "#from sklearn.neighbors import KNeighborsClassifier\n",
        "import tensorflow as tf\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "#from sys import getsizeof\n",
        "#from datetime import datetime\n",
        "#import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [ '12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume',\"suggestion\"]\n",
        "clmnsws = ['12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume']\n",
        "def read_syms_from_txt():  \n",
        "  with open(\"syms.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   #'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "   'all_cryptocurrencies_us','all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   #print(len(symbols))\n",
        "   #pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"suggestion\"],axis=1)\n",
        "  y = data[\"suggestion\"]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape,end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape,end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def extract_data(df):\n",
        "    rows = []\n",
        "    for each in range(13,df.shape[0]-1):\n",
        "        sugg = 0\n",
        "        if df[each][3] > df[each][0]:\n",
        "          sugg = 1\n",
        "        row = [\n",
        "                df[each-12][0],\n",
        "                df[each-12][1],\n",
        "                df[each-12][2],\n",
        "                df[each-12][3],\n",
        "                df[each-12][4],\n",
        "                df[each-11][0],\n",
        "                df[each-11][1],\n",
        "                df[each-11][2],\n",
        "                df[each-11][3],\n",
        "                df[each-11][4],\n",
        "                df[each-10][0],\n",
        "                df[each-10][1],\n",
        "                df[each-10][2],\n",
        "                df[each-10][3],\n",
        "                df[each-10][4],\n",
        "                df[each-9][0],\n",
        "                df[each-9][1],\n",
        "                df[each-9][2],\n",
        "                df[each-9][3],\n",
        "                df[each-9][4],\n",
        "                df[each-8][0],\n",
        "                df[each-8][1],\n",
        "                df[each-8][2],\n",
        "                df[each-8][3],\n",
        "                df[each-8][4],\n",
        "                df[each-7][0],\n",
        "                df[each-7][1],\n",
        "                df[each-7][2],\n",
        "                df[each-7][3],\n",
        "                df[each-7][4],\n",
        "                df[each-6][0],\n",
        "                df[each-6][1],\n",
        "                df[each-6][2],\n",
        "                df[each-6][3],\n",
        "                df[each-6][4],\n",
        "                df[each-5][0],\n",
        "                df[each-5][1],\n",
        "                df[each-5][2],\n",
        "                df[each-5][3],\n",
        "                df[each-5][4],\n",
        "                df[each-4][0],\n",
        "                df[each-4][1],\n",
        "                df[each-4][2],\n",
        "                df[each-4][3],\n",
        "                df[each-4][4],\n",
        "                df[each-3][0],\n",
        "                df[each-3][1],\n",
        "                df[each-3][2],\n",
        "                df[each-3][3],\n",
        "                df[each-3][4],\n",
        "                df[each-2][0],\n",
        "                df[each-2][1],\n",
        "                df[each-2][2],\n",
        "                df[each-2][3],\n",
        "                df[each-2][4],\n",
        "                df[each-1][0],\n",
        "                df[each-1][2],\n",
        "                df[each-1][1],\n",
        "                df[each-1][3],\n",
        "                df[each-1][4],\n",
        "                sugg\n",
        "        ]\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "def row_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(-6,6))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  scaled = pd.DataFrame(scaler.fit_transform(df.T).T,dtype=object,columns = clmnsws)\n",
        "  scaled[\"suggestion\"] = last_column\n",
        "  return scaled\n",
        "def column_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  df_scaled = scaler.fit_transform(df.to_numpy())\n",
        "  df_scaled = pd.DataFrame(df_scaled,columns = clmnsws)\n",
        "  df_scaled[\"suggestion\"] = last_column\n",
        "  return df_scaled\n",
        "def process(df): \n",
        "      df = df.dropna()\n",
        "      df = np.array(df)\n",
        "      df = extract_data(df)\n",
        "      df = pd.DataFrame(df,columns = clmns)\n",
        "      df = row_scaler(df)\n",
        "      #df = column_scaler(df)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIAuU_ILbU27"
      },
      "outputs": [],
      "source": [
        "def get_data(symbols):\n",
        "    unattached_dfs = []\n",
        "    for symbol in symbols:\n",
        "           data = yf.download(symbol,period=\"730d\",interval=\"1d\",progress=False)\n",
        "           if data.empty :\n",
        "              pass\n",
        "           else:\n",
        "               if data.shape[0] > 14:\n",
        "                   unattached_dfs.append(process(data))\n",
        "    symbols = []\n",
        "    symbol = []\n",
        "    data = []\n",
        "\n",
        "    data = pd.concat(unattached_dfs)\n",
        "    data = data.astype(float)\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = spliting(data)\n",
        "    print(data.shape)\n",
        "    data.to_csv(f\"{random.randint(1,1000)}.csv\")\n",
        "    data = []\n",
        "    return xTrain, xTest, yTrain, yTest\n",
        "\n",
        "#symbols = [\"MSFT\",\"AAPL\",\"GOOG\",\"TSLA\",\"AMZN\"]\n",
        "#symbols = [\"BTC-USD\",\"LTC-USD\",\"TRX-USD\",\"XRP-USD\",\"ETH-USD\",\"BNB-USD\",\"DASH-USD\",\"VET-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"SOL-USD\",\"BCH-USD\",\"FTT-USD\",\"FIL-USD\",\"XMR-USD\"]\n",
        "#symbols = [\"AAPL\",\"MSFT\",\"TSLA\",\"GOOG\"]\n",
        "#symbols = [\"BTC-USD\",\"ETH-USD\"]\n",
        "#symbols = [\"BTC-USD\"]\n",
        "#symbols = read_syms_from_txt()\n",
        "symbols = get_crypto_syms()\n",
        "\n",
        "#pieces = 10\n",
        "#new_arrays = np.array_split(symbols, pieces)\n",
        "#for symbols in new_arrays:\n",
        "#   get_data(symbols)\n",
        "    \n",
        "xTrain, xTest, yTrain, yTest= get_data(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spliting(data):\n",
        "  X = data.drop([\"suggestion\"],axis=1)\n",
        "  y = data[\"suggestion\"]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape,end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape,end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "\n",
        "data = pd.read_parquet(\"/content/drive/MyDrive/lol4.parquet\")\n",
        "data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "xTrain, xTest, yTrain, yTest= spliting(data)\n",
        "data = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MCpAhCyydmO",
        "outputId": "59119894-bf62-4aa2-e625-7452b089176f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6087411, 60) (6087411,)\n",
            "(676380, 60) (676380,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN93WT9e8ueQ",
        "outputId": "406660dd-b2e2-4880-e90d-c08aaf2d09a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 2000)              122000    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2000)              4002000   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2000)              4002000   \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2000)              4002000   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2000)              4002000   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1000)              2001000   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 1001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,132,001\n",
            "Trainable params: 18,132,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(2000, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "9172e090-009f-4c42-f70b-684355f5a6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "305/305 [==============================] - 337s 1s/step - loss: 0.7392 - accuracy: 0.5343 - val_loss: 0.6881 - val_accuracy: 0.5390\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 330s 1s/step - loss: 0.6865 - accuracy: 0.5450 - val_loss: 0.6869 - val_accuracy: 0.5432\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 330s 1s/step - loss: 0.6833 - accuracy: 0.5535 - val_loss: 0.6822 - val_accuracy: 0.5569\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 333s 1s/step - loss: 0.6781 - accuracy: 0.5640 - val_loss: 0.6767 - val_accuracy: 0.5661\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 331s 1s/step - loss: 0.6714 - accuracy: 0.5741 - val_loss: 0.6716 - val_accuracy: 0.5729\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 331s 1s/step - loss: 0.6635 - accuracy: 0.5846 - val_loss: 0.6633 - val_accuracy: 0.5847\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 331s 1s/step - loss: 0.6540 - accuracy: 0.5959 - val_loss: 0.6542 - val_accuracy: 0.5944\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 332s 1s/step - loss: 0.6426 - accuracy: 0.6086 - val_loss: 0.6472 - val_accuracy: 0.6029\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 333s 1s/step - loss: 0.6293 - accuracy: 0.6229 - val_loss: 0.6373 - val_accuracy: 0.6146\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 333s 1s/step - loss: 0.6124 - accuracy: 0.6404 - val_loss: 0.6267 - val_accuracy: 0.6263\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 333s 1s/step - loss: 0.5900 - accuracy: 0.6626 - val_loss: 0.6129 - val_accuracy: 0.6432\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 334s 1s/step - loss: 0.5602 - accuracy: 0.6896 - val_loss: 0.6015 - val_accuracy: 0.6596\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 334s 1s/step - loss: 0.5227 - accuracy: 0.7203 - val_loss: 0.5811 - val_accuracy: 0.6825\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 335s 1s/step - loss: 0.4802 - accuracy: 0.7521 - val_loss: 0.5671 - val_accuracy: 0.7053\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 335s 1s/step - loss: 0.4328 - accuracy: 0.7845 - val_loss: 0.5432 - val_accuracy: 0.7276\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 335s 1s/step - loss: 0.3855 - accuracy: 0.8146 - val_loss: 0.5364 - val_accuracy: 0.7467\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 335s 1s/step - loss: 0.3400 - accuracy: 0.8416 - val_loss: 0.5212 - val_accuracy: 0.7663\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 336s 1s/step - loss: 0.2985 - accuracy: 0.8650 - val_loss: 0.5141 - val_accuracy: 0.7828\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 335s 1s/step - loss: 0.2612 - accuracy: 0.8850 - val_loss: 0.5119 - val_accuracy: 0.7966\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 336s 1s/step - loss: 0.2290 - accuracy: 0.9014 - val_loss: 0.5137 - val_accuracy: 0.8068\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 339s 1s/step - loss: 0.2017 - accuracy: 0.9151 - val_loss: 0.5055 - val_accuracy: 0.8172\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1783 - accuracy: 0.9264 - val_loss: 0.5075 - val_accuracy: 0.8255\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1596 - accuracy: 0.9353 - val_loss: 0.5215 - val_accuracy: 0.8324\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1440 - accuracy: 0.9423 - val_loss: 0.5188 - val_accuracy: 0.8373\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1315 - accuracy: 0.9479 - val_loss: 0.5243 - val_accuracy: 0.8412\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1209 - accuracy: 0.9525 - val_loss: 0.5367 - val_accuracy: 0.8448\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 340s 1s/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.5490 - val_accuracy: 0.8485\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 339s 1s/step - loss: 0.1047 - accuracy: 0.9595 - val_loss: 0.5541 - val_accuracy: 0.8493\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 338s 1s/step - loss: 0.0984 - accuracy: 0.9622 - val_loss: 0.5599 - val_accuracy: 0.8513\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 338s 1s/step - loss: 0.0933 - accuracy: 0.9644 - val_loss: 0.5530 - val_accuracy: 0.8537\n",
            "Epoch 31/50\n",
            "152/305 [=============>................] - ETA: 2:43 - loss: 0.0827 - accuracy: 0.9685"
          ]
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=50,batch_size=20000,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAKTl3fbHIE6",
        "outputId": "cbf65033-0abf-4970-8f97-9a232ec03612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Crypto_Hour_Trading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
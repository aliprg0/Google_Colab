{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5bxbCoe9do9"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install mplfinance\n",
        "!pip install cairocffi\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib notebook\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "def get_crypto_syms():\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   return symbols\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def extract_data(max_check, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, max_check,\n",
        "                     each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "def each_file_proc(file, now, max_check, each_row_past):\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-max_check\n",
        "    lst = []\n",
        "    for i in range(11,91,10):\n",
        "            lst2 = []\n",
        "            for x in range(i,i-10,-1):\n",
        "              lst2.append(abs(data[-i][3]-data[-i][0]))\n",
        "            lst.append(sum(lst2)/len(lst2))\n",
        "    mean_candle = sum(lst)/len(lst)\n",
        "\n",
        "    for i in range(each_row_past,max_index):\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "\n",
        "        current_price = (data[i][0] + data[i][3])/2\n",
        "        delta = mean_candle * 3\n",
        "\n",
        "        high =round(current_price + delta)\n",
        "        low = round(current_price - delta)\n",
        "\n",
        "        sugg = 0\n",
        "        for p in range(i+1,i):\n",
        "          if data[p][3] <= low:\n",
        "            sugg = 0\n",
        "            break\n",
        "          if data[p][3] >= high:\n",
        "            sugg = 1\n",
        "            break\n",
        "\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clf()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 20:\n",
        "          plt.close(\"all\")\n",
        "        if i % 270 ==0:\n",
        "          print(\"\")\n",
        "    plt.close(\"all\")\n",
        "    print(\"\")\n",
        "\n",
        "def start(max_check, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        max_check, each_row_past)\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols[:100],\"1mo\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "a50fe364-8d5f-4baf-fa95-548d1ca2ac0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            "File Number 2: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            "File Number 3: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            "File Number 4: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            "File Number 5: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            "File Number 6: 90/726 100/726 110/726 120/726 130/726 140/726 150/726 160/726 170/726 180/726 190/726 200/726 210/726 220/726 230/726 240/726 250/726 260/726 270/726 \n",
            "280/726 290/726 300/726 310/726 320/726 330/726 340/726 350/726 360/726 370/726 380/726 390/726 400/726 410/726 420/726 430/726 440/726 450/726 460/726 470/726 480/726 490/726 500/726 510/726 520/726 530/726 540/726 \n",
            "550/726 560/726 570/726 580/726 590/726 600/726 610/726 620/726 630/726 640/726 650/726 660/726 670/726 680/726 690/726 700/726 710/726 720/726 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3846"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "max_check = 20\n",
        "each_row_past = 85\n",
        "\n",
        "folder_name = start(max_check,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpQvhf-pwpR",
        "outputId": "2e169ca6-2459-4078-806e-e3d4e2b57caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3846, 128, 128)\n",
            "xTrain : 3076 \\ xTest : 770\n",
            "yn: 0 nn: 3846\n"
          ]
        }
      ],
      "source": [
        "#folder_name = \"191530\"\n",
        "\n",
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(f\"/content/{folder_name}.zip\",f\"/content/extracted/{folder_name}\")\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9stbJK8Nx_0c",
        "outputId": "c035f04b-012d-406a-d842-6645bb1e57b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 128)     1280      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 128)       147584    \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 30, 30, 128)      0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 100)       115300    \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 14, 14, 100)      0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 64)        57664     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 900)               8295300   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 900)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 900)               810900    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 900)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 900)               810900    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 900)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 900)               810900    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 1802      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,051,630\n",
            "Trainable params: 11,051,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128,     (3,3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1), kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128,     (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(100,     (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,      (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(900,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(900,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(900,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(900,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.00015)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytWxowTyInc",
        "outputId": "0b33368e-4a6c-4493-b9ce-607ae6cfa0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "97/97 [==============================] - 300s 3s/step - loss: 0.2137 - accuracy: 0.9899 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "13/97 [===>..........................] - ETA: 4:01 - loss: 0.1465 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=20,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjRn1rKTEFSH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(xTest,yTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUhFkNfwDtr"
      },
      "outputs": [],
      "source": [
        "model.save(f\"1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz7BAj5wwlN"
      },
      "outputs": [],
      "source": [
        "symbol,period,interval=\"btc-usd\",\"10d\",\"1h\"\n",
        "data = yf.download(tickers=symbol,period=period,interval=interval)\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "data = data.astype(float)\n",
        "i = -2\n",
        "rows = data[i-each_row_past:i, :]\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb2r1l8yB-0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8nJ2wI-ynZw"
      },
      "outputs": [],
      "source": [
        "tv = TvDatafeed()\n",
        "data = tv.get_hist(symbol=\"btcusdt\",exchange=\"binance\",interval=Interval.in_1_hour,n_bars=1000)\n",
        "data = np.array(data)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, 1:5]\n",
        "rows.shape\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpTFxbUd5mXt"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture1.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7lUM_NBNxj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "G33",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "f5e39fa5-54a2-4fda-d3ce-aae2818af2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.74)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yahooquery in /usr/local/lib/python3.7/dist-packages (2.2.15)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: requests-futures>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.0.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.26.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tvdatafeed in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (4.3.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.3)\n",
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (0.3.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.21.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.9.2)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (1.26.11)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.2.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium->tvdatafeed) (1.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (22.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (37.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mplfinance in /usr/local/lib/python3.7/dist-packages (0.12.9b1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install mplfinance\n",
        "!pip install cairocffi\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib notebook\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "def get_crypto_syms():\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   return symbols\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3]-data[i+z][0])\n",
        "        next_candles = sum(next_candles)\n",
        "        if next_candles > 0:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clf()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 20:\n",
        "          plt.close(\"all\")\n",
        "        if i % 270 ==0:\n",
        "          print(\"\")\n",
        "    plt.close(\"all\")\n",
        "    print(\"\")\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "e83c9855-ebb6-4efe-e530-9ad44c66672a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"160d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "c84b6674-4ac0-487d-c4e8-ea3e412e7214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            "File Number 2: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            "File Number 3: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            "File Number 4: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            "File Number 5: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            "File Number 6: 80/3829 90/3829 100/3829 110/3829 120/3829 130/3829 140/3829 150/3829 160/3829 170/3829 180/3829 190/3829 200/3829 210/3829 220/3829 230/3829 240/3829 250/3829 260/3829 270/3829 \n",
            "280/3829 290/3829 300/3829 310/3829 320/3829 330/3829 340/3829 350/3829 360/3829 370/3829 380/3829 390/3829 400/3829 410/3829 420/3829 430/3829 440/3829 450/3829 460/3829 470/3829 480/3829 490/3829 500/3829 510/3829 520/3829 530/3829 540/3829 \n",
            "550/3829 560/3829 570/3829 580/3829 590/3829 600/3829 610/3829 620/3829 630/3829 640/3829 650/3829 660/3829 670/3829 680/3829 690/3829 700/3829 710/3829 720/3829 730/3829 740/3829 750/3829 760/3829 770/3829 780/3829 790/3829 800/3829 810/3829 \n",
            "820/3829 830/3829 840/3829 850/3829 860/3829 870/3829 880/3829 890/3829 900/3829 910/3829 920/3829 930/3829 940/3829 950/3829 960/3829 970/3829 980/3829 990/3829 1000/3829 1010/3829 1020/3829 1030/3829 1040/3829 1050/3829 1060/3829 1070/3829 1080/3829 \n",
            "1090/3829 1100/3829 1110/3829 1120/3829 1130/3829 1140/3829 1150/3829 1160/3829 1170/3829 1180/3829 1190/3829 1200/3829 1210/3829 1220/3829 1230/3829 1240/3829 1250/3829 1260/3829 1270/3829 1280/3829 1290/3829 1300/3829 1310/3829 1320/3829 1330/3829 1340/3829 1350/3829 \n",
            "1360/3829 1370/3829 1380/3829 1390/3829 1400/3829 1410/3829 1420/3829 1430/3829 1440/3829 1450/3829 1460/3829 1470/3829 1480/3829 1490/3829 1500/3829 1510/3829 1520/3829 1530/3829 1540/3829 1550/3829 1560/3829 1570/3829 1580/3829 1590/3829 1600/3829 1610/3829 1620/3829 \n",
            "1630/3829 1640/3829 1650/3829 1660/3829 1670/3829 1680/3829 1690/3829 1700/3829 1710/3829 1720/3829 1730/3829 1740/3829 1750/3829 1760/3829 1770/3829 1780/3829 1790/3829 1800/3829 1810/3829 1820/3829 1830/3829 1840/3829 1850/3829 1860/3829 1870/3829 1880/3829 1890/3829 \n",
            "1900/3829 1910/3829 1920/3829 1930/3829 1940/3829 1950/3829 1960/3829 1970/3829 1980/3829 1990/3829 2000/3829 2010/3829 2020/3829 2030/3829 2040/3829 2050/3829 2060/3829 2070/3829 2080/3829 2090/3829 2100/3829 2110/3829 2120/3829 2130/3829 2140/3829 2150/3829 2160/3829 \n",
            "2170/3829 2180/3829 2190/3829 2200/3829 2210/3829 2220/3829 2230/3829 2240/3829 2250/3829 2260/3829 2270/3829 2280/3829 2290/3829 2300/3829 2310/3829 2320/3829 2330/3829 2340/3829 2350/3829 2360/3829 2370/3829 2380/3829 2390/3829 2400/3829 2410/3829 2420/3829 2430/3829 \n",
            "2440/3829 2450/3829 2460/3829 2470/3829 2480/3829 2490/3829 2500/3829 2510/3829 2520/3829 2530/3829 2540/3829 2550/3829 2560/3829 2570/3829 2580/3829 2590/3829 2600/3829 2610/3829 2620/3829 2630/3829 2640/3829 2650/3829 2660/3829 2670/3829 2680/3829 2690/3829 2700/3829 \n",
            "2710/3829 2720/3829 2730/3829 2740/3829 2750/3829 2760/3829 2770/3829 2780/3829 2790/3829 2800/3829 2810/3829 2820/3829 2830/3829 2840/3829 2850/3829 2860/3829 2870/3829 2880/3829 2890/3829 2900/3829 2910/3829 2920/3829 2930/3829 2940/3829 2950/3829 2960/3829 2970/3829 \n",
            "2980/3829 2990/3829 3000/3829 3010/3829 3020/3829 3030/3829 3040/3829 3050/3829 3060/3829 3070/3829 3080/3829 3090/3829 3100/3829 3110/3829 3120/3829 3130/3829 3140/3829 3150/3829 3160/3829 3170/3829 3180/3829 3190/3829 3200/3829 3210/3829 3220/3829 3230/3829 3240/3829 \n",
            "3250/3829 3260/3829 3270/3829 3280/3829 3290/3829 3300/3829 3310/3829 3320/3829 3330/3829 3340/3829 3350/3829 3360/3829 3370/3829 3380/3829 3390/3829 3400/3829 3410/3829 3420/3829 3430/3829 3440/3829 3450/3829 3460/3829 3470/3829 3480/3829 3490/3829 3500/3829 3510/3829 \n",
            "3520/3829 3530/3829 3540/3829 3550/3829 3560/3829 3570/3829 3580/3829 3590/3829 3600/3829 3610/3829 3620/3829 3630/3829 3640/3829 3650/3829 3660/3829 3670/3829 3680/3829 3690/3829 3700/3829 3710/3829 3720/3829 3730/3829 3740/3829 3750/3829 3760/3829 3770/3829 3780/3829 \n",
            "3790/3829 3800/3829 3810/3829 3820/3829 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22494"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "how_many_future_candles = 5\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 80\n",
        "\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpQvhf-pwpR",
        "outputId": "ff0d7f31-bac8-4d26-a6bf-fc3cac12240e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22494, 128, 128)\n",
            "xTrain : 17995 \\ xTest : 4499\n",
            "yn: 11239 nn: 11255\n"
          ]
        }
      ],
      "source": [
        "folder_name = \"162812\"\n",
        "\n",
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(f\"/content/{folder_name}.zip\",f\"/content/extracted/{folder_name}\")\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjRn1rKTEFSH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(xTest,yTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9stbJK8Nx_0c",
        "outputId": "17ade938-e6bd-4375-a122-1f8028fbee41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 126, 126, 128)     1280      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 63, 63, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 61, 61, 100)       115300    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 30, 30, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 32)        28832     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 800)               20071200  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 800)               640800    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 800)               640800    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 800)               640800    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 1602      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,140,614\n",
            "Trainable params: 22,140,614\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128,   (3,3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1), kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(100,   (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32,    (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(800,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.0002)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytWxowTyInc",
        "outputId": "04f5df1c-b52c-4e6c-ac91-79f7ccb0705e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "563/563 [==============================] - 34s 58ms/step - loss: 0.8010 - accuracy: 0.5120 - val_loss: 0.7770 - val_accuracy: 0.5234\n",
            "Epoch 2/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.7562 - accuracy: 0.5734 - val_loss: 0.7355 - val_accuracy: 0.6010\n",
            "Epoch 3/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.6991 - accuracy: 0.6510 - val_loss: 0.6854 - val_accuracy: 0.6610\n",
            "Epoch 4/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.5661 - accuracy: 0.7609 - val_loss: 0.6176 - val_accuracy: 0.7362\n",
            "Epoch 5/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.3907 - accuracy: 0.8603 - val_loss: 0.5928 - val_accuracy: 0.7682\n",
            "Epoch 6/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.2549 - accuracy: 0.9240 - val_loss: 0.6301 - val_accuracy: 0.7699\n",
            "Epoch 7/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.1603 - accuracy: 0.9634 - val_loss: 0.7332 - val_accuracy: 0.7806\n",
            "Epoch 8/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.1070 - accuracy: 0.9827 - val_loss: 0.8776 - val_accuracy: 0.7777\n",
            "Epoch 9/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.0778 - accuracy: 0.9922 - val_loss: 1.0431 - val_accuracy: 0.7826\n",
            "Epoch 10/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.0678 - accuracy: 0.9950 - val_loss: 1.1064 - val_accuracy: 0.7842\n",
            "Epoch 11/50\n",
            "563/563 [==============================] - 32s 57ms/step - loss: 0.0596 - accuracy: 0.9976 - val_loss: 1.2688 - val_accuracy: 0.7828\n",
            "Epoch 12/50\n",
            "486/563 [========================>.....] - ETA: 4s - loss: 0.0579 - accuracy: 0.9977"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=50,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUhFkNfwDtr"
      },
      "outputs": [],
      "source": [
        "model.save(f\"1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz7BAj5wwlN"
      },
      "outputs": [],
      "source": [
        "symbol,period,interval=\"btc-usd\",\"10d\",\"5m\"\n",
        "data = yf.download(tickers=symbol,period=period,interval=interval)\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "data = data.astype(float)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, :]\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb2r1l8yB-0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8nJ2wI-ynZw"
      },
      "outputs": [],
      "source": [
        "tv = TvDatafeed()\n",
        "data = tv.get_hist(symbol=\"btcusdt\",exchange=\"binance\",interval=Interval.in_5_minute,n_bars=1000)\n",
        "data = np.array(data)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, 1:5]\n",
        "rows.shape\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpTFxbUd5mXt"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture1.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7lUM_NBNxj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WBt2p6M86D"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "while True:\n",
        "  ans = input()\n",
        "  if ans == \"exit\":\n",
        "    break\n",
        "  lst.append(int(ans))\n",
        "print(sum(max),len(lst))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "G29_5.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
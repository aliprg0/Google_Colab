{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "f5df1c4b-f4e7-4f3f-aff0-a1ae34373dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 18.9 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 25.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 53.9 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.10 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/twopirllc/pandas-ta\n",
            "  Cloning https://github.com/twopirllc/pandas-ta to /tmp/pip-req-build-6f5u7tk4\n",
            "  Running command git clone -q https://github.com/twopirllc/pandas-ta /tmp/pip-req-build-6f5u7tk4\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas-ta==0.3.14b0) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas-ta==0.3.14b0) (1.15.0)\n",
            "Building wheels for collected packages: pandas-ta\n",
            "  Building wheel for pandas-ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=219766 sha256=036d173328afe02758ea10ba5f01e87646ebbec2f45847cb3ff30917871c77de\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k7rqvts8/wheels/2d/b0/97/98814700c6859229dac6f4c0b1bc1546331add62e7f6c9bf15\n",
            "Successfully built pandas-ta\n",
            "Installing collected packages: pandas-ta\n",
            "Successfully installed pandas-ta-0.3.14b0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade mplfinance\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "!pip install -U git+https://github.com/twopirllc/pandas-ta\n",
        "import pandas_ta as pta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "\n",
        "\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "\n",
        "\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "\n",
        "\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "\n",
        "\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    data = data.dropna()\n",
        "    dfs = []\n",
        "    suggs = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data[\"6_rsi\"] =  pta.rsi(data['Close'], length = 6)\n",
        "    data[\"14_rsi\"] = pta.rsi(data['Close'], length = 14)\n",
        "    data[\"26_rsi\"] = pta.rsi(data['Close'], length = 26)\n",
        "    data[\"52_rsi\"] = pta.rsi(data['Close'], length = 52)\n",
        "\n",
        "    # drop Adj Close and Volume\n",
        "    data.drop(columns=['Adj Close', 'Volume'], inplace=True)\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    for i in range(each_row_past, data.shape[0]-which_future_or_past):\n",
        "\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "        past_candles = []\n",
        "        for z in range(1, how_many_past_candles+1):\n",
        "          past_candles.append((data[i-z][3]+data[i-z][0])/2)\n",
        "        past_candles = sum(past_candles)/len(past_candles)\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append((data[i+z][3]+data[i+z][0])/2)\n",
        "        next_candles = sum(next_candles)/len(next_candles)\n",
        "        if next_candles > past_candles:\n",
        "          suggs.append(1)\n",
        "        else:\n",
        "          suggs.append(0)\n",
        "\n",
        "        x = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"6_rsi\", \"14_rsi\", \"26_rsi\",\"52_rsi\"])\n",
        "        del rows\n",
        "        del next_candles\n",
        "        dfs.append(x)\n",
        "        del x\n",
        "    del data\n",
        "\n",
        "    index = 0\n",
        "    all_n = np.array(dfs).shape[0]\n",
        "    for df in dfs:\n",
        "        date_list = []\n",
        "        rrng = np.array(df).shape[0]\n",
        "        for i in range(rrng):\n",
        "            date_list.append(datetime.fromordinal(\n",
        "                datetime.today().toordinal()+i).strftime('%Y-%m-%d'))\n",
        "        df.index = date_list\n",
        "        df.index.name = \"Date\"\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{suggs[index]}.png\"\n",
        "        \n",
        "        #apds = [ \n",
        "        # mpl.make_addplot(df[\"6_rsi\"],color='b',width=1),\n",
        "        # mpl.make_addplot(df[\"14_rsi\"],color='g',width=1),\n",
        "        # mpl.make_addplot(df[\"26_rsi\"],color='r',width=1),\n",
        "        # mpl.make_addplot(df[\"52_rsi\"],color='y',width=1),\n",
        "       #]\n",
        "\n",
        "\n",
        "        mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            savefig=address, tight_layout=True,figsize =(4,3))\n",
        "        \n",
        "        plt.close(\"all\")\n",
        "        del df\n",
        "        del date_list\n",
        "        del rrng\n",
        "        del i\n",
        "        del right_now\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "        index = index + 1\n",
        "        if index % 10 == 0:\n",
        "            print(f\"{index}/{all_n}\", end=\" \")\n",
        "        if index % 160 == 0:\n",
        "          print(\" \")\n",
        "\n",
        "    print(\"\")\n",
        "    del dfs\n",
        "    del suggs\n",
        "    del index\n",
        "    del all_n\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "e29a8969-53f6-4377-e661-68d65aa5c5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "#symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\",\"FTT-USD\"]\n",
        "symbols = [\"btc-usd\"]\n",
        "download_data(symbols,\"100d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "076ce14d-6101-4666-9dd2-62a6744f6a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 1\n",
            "Processing File:\n",
            "File Number 1: 10/2291 20/2291 30/2291 40/2291 50/2291 60/2291 70/2291 80/2291 90/2291 100/2291 110/2291 120/2291 130/2291 140/2291 150/2291 160/2291  \n",
            "170/2291 180/2291 190/2291 200/2291 210/2291 220/2291 230/2291 240/2291 250/2291 260/2291 270/2291 280/2291 290/2291 300/2291 310/2291 320/2291  \n",
            "330/2291 340/2291 350/2291 360/2291 370/2291 380/2291 390/2291 400/2291 410/2291 420/2291 430/2291 440/2291 450/2291 460/2291 470/2291 480/2291  \n",
            "490/2291 500/2291 510/2291 520/2291 530/2291 540/2291 550/2291 560/2291 570/2291 580/2291 590/2291 600/2291 610/2291 620/2291 630/2291 640/2291  \n",
            "650/2291 660/2291 670/2291 680/2291 690/2291 700/2291 710/2291 720/2291 730/2291 740/2291 750/2291 760/2291 770/2291 780/2291 790/2291 800/2291  \n",
            "810/2291 820/2291 830/2291 840/2291 850/2291 860/2291 870/2291 880/2291 890/2291 900/2291 910/2291 920/2291 930/2291 940/2291 950/2291 960/2291  \n",
            "970/2291 980/2291 990/2291 1000/2291 1010/2291 1020/2291 1030/2291 1040/2291 1050/2291 1060/2291 1070/2291 1080/2291 1090/2291 1100/2291 1110/2291 1120/2291  \n",
            "1130/2291 1140/2291 1150/2291 1160/2291 1170/2291 1180/2291 1190/2291 1200/2291 1210/2291 1220/2291 1230/2291 1240/2291 1250/2291 1260/2291 1270/2291 1280/2291  \n",
            "1290/2291 1300/2291 1310/2291 1320/2291 1330/2291 1340/2291 1350/2291 1360/2291 1370/2291 1380/2291 1390/2291 1400/2291 1410/2291 1420/2291 1430/2291 1440/2291  \n",
            "1450/2291 1460/2291 1470/2291 1480/2291 1490/2291 1500/2291 1510/2291 1520/2291 1530/2291 1540/2291 1550/2291 1560/2291 1570/2291 1580/2291 1590/2291 1600/2291  \n",
            "1610/2291 1620/2291 1630/2291 1640/2291 1650/2291 1660/2291 1670/2291 1680/2291 1690/2291 1700/2291 1710/2291 1720/2291 1730/2291 1740/2291 1750/2291 1760/2291  \n",
            "1770/2291 1780/2291 1790/2291 1800/2291 1810/2291 1820/2291 1830/2291 1840/2291 1850/2291 1860/2291 1870/2291 1880/2291 1890/2291 1900/2291 1910/2291 1920/2291  \n",
            "1930/2291 1940/2291 1950/2291 1960/2291 1970/2291 1980/2291 1990/2291 2000/2291 2010/2291 2020/2291 2030/2291 2040/2291 2050/2291 2060/2291 2070/2291 2080/2291  \n",
            "2090/2291 2100/2291 2110/2291 2120/2291 2130/2291 2140/2291 2150/2291 2160/2291 2170/2291 2180/2291 2190/2291 2200/2291 2210/2291 2220/2291 2230/2291 2240/2291  \n",
            "2250/2291 2260/2291 2270/2291 2280/2291 2290/2291 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2291"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "how_many_future_candles = 5\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 90\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dQpQvhf-pwpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccc9371-f8d6-4be5-c563-50f0feff0b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2291, 128, 256, 3)\n",
            "xTrain : 1832 \\ xTest : 459\n",
            "yn: 1109 nn: 1182\n"
          ]
        }
      ],
      "source": [
        "#folder_name = '122227'\n",
        "\n",
        "\n",
        "\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name)\n",
        "    dim = (256, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59effce-0f6a-451a-ba5b-776071bcf5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 125, 253, 64)      3136      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 62, 126, 64)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 60, 124, 100)      57700     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 30, 62, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 60, 200)       180200    \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 30, 200)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 13, 29, 128)       102528    \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 6, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 10752)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              11011072  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,505,486\n",
            "Trainable params: 14,505,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,    (4, 4),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(100,   (3, 3),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(200,   (3, 3),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128,   (2, 2),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytWxowTyInc",
        "outputId": "faf5688c-9751-46ec-8185-fbcefff4f0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "58/58 [==============================] - 198s 3s/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 1.0681 - val_accuracy: 0.7865\n",
            "Epoch 2/20\n",
            "58/58 [==============================] - 239s 4s/step - loss: 9.0653e-04 - accuracy: 1.0000 - val_loss: 1.2205 - val_accuracy: 0.7887\n",
            "Epoch 3/20\n",
            "58/58 [==============================] - 195s 3s/step - loss: 2.0945e-04 - accuracy: 1.0000 - val_loss: 1.3894 - val_accuracy: 0.7887\n",
            "Epoch 4/20\n",
            "58/58 [==============================] - 193s 3s/step - loss: 8.2700e-05 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.7843\n",
            "Epoch 5/20\n",
            "58/58 [==============================] - 193s 3s/step - loss: 4.2710e-05 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.7843\n",
            "Epoch 6/20\n",
            "58/58 [==============================] - 195s 3s/step - loss: 2.4283e-05 - accuracy: 1.0000 - val_loss: 1.6795 - val_accuracy: 0.7843\n",
            "Epoch 7/20\n",
            "58/58 [==============================] - 198s 3s/step - loss: 1.5190e-05 - accuracy: 1.0000 - val_loss: 1.7438 - val_accuracy: 0.7843\n",
            "Epoch 8/20\n",
            "58/58 [==============================] - 197s 3s/step - loss: 9.9906e-06 - accuracy: 1.0000 - val_loss: 1.8092 - val_accuracy: 0.7887\n",
            "Epoch 9/20\n",
            "58/58 [==============================] - 196s 3s/step - loss: 6.9021e-06 - accuracy: 1.0000 - val_loss: 1.8518 - val_accuracy: 0.7865\n",
            "Epoch 10/20\n",
            "58/58 [==============================] - 197s 3s/step - loss: 4.9829e-06 - accuracy: 1.0000 - val_loss: 1.9008 - val_accuracy: 0.7865\n",
            "Epoch 11/20\n",
            "58/58 [==============================] - 217s 4s/step - loss: 3.6569e-06 - accuracy: 1.0000 - val_loss: 1.9506 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "58/58 [==============================] - 223s 4s/step - loss: 2.8606e-06 - accuracy: 1.0000 - val_loss: 1.9803 - val_accuracy: 0.7887\n",
            "Epoch 13/20\n",
            "58/58 [==============================] - 196s 3s/step - loss: 2.2284e-06 - accuracy: 1.0000 - val_loss: 2.0122 - val_accuracy: 0.7887\n",
            "Epoch 14/20\n",
            "58/58 [==============================] - 196s 3s/step - loss: 1.7953e-06 - accuracy: 1.0000 - val_loss: 2.0444 - val_accuracy: 0.7887\n",
            "Epoch 15/20\n",
            "58/58 [==============================] - 197s 3s/step - loss: 1.4746e-06 - accuracy: 1.0000 - val_loss: 2.0722 - val_accuracy: 0.7887\n",
            "Epoch 16/20\n",
            "58/58 [==============================] - 195s 3s/step - loss: 1.2351e-06 - accuracy: 1.0000 - val_loss: 2.1054 - val_accuracy: 0.7887\n",
            "Epoch 17/20\n",
            "58/58 [==============================] - 200s 3s/step - loss: 1.0298e-06 - accuracy: 1.0000 - val_loss: 2.1243 - val_accuracy: 0.7887\n",
            "Epoch 18/20\n",
            "58/58 [==============================] - 195s 3s/step - loss: 8.6217e-07 - accuracy: 1.0000 - val_loss: 2.1475 - val_accuracy: 0.7887\n",
            "Epoch 19/20\n",
            "58/58 [==============================] - 198s 3s/step - loss: 7.3984e-07 - accuracy: 1.0000 - val_loss: 2.1728 - val_accuracy: 0.7887\n",
            "Epoch 20/20\n",
            "58/58 [==============================] - 202s 3s/step - loss: 6.3469e-07 - accuracy: 1.0000 - val_loss: 2.1943 - val_accuracy: 0.7887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3590dc5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=20,validation_data=(xTest,yTest))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "90norsisimp.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
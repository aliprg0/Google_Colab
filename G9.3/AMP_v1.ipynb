{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMP-v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ukj6TwL1RR7o0J06LHyTJgSztw_-BUZv",
      "authorship_tag": "ABX9TyOAh2sI7hmNymW8wu8cZt0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliprg0/Google_Colab/blob/main/AMP_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj8dgmU2y8UK",
        "outputId": "21106a0f-dc76-44b9-9da6-9253f9e29385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 18.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row"
      ],
      "metadata": {
        "id": "eTgWNpTo-n8K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Monthly-3\n",
        "model = load_model(\"/content/drive/MyDrive/Exported Models/monthly_crypto_96_xbv85.h5\")\n",
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "    \n",
        "    s1 = np.delete(s1, 1)\n",
        "    s1 = np.delete(s1, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s2 = np.delete(s2, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s3 = np.delete(s3, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s4 = np.delete(s4, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s5 = np.delete(s5, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s6 = np.delete(s6, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s7 = np.delete(s7, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s8 = np.delete(s8, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s9 = np.delete(s9, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s10 = np.delete(s10, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s11 = np.delete(s11, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "    s12 = np.delete(s12, 1)\n",
        "            \n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ],
      "metadata": {
        "id": "hqQUOpMA__FY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"btc-usd\",\"15m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wD6NMxoAXx7",
        "outputId": "5f93fbf8-0672-4d97-9fa8-afc75eb6efaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99454117, 0.00664738]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cfm weeky 94\n",
        "model = load_model(\"/content/drive/MyDrive/Exported Models/weekly_crypto_94_jako6.h5\")\n",
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "\n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ],
      "metadata": {
        "id": "GevlZrRxCTHv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"btc-usd\",\"15m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3USxxzkcCaxd",
        "outputId": "596f5d02-ec9f-43e8-a979-2479380707e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40865934, 0.6182919 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 4]\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "\n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcusd',exchange='bitstamp',interval=Interval.in_15_minute,n_bars=30)\n",
        "   return model.predict(process_for_prediction(data))"
      ],
      "metadata": {
        "id": "EVrjptvzCb9l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"s\",\"x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJLzCOd1CeHl",
        "outputId": "79a76499-531c-45be-f53a-07d0d79e23b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "do you want to install chromedriver automatically?? y/n\tn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0420551e-04, 9.9993336e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yf.download(\"btc-usd\",period=\"1d\",interval=\"15m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "uaoveitrUkv4",
        "outputId": "4255edab-c76f-46f0-a4b9-975a43948993"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Open          High           Low  \\\n",
              "Datetime                                                              \n",
              "2022-04-29 00:00:00+00:00  39768.617188  39817.078125  39744.535156   \n",
              "2022-04-29 00:15:00+00:00  39815.914062  39830.531250  39807.500000   \n",
              "2022-04-29 00:30:00+00:00  39776.433594  39776.433594  39730.691406   \n",
              "2022-04-29 00:45:00+00:00  39726.808594  39777.898438  39704.660156   \n",
              "2022-04-29 01:00:00+00:00  39815.343750  39836.285156  39815.343750   \n",
              "...                                 ...           ...           ...   \n",
              "2022-04-29 16:15:00+00:00  38958.882812  38971.187500  38938.316406   \n",
              "2022-04-29 16:30:00+00:00  38991.167969  39019.707031  38763.730469   \n",
              "2022-04-29 16:45:00+00:00  38636.363281  38659.097656  38561.082031   \n",
              "2022-04-29 17:00:00+00:00  38547.824219  38547.824219  38547.824219   \n",
              "2022-04-29 17:03:00+00:00  38579.222656  38579.222656  38579.222656   \n",
              "\n",
              "                                  Close     Adj Close     Volume  \n",
              "Datetime                                                          \n",
              "2022-04-29 00:00:00+00:00  39817.078125  39817.078125  139550720  \n",
              "2022-04-29 00:15:00+00:00  39807.500000  39807.500000  214714368  \n",
              "2022-04-29 00:30:00+00:00  39730.691406  39730.691406   20400128  \n",
              "2022-04-29 00:45:00+00:00  39777.898438  39777.898438   83261440  \n",
              "2022-04-29 01:00:00+00:00  39834.808594  39834.808594   42944512  \n",
              "...                                 ...           ...        ...  \n",
              "2022-04-29 16:15:00+00:00  38971.187500  38971.187500   14114816  \n",
              "2022-04-29 16:30:00+00:00  38763.730469  38763.730469  210741248  \n",
              "2022-04-29 16:45:00+00:00  38561.082031  38561.082031  124655616  \n",
              "2022-04-29 17:00:00+00:00  38547.824219  38547.824219    2934784  \n",
              "2022-04-29 17:03:00+00:00  38579.222656  38579.222656          0  \n",
              "\n",
              "[70 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43c9b8d5-fd41-4c07-9722-67a939d70577\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:00:00+00:00</th>\n",
              "      <td>39768.617188</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>39744.535156</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>139550720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:15:00+00:00</th>\n",
              "      <td>39815.914062</td>\n",
              "      <td>39830.531250</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>214714368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:30:00+00:00</th>\n",
              "      <td>39776.433594</td>\n",
              "      <td>39776.433594</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>20400128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:45:00+00:00</th>\n",
              "      <td>39726.808594</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>39704.660156</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>83261440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 01:00:00+00:00</th>\n",
              "      <td>39815.343750</td>\n",
              "      <td>39836.285156</td>\n",
              "      <td>39815.343750</td>\n",
              "      <td>39834.808594</td>\n",
              "      <td>39834.808594</td>\n",
              "      <td>42944512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 16:15:00+00:00</th>\n",
              "      <td>38958.882812</td>\n",
              "      <td>38971.187500</td>\n",
              "      <td>38938.316406</td>\n",
              "      <td>38971.187500</td>\n",
              "      <td>38971.187500</td>\n",
              "      <td>14114816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 16:30:00+00:00</th>\n",
              "      <td>38991.167969</td>\n",
              "      <td>39019.707031</td>\n",
              "      <td>38763.730469</td>\n",
              "      <td>38763.730469</td>\n",
              "      <td>38763.730469</td>\n",
              "      <td>210741248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 16:45:00+00:00</th>\n",
              "      <td>38636.363281</td>\n",
              "      <td>38659.097656</td>\n",
              "      <td>38561.082031</td>\n",
              "      <td>38561.082031</td>\n",
              "      <td>38561.082031</td>\n",
              "      <td>124655616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 17:00:00+00:00</th>\n",
              "      <td>38547.824219</td>\n",
              "      <td>38547.824219</td>\n",
              "      <td>38547.824219</td>\n",
              "      <td>38547.824219</td>\n",
              "      <td>38547.824219</td>\n",
              "      <td>2934784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 17:03:00+00:00</th>\n",
              "      <td>38579.222656</td>\n",
              "      <td>38579.222656</td>\n",
              "      <td>38579.222656</td>\n",
              "      <td>38579.222656</td>\n",
              "      <td>38579.222656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43c9b8d5-fd41-4c07-9722-67a939d70577')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43c9b8d5-fd41-4c07-9722-67a939d70577 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43c9b8d5-fd41-4c07-9722-67a939d70577');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
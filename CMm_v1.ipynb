{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5bxbCoe9do9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0d95ee-97c9-4535-8381-9c336695f67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 819 kB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "    \"Open 12-11\",\"Open 11-10\",\"Open 10-9\",\"Open 9-8\",\"Open 8-7\",\"Open 7-6\",\"Open 6-5\",\"Open 5-4\",\"Open 4-3\",\"Open 3-2\",\"Open 2-1\",\n",
        "    \"Close 12-11\",\"Close 11-10\",\"Close 10-9\",\"Close 9-8\",\"Close 8-7\",\"Close 7-6\",\"Close 6-5\",\"Close 5-4\",\"Close 4-3\",\"Close 3-2\",\"Close 2-1\",\n",
        "    \"High 12-11\",\"High 11-10\",\"High 10-9\",\"High 9-8\",\"High 8-7\",\"High 7-6\",\"High 6-5\",\"High 5-4\",\"High 4-3\",\"High 3-2\",\"High 2-1\",\n",
        "    \"Low 12-11\",\"Low 11-10\",\"Low 10-9\",\"Low 9-8\",\"Low 8-7\",\"Low 7-6\",\"Low 6-5\",\"Low 5-4\",\"Low 4-3\",\"Low 3-2\",\"Low 2-1\",\n",
        "    \"Volume 12-11\",\"Volume 11-10\",\"Volume 10-9\",\"Volume 9-8\",\"Volume 8-7\",\"Volume 7-6\",\"Volume 6-5\",\"Volume 5-4\",\"Volume 4-3\",\"Volume 3-2\",\"Volume 2-1\",\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 5]\n",
        "    for i in range(12, data.shape[0]):\n",
        "        grow = []\n",
        "        srow = []\n",
        "\n",
        "        for j in llst:\n",
        "           srow.append([\n",
        "               data[i-1][j] - data[i-2][j],\n",
        "               data[i-2][j] - data[i-3][j],\n",
        "               data[i-3][j] - data[i-4][j],\n",
        "               data[i-4][j] - data[i-5][j],\n",
        "               data[i-5][j] - data[i-6][j],\n",
        "               data[i-6][j] - data[i-7][j],\n",
        "               data[i-7][j] - data[i-8][j],\n",
        "               data[i-8][j] - data[i-9][j],\n",
        "               data[i-9][j] - data[i-10][j],\n",
        "               data[i-10][j] - data[i-11][j],\n",
        "               data[i-11][j] - data[i-12][j]\n",
        "           ])\n",
        "\n",
        "        for lst in srow:\n",
        "            mm = np.array(lst)\n",
        "            mm = np.reshape(mm, (-1, 1))\n",
        "            grow.append(scaler(mm))\n",
        "\n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i][0]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  \n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 12:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "             \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        unattached_dfs.append(process(pd.read_csv(address)))\n",
        "     data = np.array(unattached_dfs[0])\n",
        "     for i in unattached_dfs[1:]:\n",
        "           data = np.append(data, np.array(i), axis=0)\n",
        "        \n",
        "     unattached_dfs = []\n",
        "  \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ],
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "hIAuU_ILbU27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fdf43e-0b8f-42c3-e865-e46911cd12a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 3\n",
            "Data Folder Removed\n",
            " \n",
            "Files In Data : 3\n",
            "Processing File:\n",
            "1 2 3  \n",
            "(495, 57)\n",
            "(396, 55) (396, 2)\n",
            "(99, 55) (99, 2)\n"
          ]
        }
      ],
      "source": [
        "#symbols = get_crypto_syms()\n",
        "#symbols = read_txt_list()\n",
        "#symbols = read_syms_from_txt()\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\"]\n",
        "\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"1d\",\"5m\")\n",
        "folder_name = extract_data(1)\n",
        "to_par(folder_name,1)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "id": "xN93WT9e8ueQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc8e73b-8194-416d-a129-91a315926244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 128)               7168      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,962\n",
            "Trainable params: 56,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "_SBxPzRd89uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6badd800-ee52-4c2a-ede3-a924b34a9375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 0.7032 - accuracy: 0.5253 - val_loss: 0.6960 - val_accuracy: 0.5354\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6465 - val_loss: 0.6935 - val_accuracy: 0.5657\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7020 - val_loss: 0.6868 - val_accuracy: 0.5556\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7424 - val_loss: 0.6812 - val_accuracy: 0.5758\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7727 - val_loss: 0.6806 - val_accuracy: 0.6162\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8106 - val_loss: 0.6873 - val_accuracy: 0.6263\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8510 - val_loss: 0.7074 - val_accuracy: 0.6263\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8889 - val_loss: 0.7398 - val_accuracy: 0.6364\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.9318 - val_loss: 0.7917 - val_accuracy: 0.5960\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9596 - val_loss: 0.8540 - val_accuracy: 0.5859\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9773 - val_loss: 0.9314 - val_accuracy: 0.5758\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9924 - val_loss: 1.0203 - val_accuracy: 0.5758\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9949 - val_loss: 1.1168 - val_accuracy: 0.5657\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9975 - val_loss: 1.2171 - val_accuracy: 0.5758\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.6061\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.5960\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.5859\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.5876 - val_accuracy: 0.5657\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.5657\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.8648 - val_accuracy: 0.5758\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.5556\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.1029 - val_accuracy: 0.6061\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.1887 - val_accuracy: 0.6061\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.0711 - val_accuracy: 0.6061\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.9954 - val_accuracy: 0.6061\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.8863 - val_accuracy: 0.6162\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.8994 - val_accuracy: 0.5960\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8841 - val_accuracy: 0.5960\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 9.8716e-04 - accuracy: 1.0000 - val_loss: 1.9043 - val_accuracy: 0.5960\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 8.4748e-04 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.5960\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 7.6188e-04 - accuracy: 1.0000 - val_loss: 1.9445 - val_accuracy: 0.5960\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6.9661e-04 - accuracy: 1.0000 - val_loss: 1.9625 - val_accuracy: 0.5960\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6.4216e-04 - accuracy: 1.0000 - val_loss: 1.9801 - val_accuracy: 0.5960\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9494e-04 - accuracy: 1.0000 - val_loss: 1.9968 - val_accuracy: 0.5960\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.5325e-04 - accuracy: 1.0000 - val_loss: 2.0131 - val_accuracy: 0.5960\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.1629e-04 - accuracy: 1.0000 - val_loss: 2.0289 - val_accuracy: 0.5960\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.8280e-04 - accuracy: 1.0000 - val_loss: 2.0445 - val_accuracy: 0.5960\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.5231e-04 - accuracy: 1.0000 - val_loss: 2.0599 - val_accuracy: 0.6061\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.2447e-04 - accuracy: 1.0000 - val_loss: 2.0749 - val_accuracy: 0.6061\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.9901e-04 - accuracy: 1.0000 - val_loss: 2.0896 - val_accuracy: 0.6061\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.7558e-04 - accuracy: 1.0000 - val_loss: 2.1039 - val_accuracy: 0.6061\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.5406e-04 - accuracy: 1.0000 - val_loss: 2.1180 - val_accuracy: 0.6061\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.3409e-04 - accuracy: 1.0000 - val_loss: 2.1320 - val_accuracy: 0.6061\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.1553e-04 - accuracy: 1.0000 - val_loss: 2.1456 - val_accuracy: 0.6061\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.9826e-04 - accuracy: 1.0000 - val_loss: 2.1591 - val_accuracy: 0.6061\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.8217e-04 - accuracy: 1.0000 - val_loss: 2.1724 - val_accuracy: 0.5960\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.6706e-04 - accuracy: 1.0000 - val_loss: 2.1856 - val_accuracy: 0.5960\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.5292e-04 - accuracy: 1.0000 - val_loss: 2.1987 - val_accuracy: 0.5960\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.3969e-04 - accuracy: 1.0000 - val_loss: 2.2118 - val_accuracy: 0.5960\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.2724e-04 - accuracy: 1.0000 - val_loss: 2.2247 - val_accuracy: 0.5960\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.1560e-04 - accuracy: 1.0000 - val_loss: 2.2373 - val_accuracy: 0.5960\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.0458e-04 - accuracy: 1.0000 - val_loss: 2.2499 - val_accuracy: 0.5960\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.9424e-04 - accuracy: 1.0000 - val_loss: 2.2624 - val_accuracy: 0.5960\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.8452e-04 - accuracy: 1.0000 - val_loss: 2.2746 - val_accuracy: 0.5960\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.7533e-04 - accuracy: 1.0000 - val_loss: 2.2869 - val_accuracy: 0.5960\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.6661e-04 - accuracy: 1.0000 - val_loss: 2.2991 - val_accuracy: 0.5960\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.5842e-04 - accuracy: 1.0000 - val_loss: 2.3112 - val_accuracy: 0.5960\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.5064e-04 - accuracy: 1.0000 - val_loss: 2.3232 - val_accuracy: 0.5960\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.4327e-04 - accuracy: 1.0000 - val_loss: 2.3354 - val_accuracy: 0.5960\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.3632e-04 - accuracy: 1.0000 - val_loss: 2.3472 - val_accuracy: 0.5960\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.2972e-04 - accuracy: 1.0000 - val_loss: 2.3590 - val_accuracy: 0.5960\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.2346e-04 - accuracy: 1.0000 - val_loss: 2.3707 - val_accuracy: 0.5960\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1753e-04 - accuracy: 1.0000 - val_loss: 2.3827 - val_accuracy: 0.5960\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1187e-04 - accuracy: 1.0000 - val_loss: 2.3945 - val_accuracy: 0.5960\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0653e-04 - accuracy: 1.0000 - val_loss: 2.4060 - val_accuracy: 0.5960\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0143e-04 - accuracy: 1.0000 - val_loss: 2.4179 - val_accuracy: 0.5960\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 9.6600e-05 - accuracy: 1.0000 - val_loss: 2.4295 - val_accuracy: 0.5960\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 9.2003e-05 - accuracy: 1.0000 - val_loss: 2.4414 - val_accuracy: 0.5960\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 8.7650e-05 - accuracy: 1.0000 - val_loss: 2.4531 - val_accuracy: 0.5960\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 8.3496e-05 - accuracy: 1.0000 - val_loss: 2.4647 - val_accuracy: 0.5960\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 7.9550e-05 - accuracy: 1.0000 - val_loss: 2.4762 - val_accuracy: 0.5960\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 7.5795e-05 - accuracy: 1.0000 - val_loss: 2.4878 - val_accuracy: 0.5960\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 7.2237e-05 - accuracy: 1.0000 - val_loss: 2.4994 - val_accuracy: 0.5960\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6.8838e-05 - accuracy: 1.0000 - val_loss: 2.5110 - val_accuracy: 0.5960\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6.5622e-05 - accuracy: 1.0000 - val_loss: 2.5226 - val_accuracy: 0.5960\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6.2534e-05 - accuracy: 1.0000 - val_loss: 2.5340 - val_accuracy: 0.5960\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9621e-05 - accuracy: 1.0000 - val_loss: 2.5455 - val_accuracy: 0.5960\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.6823e-05 - accuracy: 1.0000 - val_loss: 2.5569 - val_accuracy: 0.5960\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.4180e-05 - accuracy: 1.0000 - val_loss: 2.5685 - val_accuracy: 0.5960\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 5.1650e-05 - accuracy: 1.0000 - val_loss: 2.5800 - val_accuracy: 0.5960\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.9251e-05 - accuracy: 1.0000 - val_loss: 2.5913 - val_accuracy: 0.5859\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.6955e-05 - accuracy: 1.0000 - val_loss: 2.6027 - val_accuracy: 0.5859\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.4774e-05 - accuracy: 1.0000 - val_loss: 2.6140 - val_accuracy: 0.5758\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 4.2690e-05 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.5758\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 4.0717e-05 - accuracy: 1.0000 - val_loss: 2.6367 - val_accuracy: 0.5758\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.8831e-05 - accuracy: 1.0000 - val_loss: 2.6477 - val_accuracy: 0.5758\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.7039e-05 - accuracy: 1.0000 - val_loss: 2.6590 - val_accuracy: 0.5758\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.5325e-05 - accuracy: 1.0000 - val_loss: 2.6703 - val_accuracy: 0.5758\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.3688e-05 - accuracy: 1.0000 - val_loss: 2.6815 - val_accuracy: 0.5758\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.2139e-05 - accuracy: 1.0000 - val_loss: 2.6926 - val_accuracy: 0.5758\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.0662e-05 - accuracy: 1.0000 - val_loss: 2.7040 - val_accuracy: 0.5758\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.9234e-05 - accuracy: 1.0000 - val_loss: 2.7152 - val_accuracy: 0.5758\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.7889e-05 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.5758\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 2.6601e-05 - accuracy: 1.0000 - val_loss: 2.7377 - val_accuracy: 0.5758\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.5374e-05 - accuracy: 1.0000 - val_loss: 2.7484 - val_accuracy: 0.5758\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.4201e-05 - accuracy: 1.0000 - val_loss: 2.7594 - val_accuracy: 0.5758\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.3093e-05 - accuracy: 1.0000 - val_loss: 2.7705 - val_accuracy: 0.5758\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.2025e-05 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.5758\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.1009e-05 - accuracy: 1.0000 - val_loss: 2.7929 - val_accuracy: 0.5758\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.0051e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.5758\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6b2e7cdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=100,batch_size=10,validation_data=(xTest,yTest),shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download(\"trx-usd\",period=\"1d\",interval=\"5m\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6bqkwjROb3lL",
        "outputId": "6c931ed0-766b-4f42-a41b-eec902e0fb43"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Open      High       Low     Close  Adj Close  \\\n",
              "Datetime                                                                       \n",
              "2022-04-26 00:00:00+00:00  0.065323  0.065323  0.065303  0.065318   0.065318   \n",
              "2022-04-26 00:05:00+00:00  0.065294  0.065294  0.065235  0.065235   0.065235   \n",
              "2022-04-26 00:10:00+00:00  0.065123  0.065124  0.065123  0.065124   0.065124   \n",
              "2022-04-26 00:15:00+00:00  0.065094  0.065125  0.065094  0.065125   0.065125   \n",
              "2022-04-26 00:20:00+00:00  0.065071  0.065071  0.065071  0.065071   0.065071   \n",
              "...                             ...       ...       ...       ...        ...   \n",
              "2022-04-26 14:30:00+00:00  0.063578  0.063578  0.063515  0.063515   0.063515   \n",
              "2022-04-26 14:35:00+00:00  0.063494  0.063494  0.063386  0.063386   0.063386   \n",
              "2022-04-26 14:40:00+00:00  0.063276  0.063276  0.063225  0.063225   0.063225   \n",
              "2022-04-26 14:45:00+00:00  0.063163  0.063173  0.063163  0.063173   0.063173   \n",
              "2022-04-26 14:48:00+00:00  0.063180  0.063180  0.063180  0.063180   0.063180   \n",
              "\n",
              "                            Volume  \n",
              "Datetime                            \n",
              "2022-04-26 00:00:00+00:00        0  \n",
              "2022-04-26 00:05:00+00:00   362752  \n",
              "2022-04-26 00:10:00+00:00        0  \n",
              "2022-04-26 00:15:00+00:00  1247552  \n",
              "2022-04-26 00:20:00+00:00        0  \n",
              "...                            ...  \n",
              "2022-04-26 14:30:00+00:00    15872  \n",
              "2022-04-26 14:35:00+00:00    30336  \n",
              "2022-04-26 14:40:00+00:00   540160  \n",
              "2022-04-26 14:45:00+00:00  1098048  \n",
              "2022-04-26 14:48:00+00:00        0  \n",
              "\n",
              "[179 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b074d0c-3595-4bcb-a45d-170e954572f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-26 00:00:00+00:00</th>\n",
              "      <td>0.065323</td>\n",
              "      <td>0.065323</td>\n",
              "      <td>0.065303</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 00:05:00+00:00</th>\n",
              "      <td>0.065294</td>\n",
              "      <td>0.065294</td>\n",
              "      <td>0.065235</td>\n",
              "      <td>0.065235</td>\n",
              "      <td>0.065235</td>\n",
              "      <td>362752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 00:10:00+00:00</th>\n",
              "      <td>0.065123</td>\n",
              "      <td>0.065124</td>\n",
              "      <td>0.065123</td>\n",
              "      <td>0.065124</td>\n",
              "      <td>0.065124</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 00:15:00+00:00</th>\n",
              "      <td>0.065094</td>\n",
              "      <td>0.065125</td>\n",
              "      <td>0.065094</td>\n",
              "      <td>0.065125</td>\n",
              "      <td>0.065125</td>\n",
              "      <td>1247552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 00:20:00+00:00</th>\n",
              "      <td>0.065071</td>\n",
              "      <td>0.065071</td>\n",
              "      <td>0.065071</td>\n",
              "      <td>0.065071</td>\n",
              "      <td>0.065071</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 14:30:00+00:00</th>\n",
              "      <td>0.063578</td>\n",
              "      <td>0.063578</td>\n",
              "      <td>0.063515</td>\n",
              "      <td>0.063515</td>\n",
              "      <td>0.063515</td>\n",
              "      <td>15872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 14:35:00+00:00</th>\n",
              "      <td>0.063494</td>\n",
              "      <td>0.063494</td>\n",
              "      <td>0.063386</td>\n",
              "      <td>0.063386</td>\n",
              "      <td>0.063386</td>\n",
              "      <td>30336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 14:40:00+00:00</th>\n",
              "      <td>0.063276</td>\n",
              "      <td>0.063276</td>\n",
              "      <td>0.063225</td>\n",
              "      <td>0.063225</td>\n",
              "      <td>0.063225</td>\n",
              "      <td>540160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 14:45:00+00:00</th>\n",
              "      <td>0.063163</td>\n",
              "      <td>0.063173</td>\n",
              "      <td>0.063163</td>\n",
              "      <td>0.063173</td>\n",
              "      <td>0.063173</td>\n",
              "      <td>1098048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-26 14:48:00+00:00</th>\n",
              "      <td>0.063180</td>\n",
              "      <td>0.063180</td>\n",
              "      <td>0.063180</td>\n",
              "      <td>0.063180</td>\n",
              "      <td>0.063180</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b074d0c-3595-4bcb-a45d-170e954572f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b074d0c-3595-4bcb-a45d-170e954572f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b074d0c-3595-4bcb-a45d-170e954572f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 5]\n",
        "    grow = []\n",
        "    srow = []\n",
        "    for j in llst:\n",
        "           srow.append([\n",
        "               data[i-1][j] - data[i-2][j],\n",
        "               data[i-2][j] - data[i-3][j],\n",
        "               data[i-3][j] - data[i-4][j],\n",
        "               data[i-4][j] - data[i-5][j],\n",
        "               data[i-5][j] - data[i-6][j],\n",
        "               data[i-6][j] - data[i-7][j],\n",
        "               data[i-7][j] - data[i-8][j],\n",
        "               data[i-8][j] - data[i-9][j],\n",
        "               data[i-9][j] - data[i-10][j],\n",
        "               data[i-10][j] - data[i-11][j],\n",
        "               data[i-11][j] - data[i-12][j]\n",
        "           ])\n",
        "\n",
        "    for lst in srow:\n",
        "            mm = np.array(lst)\n",
        "            mm = np.reshape(mm, (-1, 1))\n",
        "            grow.append(scaler(mm))\n",
        "\n",
        "        \n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ],
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"btc-usd\",\"5m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "b338c30c-22c1-4139-b0c3-c9bac5b8aab0"
      },
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5138444 , 0.12956947]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "86b20654-2a9e-4d90-f271-26450936e9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CMm_v1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
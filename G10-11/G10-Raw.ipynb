{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5bxbCoe9do9"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "    \"Open 1\",\"Close 1\",\"Open 2\",\"Close 2\",\"Open 3\",\"Close 3\",\"Open 4\",\"Close 4\",\"Open 5\",\"Close 5\",\"Open 6\",\"Close 6\",\"Open 7\",\"Close 7\",\"Open 8\",\"Close 8\",\"Open 9\",\"Close 9\",\"Open 10\",\"Close 10\",\"Open 11\",\"Close 11\",\"Open 12\",\"Close 12\",\"Open 13\",\"Close 13\",\"Open 14\",\"Close 14\",\"Open 15\",\"Close 15\",\"Open 16\",\"Close 16\",\"Open 17\",\"Close 17\",\"Open 18\",\"Close 18\",\"Open 19\",\"Close 19\",\"Open 20\",\"Close 20\",\"Open 21\",\"Close 21\",\"Open 22\",\"Close 22\",\"Open 23\",\"Close 23\",\"Open 24\",\"Close 24\",\"Open 25\",\"Close 25\",\"Open 26\",\"Close 26\",\"Open 27\",\"Close 27\",\"Open 28\",\"Close 28\",\"Open 29\",\"Close 29\",\"Open 30\",\"Close 30\",\n",
        "    \"Open 31\",\"Close 31\",\"Open 32\",\"Close 32\",\"Open 33\",\"Close 33\",\"Open 34\",\"Close 34\",\"Open 35\",\"Close 35\",\"Open 36\",\"Close 36\",\"Open 37\",\"Close 37\",\"Open 38\",\"Close 38\",\"Open 39\",\"Close 39\",\"Open 40\",\"Close 40\",\"Open 41\",\"Close 41\",\"Open 42\",\"Close 42\",\"Open 43\",\"Close 43\",\"Open 44\",\"Close 44\",\"Open 45\",\"Close 45\",\"Open 46\",\"Close 46\",\"Open 47\",\"Close 47\",\"Open 48\",\"Close 48\",\"Open 49\",\"Close 49\",\"Open 50\",\"Close 50\",\"Open 51\",\"Close 51\",\"Open 52\",\"Close 52\",\"Open 53\",\"Close 53\",\"Open 54\",\"Close 54\",\"Open 55\",\"Close 55\",\"Open 56\",\"Close 56\",\"Open 57\",\"Close 57\",\"Open 58\",\"Close 58\",\"Open 59\",\"Close 59\",\"Open 60\",\"Close 60\"\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        for x in range(1, 61):\n",
        "            grow.append([data[i-x, 0], data[i-x, 1],\n",
        "                        data[i-x, 2], data[i-x, 3]])\n",
        "        for eeach in grow:\n",
        "            ggrow.append(scaler(np.array(eeach).reshape(-1, 1)))\n",
        "        for eachh in ggrow:\n",
        "            eachh = np.array(eachh).reshape(-1,1)\n",
        "            eachh = np.delete(eachh,1)\n",
        "            eachh = np.delete(eachh, 1)\n",
        "            gggrow.append(eachh)\n",
        "        sugg = \"sell\"\n",
        "        if data[i][3] > data[i-1][3]:\n",
        "            sugg = \"buy\"\n",
        "        arr = np.array(gggrow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "    grow = []\n",
        "    ggrow = []\n",
        "    gggrow = []\n",
        "    arr = []\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 60:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")         \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        try:\n",
        "           unattached_dfs.append(process(pd.read_csv(address)))\n",
        "        except:\n",
        "          print(\" EP \")\n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\" Null \")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     unattached_dfs = []\n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIAuU_ILbU27"
      },
      "outputs": [],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"7d\",\"15m\")\n",
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN93WT9e8ueQ"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(750, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "model.add(Dense(750, activation='relu'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SBxPzRd89uy"
      },
      "outputs": [],
      "source": [
        "model.fit(xTrain,yTrain,epochs=30,batch_size=1024,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"A.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bqkwjROb3lL"
      },
      "outputs": [],
      "source": [
        "yf.download(\"btc-usd\",period=\"7d\",interval=\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        row = []\n",
        "        if len(pd.DataFrame(data).columns) == 7:\n",
        "          data = data.iloc[: , 1:]        \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"30d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"100d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuUzTsN-SfnH"
      },
      "outputs": [],
      "source": [
        "make_prediction(\"btc-usd\",\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        row = []\n",
        "        data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcUSD',exchange='bitstamp',interval=Interval.in_15_minute,n_bars=100)\n",
        "   return model.predict(process_for_prediction(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLgPS4HGIpgT"
      },
      "outputs": [],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "16d1676b-03f8-4919-bfad-d24545d89233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FD_9G5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "c83fa34a-790d-45f2-d3b6-45e882fe3b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 18.0 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\",\n",
        "     \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "     \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\",     \n",
        "\n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]\n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "\n",
        "        \n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i-1][3]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  \n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 60:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "             \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        try:\n",
        "            unattached_dfs.append(process(pd.read_csv(address)))\n",
        "        except:\n",
        "          print(\"Corrupted!\",end=\" \")\n",
        "     \n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\"Null!\")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "        \n",
        "     unattached_dfs = []\n",
        "  \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIAuU_ILbU27",
        "outputId": "43d69cea-147f-42bb-ce1f-32c405c8fdd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " -- 100 -- 200 -- 300 -- 400 -- 500 -- 600 -- 700 -- 800 -- 900 -- 1000 -- 1100 -- 1200 -- 1300 -- 1400 -- 1500 \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "#symbols = read_txt_list()\n",
        "#symbols = read_syms_from_txt()\n",
        "#symbols = [\"msft\",\"aapl\",\"googl\",\"fb\",\"2222.sr\",\"amzn\",\"tsla\",\"brk.a\",\"nvda\",\"tsm\",\"unh\",\"jnj\",\"wmt\",\"pg\",\"v\",\"xom\",\"005930.KS\",\"ma\"]\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"30d\",\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qBYzyyUKHQQ"
      },
      "outputs": [],
      "source": [
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest = spliting(pd.read_parquet(\"/content/drive/MyDrive/data.parquet\"))"
      ],
      "metadata": {
        "id": "W7lZ-kxuPb5Z",
        "outputId": "10affe62-e69e-449d-cc83-71160aa2ecca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(956902, 240) (956902, 2)\n",
            "(239226, 240) (239226, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xN93WT9e8ueQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7185e721-9971-4234-e1f7-6e97ec424926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 1024)              246784    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,596,034\n",
            "Trainable params: 7,596,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(1024, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_SBxPzRd89uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd03761-cc09-4348-a9ac-4041b929944c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "935/935 [==============================] - 20s 21ms/step - loss: 0.6368 - accuracy: 0.6155 - val_loss: 0.5837 - val_accuracy: 0.6722\n",
            "Epoch 2/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.5502 - accuracy: 0.7003 - val_loss: 0.5375 - val_accuracy: 0.7106\n",
            "Epoch 3/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.4848 - accuracy: 0.7542 - val_loss: 0.4920 - val_accuracy: 0.7492\n",
            "Epoch 4/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.4102 - accuracy: 0.8075 - val_loss: 0.4539 - val_accuracy: 0.7835\n",
            "Epoch 5/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.3396 - accuracy: 0.8505 - val_loss: 0.4139 - val_accuracy: 0.8148\n",
            "Epoch 6/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.2850 - accuracy: 0.8798 - val_loss: 0.3964 - val_accuracy: 0.8318\n",
            "Epoch 7/30\n",
            "935/935 [==============================] - 17s 18ms/step - loss: 0.2411 - accuracy: 0.9010 - val_loss: 0.3904 - val_accuracy: 0.8428\n",
            "Epoch 8/30\n",
            "935/935 [==============================] - 17s 18ms/step - loss: 0.2070 - accuracy: 0.9164 - val_loss: 0.3938 - val_accuracy: 0.8490\n",
            "Epoch 9/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.1807 - accuracy: 0.9280 - val_loss: 0.3845 - val_accuracy: 0.8565\n",
            "Epoch 10/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.1592 - accuracy: 0.9373 - val_loss: 0.3750 - val_accuracy: 0.8577\n",
            "Epoch 11/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.1410 - accuracy: 0.9448 - val_loss: 0.4043 - val_accuracy: 0.8635\n",
            "Epoch 12/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.1266 - accuracy: 0.9511 - val_loss: 0.3957 - val_accuracy: 0.8651\n",
            "Epoch 13/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.1143 - accuracy: 0.9562 - val_loss: 0.4261 - val_accuracy: 0.8676\n",
            "Epoch 14/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.1047 - accuracy: 0.9601 - val_loss: 0.4013 - val_accuracy: 0.8672\n",
            "Epoch 15/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0968 - accuracy: 0.9631 - val_loss: 0.4389 - val_accuracy: 0.8712\n",
            "Epoch 16/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0896 - accuracy: 0.9661 - val_loss: 0.4268 - val_accuracy: 0.8722\n",
            "Epoch 17/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0831 - accuracy: 0.9686 - val_loss: 0.4400 - val_accuracy: 0.8721\n",
            "Epoch 18/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0769 - accuracy: 0.9709 - val_loss: 0.4310 - val_accuracy: 0.8756\n",
            "Epoch 19/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0724 - accuracy: 0.9728 - val_loss: 0.4413 - val_accuracy: 0.8751\n",
            "Epoch 20/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0680 - accuracy: 0.9745 - val_loss: 0.4817 - val_accuracy: 0.8760\n",
            "Epoch 21/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 0.4533 - val_accuracy: 0.8763\n",
            "Epoch 22/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0608 - accuracy: 0.9773 - val_loss: 0.4790 - val_accuracy: 0.8777\n",
            "Epoch 23/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0574 - accuracy: 0.9785 - val_loss: 0.4740 - val_accuracy: 0.8789\n",
            "Epoch 24/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0546 - accuracy: 0.9797 - val_loss: 0.5081 - val_accuracy: 0.8771\n",
            "Epoch 25/30\n",
            "935/935 [==============================] - 16s 18ms/step - loss: 0.0519 - accuracy: 0.9806 - val_loss: 0.4925 - val_accuracy: 0.8810\n",
            "Epoch 26/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 0.5391 - val_accuracy: 0.8796\n",
            "Epoch 27/30\n",
            "935/935 [==============================] - 16s 17ms/step - loss: 0.0476 - accuracy: 0.9822 - val_loss: 0.4973 - val_accuracy: 0.8815\n",
            "Epoch 28/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0456 - accuracy: 0.9830 - val_loss: 0.5263 - val_accuracy: 0.8818\n",
            "Epoch 29/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.5097 - val_accuracy: 0.8801\n",
            "Epoch 30/30\n",
            "935/935 [==============================] - 18s 19ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.5524 - val_accuracy: 0.8820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7780076090>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=30,batch_size=1024,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"C15m9G5_8820_c.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6bqkwjROb3lL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "112db02b-5000-4d7e-9e43-a059c2ea31ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Open      High       Low     Close  Adj Close  \\\n",
              "Datetime                                                                       \n",
              "2022-03-03 00:00:00+00:00  0.061524  0.061527  0.061296  0.061341   0.061341   \n",
              "2022-03-03 00:15:00+00:00  0.061337  0.061497  0.061337  0.061456   0.061456   \n",
              "2022-03-03 00:30:00+00:00  0.061480  0.061616  0.061480  0.061610   0.061610   \n",
              "2022-03-03 00:45:00+00:00  0.061607  0.061607  0.061488  0.061491   0.061491   \n",
              "2022-03-03 01:00:00+00:00  0.061501  0.061510  0.061328  0.061328   0.061328   \n",
              "...                             ...       ...       ...       ...        ...   \n",
              "2022-05-01 10:30:00+00:00  0.067180  0.067191  0.066733  0.066733   0.066733   \n",
              "2022-05-01 10:45:00+00:00  0.066719  0.066719  0.066463  0.066532   0.066532   \n",
              "2022-05-01 11:00:00+00:00  0.066486  0.066486  0.066095  0.066095   0.066095   \n",
              "2022-05-01 11:15:00+00:00  0.066102  0.066102  0.066102  0.066102   0.066102   \n",
              "2022-05-01 11:16:00+00:00  0.066069  0.066069  0.066069  0.066069   0.066069   \n",
              "\n",
              "                             Volume  \n",
              "Datetime                             \n",
              "2022-03-03 00:00:00+00:00         0  \n",
              "2022-03-03 00:15:00+00:00    400064  \n",
              "2022-03-03 00:30:00+00:00         0  \n",
              "2022-03-03 00:45:00+00:00   1795072  \n",
              "2022-03-03 01:00:00+00:00         0  \n",
              "...                             ...  \n",
              "2022-05-01 10:30:00+00:00  10185472  \n",
              "2022-05-01 10:45:00+00:00   5057536  \n",
              "2022-05-01 11:00:00+00:00   4269568  \n",
              "2022-05-01 11:15:00+00:00    462336  \n",
              "2022-05-01 11:16:00+00:00         0  \n",
              "\n",
              "[5711 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77bc3b32-d2d4-4717-ac35-757b70901fcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-03-03 00:00:00+00:00</th>\n",
              "      <td>0.061524</td>\n",
              "      <td>0.061527</td>\n",
              "      <td>0.061296</td>\n",
              "      <td>0.061341</td>\n",
              "      <td>0.061341</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-03 00:15:00+00:00</th>\n",
              "      <td>0.061337</td>\n",
              "      <td>0.061497</td>\n",
              "      <td>0.061337</td>\n",
              "      <td>0.061456</td>\n",
              "      <td>0.061456</td>\n",
              "      <td>400064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-03 00:30:00+00:00</th>\n",
              "      <td>0.061480</td>\n",
              "      <td>0.061616</td>\n",
              "      <td>0.061480</td>\n",
              "      <td>0.061610</td>\n",
              "      <td>0.061610</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-03 00:45:00+00:00</th>\n",
              "      <td>0.061607</td>\n",
              "      <td>0.061607</td>\n",
              "      <td>0.061488</td>\n",
              "      <td>0.061491</td>\n",
              "      <td>0.061491</td>\n",
              "      <td>1795072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-03 01:00:00+00:00</th>\n",
              "      <td>0.061501</td>\n",
              "      <td>0.061510</td>\n",
              "      <td>0.061328</td>\n",
              "      <td>0.061328</td>\n",
              "      <td>0.061328</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 10:30:00+00:00</th>\n",
              "      <td>0.067180</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.066733</td>\n",
              "      <td>0.066733</td>\n",
              "      <td>0.066733</td>\n",
              "      <td>10185472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 10:45:00+00:00</th>\n",
              "      <td>0.066719</td>\n",
              "      <td>0.066719</td>\n",
              "      <td>0.066463</td>\n",
              "      <td>0.066532</td>\n",
              "      <td>0.066532</td>\n",
              "      <td>5057536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 11:00:00+00:00</th>\n",
              "      <td>0.066486</td>\n",
              "      <td>0.066486</td>\n",
              "      <td>0.066095</td>\n",
              "      <td>0.066095</td>\n",
              "      <td>0.066095</td>\n",
              "      <td>4269568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 11:15:00+00:00</th>\n",
              "      <td>0.066102</td>\n",
              "      <td>0.066102</td>\n",
              "      <td>0.066102</td>\n",
              "      <td>0.066102</td>\n",
              "      <td>0.066102</td>\n",
              "      <td>462336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01 11:16:00+00:00</th>\n",
              "      <td>0.066069</td>\n",
              "      <td>0.066069</td>\n",
              "      <td>0.066069</td>\n",
              "      <td>0.066069</td>\n",
              "      <td>0.066069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5711 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77bc3b32-d2d4-4717-ac35-757b70901fcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77bc3b32-d2d4-4717-ac35-757b70901fcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77bc3b32-d2d4-4717-ac35-757b70901fcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data = yf.download(\"trx-usd\",period=\"60d\",interval=\"15m\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -2\n",
        "        row = []\n",
        "        if len(pd.DataFrame(data).columns) == 7:\n",
        "          data = data.iloc[: , 1:]        \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"30d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"100d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "60a41bac-4a41-4435-aeeb-105f8d71aa0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04269813, 0.96452624]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "make_prediction(\"trx-usd\",\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "\n",
        "        i = -1\n",
        "        row = []\n",
        "        data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "        s13 = [\n",
        "            data[i-13][0], data[i-13][1], data[i-13][2], data[i-13][3]\n",
        "        ]\n",
        "        s14 = [\n",
        "            data[i-14][0], data[i-14][1], data[i-14][2], data[i-14][3]\n",
        "        ]\n",
        "        s15 = [\n",
        "            data[i-15][0], data[i-15][1], data[i-15][2], data[i-15][3]\n",
        "        ]   \n",
        "        s16 = [\n",
        "            data[i-16][0], data[i-16][1], data[i-16][2], data[i-16][3]\n",
        "        ]\n",
        "        s17 = [\n",
        "            data[i-17][0], data[i-17][1], data[i-17][2], data[i-17][3]\n",
        "        ]\n",
        "        s18 = [\n",
        "            data[i-18][0], data[i-18][1], data[i-18][2], data[i-18][3]\n",
        "        ]   \n",
        "        s19 = [\n",
        "            data[i-19][0], data[i-19][1], data[i-19][2], data[i-19][3]\n",
        "        ]\n",
        "        s20 = [\n",
        "            data[i-20][0], data[i-20][1], data[i-20][2], data[i-20][3]\n",
        "        ]\n",
        "        s21 = [\n",
        "            data[i-21][0], data[i-21][1], data[i-21][2], data[i-21][3]\n",
        "        ]   \n",
        "        s22 = [\n",
        "            data[i-22][0], data[i-22][1], data[i-22][2], data[i-22][3]\n",
        "        ]\n",
        "        s23 = [\n",
        "            data[i-23][0], data[i-23][1], data[i-23][2], data[i-23][3]\n",
        "        ]\n",
        "        s24 = [\n",
        "            data[i-24][0], data[i-24][1], data[i-24][2], data[i-24][3]\n",
        "        ]\n",
        "        s25 = [\n",
        "            data[i-25][0], data[i-25][1], data[i-25][2], data[i-25][3]\n",
        "        ]\n",
        "        s26 = [\n",
        "            data[i-26][0], data[i-26][1], data[i-26][2], data[i-26][3]\n",
        "        ]   \n",
        "        s27 = [\n",
        "            data[i-27][0], data[i-27][1], data[i-27][2], data[i-27][3]\n",
        "        ]\n",
        "        s28 = [\n",
        "            data[i-28][0], data[i-28][1], data[i-28][2], data[i-28][3]\n",
        "        ]   \n",
        "        s29 = [\n",
        "            data[i-29][0], data[i-29][1], data[i-29][2], data[i-29][3]\n",
        "        ]   \n",
        "        s30 = [\n",
        "            data[i-30][0], data[i-30][1], data[i-30][2], data[i-30][3]]\n",
        "        \n",
        "        s31 = [\n",
        "            data[i-31][0], data[i-31][1], data[i-31][2], data[i-31][3]]\n",
        "        s32 = [\n",
        "            data[i-32][0], data[i-32][1], data[i-32][2], data[i-32][3]]\n",
        "        s33 = [\n",
        "            data[i-33][0], data[i-33][1], data[i-33][2], data[i-33][3]]\n",
        "        s34 = [\n",
        "            data[i-34][0], data[i-34][1], data[i-34][2], data[i-34][3]]\n",
        "        s35 = [\n",
        "            data[i-35][0], data[i-35][1], data[i-35][2], data[i-35][3]]\n",
        "        s36 = [\n",
        "            data[i-36][0], data[i-36][1], data[i-36][2], data[i-36][3]]\n",
        "        s37 = [\n",
        "            data[i-37][0], data[i-37][1], data[i-37][2], data[i-37][3]]\n",
        "        s38 = [\n",
        "            data[i-38][0], data[i-38][1], data[i-38][2], data[i-38][3]]\n",
        "        s39 = [\n",
        "            data[i-39][0], data[i-39][1], data[i-39][2], data[i-39][3]]\n",
        "        s40 = [\n",
        "            data[i-40][0], data[i-40][1], data[i-40][2], data[i-40][3]]\n",
        "        s41 = [\n",
        "            data[i-41][0], data[i-41][1], data[i-41][2], data[i-41][3]]\n",
        "        s42 = [\n",
        "            \n",
        "            data[i-42][0], data[i-42][1], data[i-42][2], data[i-42][3]]\n",
        "        s43 = [\n",
        "            data[i-43][0], data[i-43][1], data[i-43][2], data[i-43][3]]\n",
        "        s44 = [\n",
        "            data[i-44][0], data[i-44][1], data[i-44][2], data[i-44][3]]\n",
        "        s45 = [\n",
        "            data[i-45][0], data[i-45][1], data[i-45][2], data[i-45][3]]\n",
        "        s46 = [\n",
        "            data[i-46][0], data[i-46][1], data[i-46][2], data[i-46][3]]\n",
        "        s47 = [\n",
        "            data[i-47][0], data[i-47][1], data[i-47][2], data[i-47][3]]\n",
        "        s48 = [\n",
        "            data[i-48][0], data[i-48][1], data[i-48][2], data[i-48][3]]\n",
        "        s49 = [\n",
        "            data[i-49][0], data[i-49][1], data[i-49][2], data[i-49][3]]\n",
        "        s50 = [\n",
        "            data[i-50][0], data[i-50][1], data[i-50][2], data[i-50][3]]\n",
        "\n",
        "        s51 = [\n",
        "            data[i-51][0], data[i-51][1], data[i-51][2], data[i-51][3]]\n",
        "        s52 = [ \n",
        "            data[i-52][0], data[i-52][1], data[i-52][2], data[i-52][3]]\n",
        "        s53 = [\n",
        "            data[i-53][0], data[i-53][1], data[i-53][2], data[i-53][3]]\n",
        "        s54 = [\n",
        "            data[i-54][0], data[i-54][1], data[i-54][2], data[i-54][3]]\n",
        "        s55 = [\n",
        "            data[i-55][0], data[i-55][1], data[i-55][2], data[i-55][3]]\n",
        "        s56 = [\n",
        "            data[i-56][0], data[i-56][1], data[i-56][2], data[i-56][3]]\n",
        "        s57 = [\n",
        "            data[i-57][0], data[i-57][1], data[i-57][2], data[i-57][3]]\n",
        "        s58 = [\n",
        "            data[i-58][0], data[i-58][1], data[i-58][2], data[i-58][3]]\n",
        "        s59 = [\n",
        "            data[i-59][0], data[i-59][1], data[i-59][2], data[i-59][3]]\n",
        "        s60 = [\n",
        "            data[i-60][0], data[i-60][1], data[i-60][2], data[i-60][3]]   \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "        s13 = scaler(np.array(s13).reshape(-1,1))\n",
        "        s14 = scaler(np.array(s14).reshape(-1,1))\n",
        "        s15 = scaler(np.array(s15).reshape(-1,1))\n",
        "        s16 = scaler(np.array(s16).reshape(-1,1))\n",
        "        s17 = scaler(np.array(s17).reshape(-1,1))\n",
        "        s18 = scaler(np.array(s18).reshape(-1,1))\n",
        "        s19 = scaler(np.array(s19).reshape(-1,1))\n",
        "        s20 = scaler(np.array(s20).reshape(-1,1))\n",
        "        s21 = scaler(np.array(s21).reshape(-1,1))\n",
        "        s22 = scaler(np.array(s22).reshape(-1,1))\n",
        "        s23 = scaler(np.array(s23).reshape(-1,1))\n",
        "        s24 = scaler(np.array(s24).reshape(-1,1))\n",
        "        s25 = scaler(np.array(s25).reshape(-1,1))\n",
        "        s26 = scaler(np.array(s26).reshape(-1,1))\n",
        "        s27 = scaler(np.array(s27).reshape(-1,1))\n",
        "        s28 = scaler(np.array(s28).reshape(-1,1))\n",
        "        s29 = scaler(np.array(s29).reshape(-1,1))\n",
        "        s30 = scaler(np.array(s30).reshape(-1,1))\n",
        "        s31 = scaler(np.array(s31).reshape(-1,1))\n",
        "        s32 = scaler(np.array(s32).reshape(-1,1))\n",
        "        s33 = scaler(np.array(s33).reshape(-1,1))\n",
        "        s34 = scaler(np.array(s34).reshape(-1,1))\n",
        "        s35 = scaler(np.array(s35).reshape(-1,1))\n",
        "        s36 = scaler(np.array(s36).reshape(-1,1))\n",
        "        s37 = scaler(np.array(s37).reshape(-1,1))\n",
        "        s38 = scaler(np.array(s38).reshape(-1,1))\n",
        "        s39 = scaler(np.array(s39).reshape(-1,1))\n",
        "        s40 = scaler(np.array(s40).reshape(-1,1))\n",
        "        s41 = scaler(np.array(s41).reshape(-1,1))\n",
        "        s42 = scaler(np.array(s42).reshape(-1,1))\n",
        "        s43 = scaler(np.array(s43).reshape(-1,1))\n",
        "        s44 = scaler(np.array(s44).reshape(-1,1))\n",
        "        s45 = scaler(np.array(s45).reshape(-1,1))\n",
        "        s46 = scaler(np.array(s46).reshape(-1,1))\n",
        "        s47 = scaler(np.array(s47).reshape(-1,1))\n",
        "        s48 = scaler(np.array(s48).reshape(-1,1))\n",
        "        s49 = scaler(np.array(s49).reshape(-1,1))\n",
        "        s50 = scaler(np.array(s50).reshape(-1,1))\n",
        "        s51 = scaler(np.array(s51).reshape(-1,1))\n",
        "        s52 = scaler(np.array(s52).reshape(-1,1))\n",
        "        s53 = scaler(np.array(s53).reshape(-1,1))\n",
        "        s54 = scaler(np.array(s54).reshape(-1,1))\n",
        "        s55 = scaler(np.array(s55).reshape(-1,1))\n",
        "        s56 = scaler(np.array(s56).reshape(-1,1))\n",
        "        s57 = scaler(np.array(s57).reshape(-1,1))\n",
        "        s58 = scaler(np.array(s58).reshape(-1,1))\n",
        "        s59 = scaler(np.array(s59).reshape(-1,1))\n",
        "        s60 = scaler(np.array(s60).reshape(-1,1))\n",
        "\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30, s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52, s53, s54, s55, s56, s57, s58, s59, s60))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        row.append(arr)\n",
        "\n",
        "        return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='trxusd',exchange='binance',interval=Interval.in_15_minute,n_bars=100)\n",
        "   return model.predict(process_for_prediction(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgPS4HGIpgT",
        "outputId": "22850c3e-b2ad-4d23-fd9f-5c86c335bd2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "do you want to install chromedriver automatically?? y/n\tn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71241933, 0.29599974]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "1d3656aa-1600-4a09-8ae6-7d875a89d9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "C15m_9G5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
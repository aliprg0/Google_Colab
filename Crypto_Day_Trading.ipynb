{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5bxbCoe9do9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8e88e1-2188-4bbd-97c3-c91227480cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: yahooquery in /usr/local/lib/python3.7/dist-packages (2.2.15)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: requests-futures>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.0.0)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sys import getsizeof\n",
        "from datetime import datetime\n",
        "import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = ['15 Open', '15 High', '15 Low', '15 Close', '15 Volume', '14 Open', '14 High', '14 Low', '14 Close', '14 Volume', '13 Open', '13 High', '13 Low', '13 Close', '13 Volume', '12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume',\"suggestion\"]\n",
        "clmnsws = ['15 Open', '15 High', '15 Low', '15 Close', '15 Volume', '14 Open', '14 High', '14 Low', '14 Close', '14 Volume', '13 Open', '13 High', '13 Low', '13 Close', '13 Volume', '12 Open', '12 High', '12 Low', '12 Close', '12 Volume', '11 Open', '11 High', '11 Low', '11 Close', '11 Volume', '10 Open', '10 High', '10 Low', '10 Close', '10 Volume', '9 Open', '9 High', '9 Low', '9 Close', '9 Volume', '8 Open', '8 High', '8 Low', '8 Close', '8 Volume', '7 Open', '7 High', '7 Low', '7 Close', '7 Volume', '6 Open', '6 High', '6 Low', '6 Close', '6 Volume', '5 Open', '5 High', '5 Low', '5 Close', '5 Volume', '4 Open', '4 High', '4 Low', '4 Close', '4 Volume', '3 Open', '3 High', '3 Low', '3 Close', '3 Volume', '2 Open', '2 High', '2 Low', '2 Close', '2 Volume', '1 Open', '1 High', '1 Low', '1 Close', '1 Volume']\n",
        "def read_syms_from_txt():  \n",
        "  with open(\"syms.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   #'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "   'all_cryptocurrencies_us','all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   #print(len(symbols))\n",
        "   #pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"suggestion\"],axis=1)\n",
        "  y = data[\"suggestion\"]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape,end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape,end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def extract_data(df):\n",
        "    rows = []\n",
        "    for each in range(15,df.shape[0]-1):\n",
        "        sugg = 0\n",
        "        if df[each][3] > df[each][0]:\n",
        "          sugg = 1\n",
        "        row = [\n",
        "                df[each-15][0],\n",
        "                df[each-15][1],\n",
        "                df[each-15][2],\n",
        "                df[each-15][3],\n",
        "                df[each-15][4],\n",
        "                df[each-14][0],\n",
        "                df[each-14][1],\n",
        "                df[each-14][2],\n",
        "                df[each-14][3],\n",
        "                df[each-14][4],\n",
        "                df[each-13][0],\n",
        "                df[each-13][1],\n",
        "                df[each-13][2],\n",
        "                df[each-13][3],\n",
        "                df[each-13][4],\n",
        "                df[each-12][0],\n",
        "                df[each-12][1],\n",
        "                df[each-12][2],\n",
        "                df[each-12][3],\n",
        "                df[each-12][4],\n",
        "                df[each-11][0],\n",
        "                df[each-11][1],\n",
        "                df[each-11][2],\n",
        "                df[each-11][3],\n",
        "                df[each-11][4],\n",
        "                df[each-10][0],\n",
        "                df[each-10][1],\n",
        "                df[each-10][2],\n",
        "                df[each-10][3],\n",
        "                df[each-10][4],\n",
        "                df[each-9][0],\n",
        "                df[each-9][1],\n",
        "                df[each-9][2],\n",
        "                df[each-9][3],\n",
        "                df[each-9][4],\n",
        "                df[each-8][0],\n",
        "                df[each-8][1],\n",
        "                df[each-8][2],\n",
        "                df[each-8][3],\n",
        "                df[each-8][4],\n",
        "                df[each-7][0],\n",
        "                df[each-7][1],\n",
        "                df[each-7][2],\n",
        "                df[each-7][3],\n",
        "                df[each-7][4],\n",
        "                df[each-6][0],\n",
        "                df[each-6][1],\n",
        "                df[each-6][2],\n",
        "                df[each-6][3],\n",
        "                df[each-6][4],\n",
        "                df[each-5][0],\n",
        "                df[each-5][1],\n",
        "                df[each-5][2],\n",
        "                df[each-5][3],\n",
        "                df[each-5][4],\n",
        "                df[each-4][0],\n",
        "                df[each-4][1],\n",
        "                df[each-4][2],\n",
        "                df[each-4][3],\n",
        "                df[each-4][4],\n",
        "                df[each-3][0],\n",
        "                df[each-3][1],\n",
        "                df[each-3][2],\n",
        "                df[each-3][3],\n",
        "                df[each-3][4],\n",
        "                df[each-2][0],\n",
        "                df[each-2][1],\n",
        "                df[each-2][2],\n",
        "                df[each-2][3],\n",
        "                df[each-2][4],\n",
        "                df[each-1][0],\n",
        "                df[each-1][2],\n",
        "                df[each-1][1],\n",
        "                df[each-1][3],\n",
        "                df[each-1][4],\n",
        "                sugg\n",
        "        ]\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "def row_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(0,10))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  scaled = pd.DataFrame(scaler.fit_transform(df.T).T,dtype=object,columns = clmnsws)\n",
        "  scaled[\"suggestion\"] = last_column\n",
        "  return scaled\n",
        "def column_scaler(df):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  last_column = df.iloc[: , -1]\n",
        "  df = df.drop(columns=df.columns[-1], axis=1)\n",
        "  df_scaled = scaler.fit_transform(df.to_numpy())\n",
        "  df_scaled = pd.DataFrame(df_scaled,columns = clmnsws)\n",
        "  df_scaled[\"suggestion\"] = last_column\n",
        "  return df_scaled\n",
        "def process(df): \n",
        "      df = df.dropna()\n",
        "      df = np.array(df)\n",
        "      df = extract_data(df)\n",
        "      df = pd.DataFrame(df,columns = clmns)\n",
        "      df = row_scaler(df)\n",
        "      #df = column_scaler(df)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIAuU_ILbU27"
      },
      "outputs": [],
      "source": [
        "def get_data(symbols):\n",
        "    unattached_dfs = []\n",
        "    for symbol in symbols:\n",
        "           data = yf.download(symbol,period=\"MAX\",interval=\"1d\",progress=False)\n",
        "           if data.empty :\n",
        "              pass\n",
        "           else:\n",
        "               if data.shape[0] > 14:\n",
        "                   unattached_dfs.append(process(data))\n",
        "    symbols = []\n",
        "    symbol = []\n",
        "    data = []\n",
        "\n",
        "    data = pd.concat(unattached_dfs)\n",
        "    data = data.astype(float)\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = spliting(data)\n",
        "    print(data.shape)\n",
        "    data.to_csv(f\"{random.randint(1,1000)}.csv\")\n",
        "    data = []\n",
        "    return xTrain, xTest, yTrain, yTest\n",
        "\n",
        "#symbols = [\"MSFT\",\"AAPL\",\"GOOG\",\"TSLA\",\"AMZN\"]\n",
        "#symbols = [\"BTC-USD\",\"LTC-USD\",\"TRX-USD\",\"XRP-USD\",\"ETH-USD\",\"BNB-USD\",\"DASH-USD\",\"VET-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"SOL-USD\",\"BCH-USD\",\"FTT-USD\",\"FIL-USD\",\"XMR-USD\"]\n",
        "#symbols = [\"AAPL\",\"MSFT\",\"TSLA\",\"GOOG\"]\n",
        "#symbols = [\"BTC-USD\",\"ETH-USD\"]\n",
        "#symbols = [\"BTC-USD\"]\n",
        "#symbols = read_syms_from_txt()\n",
        "symbols = get_crypto_syms()\n",
        "\n",
        "#pieces = 10\n",
        "#new_arrays = np.array_split(symbols, pieces)\n",
        "#for symbols in new_arrays:\n",
        "#   xTrain, xTest, yTrain, yTest= get_data(symbols)\n",
        "  \n",
        "xTrain, xTest, yTrain, yTest= get_data(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN93WT9e8ueQ",
        "outputId": "8bab101d-7886-43d6-d1f7-609c3698f601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 4048)              307648    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3096)              12535704  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2048)              6342656   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,334,809\n",
            "Trainable params: 22,334,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(4048, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(3096, activation='relu'))\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "e078f4b1-a917-43e2-b276-f064e3481382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  4/194 [..............................] - ETA: 1:08:08 - loss: 3.7339 - accuracy: 0.5042"
          ]
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=50,batch_size=8192,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAKTl3fbHIE6",
        "outputId": "34a3721b-1f15-4b29-f064-3cc13103a6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Crypto_Day_Trading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "fa2788d6-9b43-4ea3-b999-820054ee1aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 21.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 27.1 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 39.4 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 42.5 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\"Open 0-1\",\n",
        "    \"Open 1-2\", \"Open 2-3\", \"Open 3-4\", \"Open 4-5\", \"Open 5-6\", \"Open 6-7\", \"Open 7-8\", \"Open 8-9\", \"Open 9-10\", \"Open 10-11\", \"Open 11-12\", \"Open 12-13\", \"Open 13-14\", \"Open 14-15\", \"Open 15-16\",\n",
        "    \"Close 1-2\", \"Close 2-3\", \"Close 3-4\", \"Close 4-5\", \"Close 5-6\", \"Close 6-7\", \"Close 7-8\", \"Close 8-9\", \"Close 9-10\", \"Close 10-11\", \"Close 11-12\", \"Close 12-13\", \"Close 13-14\", \"Close 14-15\", \"Close 15-16\",\n",
        "    \"High 1-2\", \"High 2-3\", \"High 3-4\", \"High 4-5\", \"High 5-6\", \"High 6-7\", \"High 7-8\", \"High 8-9\", \"High 9-10\", \"High 10-11\", \"High 11-12\", \"High 12-13\", \"High 13-14\", \"High 14-15\", \"High 15-16\",\n",
        "    \"Low 1-2\", \"Low 2-3\", \n",
        "    \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"yes\",\"no\"], axis=1)\n",
        "  y = data[[\"yes\",\"no\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[: , 1:]     \n",
        "   \n",
        "    data = np.array(data)\n",
        "    for i in range(15, data.shape[0]):\n",
        "        grow = []\n",
        "      \n",
        "        s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "        s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "        s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "        s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "        s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "        s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "        s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "        s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "        s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "        s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "        s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "        s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "        s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "        s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "        s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "        s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "        s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "        s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "        s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "        s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "        s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "        s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "        s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "        s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "\n",
        "        \n",
        "        sugg = \"no\"\n",
        "        if data[i][3] > data[i][0]:\n",
        "            sugg = \"yes\"\n",
        "\n",
        "        grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "\n",
        "\n",
        "    grow = []\n",
        "    srow = []\n",
        "    llst = []\n",
        "    data = []\n",
        "    arr = []\n",
        "    mm = []\n",
        "\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  \n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 12:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "             \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        unattached_dfs.append(process(pd.read_csv(address)))\n",
        "     \n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\"solving...\")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               data = np.append(data, np.array(z), axis=0)\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "        \n",
        "     unattached_dfs = []\n",
        "  \n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIAuU_ILbU27",
        "outputId": "f5d0d2ae-dd63-43ce-a95b-02728471eca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " -- 100 -- 200 -- 300 -- 400 -- 500 -- 600 -- 700 -- 800 -- 900 -- 1000 -- 1100 -- 1200 -- 1300 -- 1400 -- 1500 \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "#symbols = read_txt_list()\n",
        "#symbols = read_syms_from_txt()\n",
        "#symbols = [\"msft\",\"aapl\",\"goog\"]\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"max\",\"1mo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qBYzyyUKHQQ"
      },
      "outputs": [],
      "source": [
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN93WT9e8ueQ",
        "outputId": "ea87ccc2-a421-464e-8ecc-3d34b38f49a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 512)               25088     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,339,394\n",
            "Trainable params: 1,339,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(512, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBxPzRd89uy",
        "outputId": "df611d5b-b835-4202-e43c-eeb0d492565c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.5533 - accuracy: 0.7061 - val_loss: 0.4848 - val_accuracy: 0.7608\n",
            "Epoch 2/30\n",
            "1018/1018 [==============================] - 17s 17ms/step - loss: 0.4549 - accuracy: 0.7793 - val_loss: 0.4239 - val_accuracy: 0.7988\n",
            "Epoch 3/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.3847 - accuracy: 0.8253 - val_loss: 0.3640 - val_accuracy: 0.8396\n",
            "Epoch 4/30\n",
            "1018/1018 [==============================] - 17s 17ms/step - loss: 0.2976 - accuracy: 0.8747 - val_loss: 0.3119 - val_accuracy: 0.8704\n",
            "Epoch 5/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.2280 - accuracy: 0.9102 - val_loss: 0.2517 - val_accuracy: 0.9027\n",
            "Epoch 6/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.1761 - accuracy: 0.9331 - val_loss: 0.2015 - val_accuracy: 0.9302\n",
            "Epoch 7/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.1397 - accuracy: 0.9491 - val_loss: 0.2283 - val_accuracy: 0.9183\n",
            "Epoch 8/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.1158 - accuracy: 0.9585 - val_loss: 0.1743 - val_accuracy: 0.9447\n",
            "Epoch 9/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.1003 - accuracy: 0.9647 - val_loss: 0.1652 - val_accuracy: 0.9504\n",
            "Epoch 10/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0866 - accuracy: 0.9691 - val_loss: 0.1838 - val_accuracy: 0.9448\n",
            "Epoch 11/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0779 - accuracy: 0.9724 - val_loss: 0.1843 - val_accuracy: 0.9479\n",
            "Epoch 12/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.1718 - val_accuracy: 0.9493\n",
            "Epoch 13/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.1823 - val_accuracy: 0.9555\n",
            "Epoch 14/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0542 - accuracy: 0.9796 - val_loss: 0.1985 - val_accuracy: 0.9559\n",
            "Epoch 15/30\n",
            "1018/1018 [==============================] - 18s 18ms/step - loss: 0.0516 - accuracy: 0.9800 - val_loss: 0.2312 - val_accuracy: 0.9496\n",
            "Epoch 16/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 0.2145 - val_accuracy: 0.9561\n",
            "Epoch 17/30\n",
            "1018/1018 [==============================] - 18s 18ms/step - loss: 0.0442 - accuracy: 0.9823 - val_loss: 0.2092 - val_accuracy: 0.9585\n",
            "Epoch 18/30\n",
            "1018/1018 [==============================] - 18s 18ms/step - loss: 0.0413 - accuracy: 0.9839 - val_loss: 0.2370 - val_accuracy: 0.9589\n",
            "Epoch 19/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0398 - accuracy: 0.9839 - val_loss: 0.2200 - val_accuracy: 0.9516\n",
            "Epoch 20/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0385 - accuracy: 0.9847 - val_loss: 0.2311 - val_accuracy: 0.9571\n",
            "Epoch 21/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0384 - accuracy: 0.9833 - val_loss: 0.2463 - val_accuracy: 0.9579\n",
            "Epoch 22/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0364 - accuracy: 0.9844 - val_loss: 0.2527 - val_accuracy: 0.9606\n",
            "Epoch 23/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0358 - accuracy: 0.9850 - val_loss: 0.2503 - val_accuracy: 0.9580\n",
            "Epoch 24/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0337 - accuracy: 0.9861 - val_loss: 0.2366 - val_accuracy: 0.9598\n",
            "Epoch 25/30\n",
            "1018/1018 [==============================] - 18s 18ms/step - loss: 0.0365 - accuracy: 0.9845 - val_loss: 0.2445 - val_accuracy: 0.9591\n",
            "Epoch 26/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0336 - accuracy: 0.9859 - val_loss: 0.2403 - val_accuracy: 0.9581\n",
            "Epoch 27/30\n",
            "1018/1018 [==============================] - 20s 20ms/step - loss: 0.0325 - accuracy: 0.9858 - val_loss: 0.2640 - val_accuracy: 0.9596\n",
            "Epoch 28/30\n",
            "1018/1018 [==============================] - 17s 17ms/step - loss: 0.0340 - accuracy: 0.9864 - val_loss: 0.2880 - val_accuracy: 0.9550\n",
            "Epoch 29/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0322 - accuracy: 0.9866 - val_loss: 0.2844 - val_accuracy: 0.9612\n",
            "Epoch 30/30\n",
            "1018/1018 [==============================] - 18s 17ms/step - loss: 0.0328 - accuracy: 0.9864 - val_loss: 0.2615 - val_accuracy: 0.9613\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f771a0fdc10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=30,batch_size=32,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"monthly_crypto_96_xts1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6bqkwjROb3lL",
        "outputId": "33d1042c-3245-45ea-b21b-3b0d30b89fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Open          High           Low  \\\n",
              "Datetime                                                              \n",
              "2022-04-29 00:00:00+00:00  39768.617188  39817.078125  39744.535156   \n",
              "2022-04-29 00:15:00+00:00  39815.914062  39830.531250  39807.500000   \n",
              "2022-04-29 00:30:00+00:00  39776.433594  39776.433594  39730.691406   \n",
              "2022-04-29 00:45:00+00:00  39726.808594  39777.898438  39704.660156   \n",
              "2022-04-29 01:00:00+00:00  39815.343750  39836.285156  39815.343750   \n",
              "2022-04-29 01:15:00+00:00  39840.023438  39874.695312  39828.148438   \n",
              "2022-04-29 01:30:00+00:00  39887.269531  39887.269531  39848.953125   \n",
              "2022-04-29 01:45:00+00:00  39848.152344  39848.152344  39790.625000   \n",
              "2022-04-29 02:00:00+00:00  39815.246094  39821.156250  39770.019531   \n",
              "2022-04-29 02:15:00+00:00  39785.300781  39785.300781  39686.406250   \n",
              "2022-04-29 02:30:00+00:00  39692.570312  39696.390625  39683.644531   \n",
              "2022-04-29 02:45:00+00:00  39689.734375  39721.339844  39533.644531   \n",
              "2022-04-29 03:00:00+00:00  39540.828125  39545.496094  39509.773438   \n",
              "2022-04-29 03:15:00+00:00  39452.703125  39460.746094  39410.058594   \n",
              "2022-04-29 03:30:00+00:00  39461.578125  39520.503906  39436.550781   \n",
              "2022-04-29 03:45:00+00:00  39505.714844  39508.167969  39475.558594   \n",
              "2022-04-29 04:00:00+00:00  39501.160156  39522.230469  39446.148438   \n",
              "2022-04-29 04:15:00+00:00  39479.625000  39479.625000  39418.507812   \n",
              "2022-04-29 04:30:00+00:00  39477.371094  39514.496094  39469.914062   \n",
              "2022-04-29 04:45:00+00:00  39515.066406  39563.062500  39515.066406   \n",
              "2022-04-29 05:00:00+00:00  39555.625000  39593.578125  39544.339844   \n",
              "2022-04-29 05:15:00+00:00  39547.507812  39603.835938  39547.507812   \n",
              "2022-04-29 05:30:00+00:00  39592.222656  39592.222656  39567.578125   \n",
              "2022-04-29 05:45:00+00:00  39571.187500  39571.187500  39509.949219   \n",
              "2022-04-29 06:00:00+00:00  39507.710938  39521.703125  39441.917969   \n",
              "2022-04-29 06:15:00+00:00  39461.585938  39503.851562  39449.324219   \n",
              "2022-04-29 06:30:00+00:00  39517.375000  39558.953125  39507.585938   \n",
              "2022-04-29 06:45:00+00:00  39552.523438  39552.523438  39507.000000   \n",
              "2022-04-29 07:00:00+00:00  39505.796875  39505.796875  39461.402344   \n",
              "2022-04-29 07:15:00+00:00  39484.097656  39510.476562  39463.605469   \n",
              "2022-04-29 07:30:00+00:00  39522.156250  39567.562500  39522.156250   \n",
              "2022-04-29 07:45:00+00:00  39564.582031  39579.304688  39557.339844   \n",
              "2022-04-29 08:00:00+00:00  39584.148438  39603.105469  39565.667969   \n",
              "2022-04-29 08:15:00+00:00  39578.773438  39578.773438  39511.476562   \n",
              "2022-04-29 08:30:00+00:00  39523.976562  39524.589844  39455.675781   \n",
              "2022-04-29 08:45:00+00:00  39461.070312  39466.074219  39426.089844   \n",
              "2022-04-29 09:00:00+00:00  39426.621094  39426.621094  39411.703125   \n",
              "2022-04-29 09:03:00+00:00  39375.222656  39375.222656  39375.222656   \n",
              "\n",
              "                                  Close     Adj Close     Volume  \n",
              "Datetime                                                          \n",
              "2022-04-29 00:00:00+00:00  39817.078125  39817.078125  139550720  \n",
              "2022-04-29 00:15:00+00:00  39807.500000  39807.500000  214714368  \n",
              "2022-04-29 00:30:00+00:00  39730.691406  39730.691406   20400128  \n",
              "2022-04-29 00:45:00+00:00  39777.898438  39777.898438   83261440  \n",
              "2022-04-29 01:00:00+00:00  39834.808594  39834.808594   42944512  \n",
              "2022-04-29 01:15:00+00:00  39874.695312  39874.695312   24004608  \n",
              "2022-04-29 01:30:00+00:00  39851.039062  39851.039062   26449920  \n",
              "2022-04-29 01:45:00+00:00  39795.093750  39795.093750          0  \n",
              "2022-04-29 02:00:00+00:00  39807.128906  39807.128906   76507136  \n",
              "2022-04-29 02:15:00+00:00  39687.773438  39687.773438   55580672  \n",
              "2022-04-29 02:30:00+00:00  39687.214844  39687.214844   37574656  \n",
              "2022-04-29 02:45:00+00:00  39533.644531  39533.644531  112439296  \n",
              "2022-04-29 03:00:00+00:00  39509.773438  39509.773438   82055168  \n",
              "2022-04-29 03:15:00+00:00  39454.859375  39454.859375  123062272  \n",
              "2022-04-29 03:30:00+00:00  39515.203125  39515.203125   90701824  \n",
              "2022-04-29 03:45:00+00:00  39501.593750  39501.593750   21354496  \n",
              "2022-04-29 04:00:00+00:00  39490.191406  39490.191406  117667840  \n",
              "2022-04-29 04:15:00+00:00  39469.515625  39469.515625  122662912  \n",
              "2022-04-29 04:30:00+00:00  39513.253906  39513.253906  148353024  \n",
              "2022-04-29 04:45:00+00:00  39560.375000  39560.375000  116551680  \n",
              "2022-04-29 05:00:00+00:00  39544.339844  39544.339844  101138432  \n",
              "2022-04-29 05:15:00+00:00  39602.058594  39602.058594  142434304  \n",
              "2022-04-29 05:30:00+00:00  39568.496094  39568.496094   27332608  \n",
              "2022-04-29 05:45:00+00:00  39509.949219  39509.949219   49934336  \n",
              "2022-04-29 06:00:00+00:00  39441.917969  39441.917969   96485376  \n",
              "2022-04-29 06:15:00+00:00  39503.851562  39503.851562   94171136  \n",
              "2022-04-29 06:30:00+00:00  39549.519531  39549.519531  125059072  \n",
              "2022-04-29 06:45:00+00:00  39507.000000  39507.000000   23261184  \n",
              "2022-04-29 07:00:00+00:00  39493.671875  39493.671875   70033408  \n",
              "2022-04-29 07:15:00+00:00  39510.109375  39510.109375   77676544  \n",
              "2022-04-29 07:30:00+00:00  39565.960938  39565.960938   15921152  \n",
              "2022-04-29 07:45:00+00:00  39579.304688  39579.304688    2777088  \n",
              "2022-04-29 08:00:00+00:00  39565.667969  39565.667969   17186816  \n",
              "2022-04-29 08:15:00+00:00  39511.476562  39511.476562   14303232  \n",
              "2022-04-29 08:30:00+00:00  39464.203125  39464.203125          0  \n",
              "2022-04-29 08:45:00+00:00  39426.089844  39426.089844   24203264  \n",
              "2022-04-29 09:00:00+00:00  39411.703125  39411.703125          0  \n",
              "2022-04-29 09:03:00+00:00  39375.222656  39375.222656          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-568ea267-cc5f-49f8-9d2e-78a01db3d3f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:00:00+00:00</th>\n",
              "      <td>39768.617188</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>39744.535156</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>39817.078125</td>\n",
              "      <td>139550720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:15:00+00:00</th>\n",
              "      <td>39815.914062</td>\n",
              "      <td>39830.531250</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>39807.500000</td>\n",
              "      <td>214714368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:30:00+00:00</th>\n",
              "      <td>39776.433594</td>\n",
              "      <td>39776.433594</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>39730.691406</td>\n",
              "      <td>20400128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 00:45:00+00:00</th>\n",
              "      <td>39726.808594</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>39704.660156</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>39777.898438</td>\n",
              "      <td>83261440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 01:00:00+00:00</th>\n",
              "      <td>39815.343750</td>\n",
              "      <td>39836.285156</td>\n",
              "      <td>39815.343750</td>\n",
              "      <td>39834.808594</td>\n",
              "      <td>39834.808594</td>\n",
              "      <td>42944512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 01:15:00+00:00</th>\n",
              "      <td>39840.023438</td>\n",
              "      <td>39874.695312</td>\n",
              "      <td>39828.148438</td>\n",
              "      <td>39874.695312</td>\n",
              "      <td>39874.695312</td>\n",
              "      <td>24004608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 01:30:00+00:00</th>\n",
              "      <td>39887.269531</td>\n",
              "      <td>39887.269531</td>\n",
              "      <td>39848.953125</td>\n",
              "      <td>39851.039062</td>\n",
              "      <td>39851.039062</td>\n",
              "      <td>26449920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 01:45:00+00:00</th>\n",
              "      <td>39848.152344</td>\n",
              "      <td>39848.152344</td>\n",
              "      <td>39790.625000</td>\n",
              "      <td>39795.093750</td>\n",
              "      <td>39795.093750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 02:00:00+00:00</th>\n",
              "      <td>39815.246094</td>\n",
              "      <td>39821.156250</td>\n",
              "      <td>39770.019531</td>\n",
              "      <td>39807.128906</td>\n",
              "      <td>39807.128906</td>\n",
              "      <td>76507136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 02:15:00+00:00</th>\n",
              "      <td>39785.300781</td>\n",
              "      <td>39785.300781</td>\n",
              "      <td>39686.406250</td>\n",
              "      <td>39687.773438</td>\n",
              "      <td>39687.773438</td>\n",
              "      <td>55580672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 02:30:00+00:00</th>\n",
              "      <td>39692.570312</td>\n",
              "      <td>39696.390625</td>\n",
              "      <td>39683.644531</td>\n",
              "      <td>39687.214844</td>\n",
              "      <td>39687.214844</td>\n",
              "      <td>37574656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 02:45:00+00:00</th>\n",
              "      <td>39689.734375</td>\n",
              "      <td>39721.339844</td>\n",
              "      <td>39533.644531</td>\n",
              "      <td>39533.644531</td>\n",
              "      <td>39533.644531</td>\n",
              "      <td>112439296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 03:00:00+00:00</th>\n",
              "      <td>39540.828125</td>\n",
              "      <td>39545.496094</td>\n",
              "      <td>39509.773438</td>\n",
              "      <td>39509.773438</td>\n",
              "      <td>39509.773438</td>\n",
              "      <td>82055168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 03:15:00+00:00</th>\n",
              "      <td>39452.703125</td>\n",
              "      <td>39460.746094</td>\n",
              "      <td>39410.058594</td>\n",
              "      <td>39454.859375</td>\n",
              "      <td>39454.859375</td>\n",
              "      <td>123062272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 03:30:00+00:00</th>\n",
              "      <td>39461.578125</td>\n",
              "      <td>39520.503906</td>\n",
              "      <td>39436.550781</td>\n",
              "      <td>39515.203125</td>\n",
              "      <td>39515.203125</td>\n",
              "      <td>90701824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 03:45:00+00:00</th>\n",
              "      <td>39505.714844</td>\n",
              "      <td>39508.167969</td>\n",
              "      <td>39475.558594</td>\n",
              "      <td>39501.593750</td>\n",
              "      <td>39501.593750</td>\n",
              "      <td>21354496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 04:00:00+00:00</th>\n",
              "      <td>39501.160156</td>\n",
              "      <td>39522.230469</td>\n",
              "      <td>39446.148438</td>\n",
              "      <td>39490.191406</td>\n",
              "      <td>39490.191406</td>\n",
              "      <td>117667840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 04:15:00+00:00</th>\n",
              "      <td>39479.625000</td>\n",
              "      <td>39479.625000</td>\n",
              "      <td>39418.507812</td>\n",
              "      <td>39469.515625</td>\n",
              "      <td>39469.515625</td>\n",
              "      <td>122662912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 04:30:00+00:00</th>\n",
              "      <td>39477.371094</td>\n",
              "      <td>39514.496094</td>\n",
              "      <td>39469.914062</td>\n",
              "      <td>39513.253906</td>\n",
              "      <td>39513.253906</td>\n",
              "      <td>148353024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 04:45:00+00:00</th>\n",
              "      <td>39515.066406</td>\n",
              "      <td>39563.062500</td>\n",
              "      <td>39515.066406</td>\n",
              "      <td>39560.375000</td>\n",
              "      <td>39560.375000</td>\n",
              "      <td>116551680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 05:00:00+00:00</th>\n",
              "      <td>39555.625000</td>\n",
              "      <td>39593.578125</td>\n",
              "      <td>39544.339844</td>\n",
              "      <td>39544.339844</td>\n",
              "      <td>39544.339844</td>\n",
              "      <td>101138432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 05:15:00+00:00</th>\n",
              "      <td>39547.507812</td>\n",
              "      <td>39603.835938</td>\n",
              "      <td>39547.507812</td>\n",
              "      <td>39602.058594</td>\n",
              "      <td>39602.058594</td>\n",
              "      <td>142434304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 05:30:00+00:00</th>\n",
              "      <td>39592.222656</td>\n",
              "      <td>39592.222656</td>\n",
              "      <td>39567.578125</td>\n",
              "      <td>39568.496094</td>\n",
              "      <td>39568.496094</td>\n",
              "      <td>27332608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 05:45:00+00:00</th>\n",
              "      <td>39571.187500</td>\n",
              "      <td>39571.187500</td>\n",
              "      <td>39509.949219</td>\n",
              "      <td>39509.949219</td>\n",
              "      <td>39509.949219</td>\n",
              "      <td>49934336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 06:00:00+00:00</th>\n",
              "      <td>39507.710938</td>\n",
              "      <td>39521.703125</td>\n",
              "      <td>39441.917969</td>\n",
              "      <td>39441.917969</td>\n",
              "      <td>39441.917969</td>\n",
              "      <td>96485376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 06:15:00+00:00</th>\n",
              "      <td>39461.585938</td>\n",
              "      <td>39503.851562</td>\n",
              "      <td>39449.324219</td>\n",
              "      <td>39503.851562</td>\n",
              "      <td>39503.851562</td>\n",
              "      <td>94171136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 06:30:00+00:00</th>\n",
              "      <td>39517.375000</td>\n",
              "      <td>39558.953125</td>\n",
              "      <td>39507.585938</td>\n",
              "      <td>39549.519531</td>\n",
              "      <td>39549.519531</td>\n",
              "      <td>125059072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 06:45:00+00:00</th>\n",
              "      <td>39552.523438</td>\n",
              "      <td>39552.523438</td>\n",
              "      <td>39507.000000</td>\n",
              "      <td>39507.000000</td>\n",
              "      <td>39507.000000</td>\n",
              "      <td>23261184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 07:00:00+00:00</th>\n",
              "      <td>39505.796875</td>\n",
              "      <td>39505.796875</td>\n",
              "      <td>39461.402344</td>\n",
              "      <td>39493.671875</td>\n",
              "      <td>39493.671875</td>\n",
              "      <td>70033408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 07:15:00+00:00</th>\n",
              "      <td>39484.097656</td>\n",
              "      <td>39510.476562</td>\n",
              "      <td>39463.605469</td>\n",
              "      <td>39510.109375</td>\n",
              "      <td>39510.109375</td>\n",
              "      <td>77676544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 07:30:00+00:00</th>\n",
              "      <td>39522.156250</td>\n",
              "      <td>39567.562500</td>\n",
              "      <td>39522.156250</td>\n",
              "      <td>39565.960938</td>\n",
              "      <td>39565.960938</td>\n",
              "      <td>15921152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 07:45:00+00:00</th>\n",
              "      <td>39564.582031</td>\n",
              "      <td>39579.304688</td>\n",
              "      <td>39557.339844</td>\n",
              "      <td>39579.304688</td>\n",
              "      <td>39579.304688</td>\n",
              "      <td>2777088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 08:00:00+00:00</th>\n",
              "      <td>39584.148438</td>\n",
              "      <td>39603.105469</td>\n",
              "      <td>39565.667969</td>\n",
              "      <td>39565.667969</td>\n",
              "      <td>39565.667969</td>\n",
              "      <td>17186816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 08:15:00+00:00</th>\n",
              "      <td>39578.773438</td>\n",
              "      <td>39578.773438</td>\n",
              "      <td>39511.476562</td>\n",
              "      <td>39511.476562</td>\n",
              "      <td>39511.476562</td>\n",
              "      <td>14303232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 08:30:00+00:00</th>\n",
              "      <td>39523.976562</td>\n",
              "      <td>39524.589844</td>\n",
              "      <td>39455.675781</td>\n",
              "      <td>39464.203125</td>\n",
              "      <td>39464.203125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 08:45:00+00:00</th>\n",
              "      <td>39461.070312</td>\n",
              "      <td>39466.074219</td>\n",
              "      <td>39426.089844</td>\n",
              "      <td>39426.089844</td>\n",
              "      <td>39426.089844</td>\n",
              "      <td>24203264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:00:00+00:00</th>\n",
              "      <td>39426.621094</td>\n",
              "      <td>39426.621094</td>\n",
              "      <td>39411.703125</td>\n",
              "      <td>39411.703125</td>\n",
              "      <td>39411.703125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-29 09:03:00+00:00</th>\n",
              "      <td>39375.222656</td>\n",
              "      <td>39375.222656</td>\n",
              "      <td>39375.222656</td>\n",
              "      <td>39375.222656</td>\n",
              "      <td>39375.222656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-568ea267-cc5f-49f8-9d2e-78a01db3d3f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-568ea267-cc5f-49f8-9d2e-78a01db3d3f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-568ea267-cc5f-49f8-9d2e-78a01db3d3f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "data = yf.download(\"btc-usd\",period=\"1d\",interval=\"15m\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    if len(pd.DataFrame(data).columns) == 7:\n",
        "      data = data.iloc[: , 1:]        \n",
        "    data = np.array(data)\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "\n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "  if timeframe == \"5m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))    \n",
        "  if timeframe == \"15m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1h\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1d\":\n",
        "    data = yf.download(symbol,period=\"20d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1wk\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"1m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"2m\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"30m\":\n",
        "    data = yf.download(symbol,period=\"1d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"5d\":\n",
        "    data = yf.download(symbol,period=\"5mo\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"90m\":\n",
        "    data = yf.download(symbol,period=\"5d\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  \n",
        "  if timeframe == \"3mo\":\n",
        "    data = yf.download(symbol,period=\"max\",interval=timeframe)\n",
        "    lst = [str(i) for i in data.index.values]\n",
        "    ddata = process_for_prediction(data)\n",
        "    return(model.predict(ddata))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUzTsN-SfnH",
        "outputId": "fb427ec3-9d10-4d2b-e89d-eb4bc1d0dd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1422633e-06, 9.9993634e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ],
      "source": [
        "make_prediction(\"btc-usd\",\"15m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "    i = -1\n",
        "    row = []\n",
        "    data.drop(\"symbol\",axis=1,inplace=True)   \n",
        "    data = np.array(data)\n",
        "    llst = [0, 1, 2, 3, 4]\n",
        "    grow = []\n",
        "      \n",
        "    s12 = [ \n",
        "            data[i-12][0], data[i-12][1], data[i-12][2], data[i-12][3]\n",
        "        ]\n",
        "    s11 = [\n",
        "            data[i-11][0], data[i-11][1], data[i-11][2], data[i-11][3]\n",
        "        ]\n",
        "    s10 = [\n",
        "            data[i-10][0], data[i-10][1], data[i-10][2], data[i-10][3]\n",
        "        ]\n",
        "    s9 = [\n",
        "            data[i-9][0], data[i-9][1], data[i-9][2], data[i-9][3]\n",
        "        ]\n",
        "    s8 = [\n",
        "            data[i-8][0], data[i-8][1], data[i-8][2], data[i-8][3]\n",
        "        ]\n",
        "    s7 = [\n",
        "            data[i-7][0], data[i-7][1], data[i-7][2], data[i-7][3]\n",
        "        ]\n",
        "    s6 = [\n",
        "            data[i-6][0], data[i-6][1], data[i-6][2], data[i-6][3]\n",
        "        ]\n",
        "    s5 = [\n",
        "            data[i-5][0], data[i-5][1], data[i-5][2], data[i-5][3]\n",
        "        ]   \n",
        "    s4 = [\n",
        "            data[i-4][0], data[i-4][1], data[i-4][2], data[i-4][3]\n",
        "        ]\n",
        "    s3 = [\n",
        "            data[i-3][0], data[i-3][1], data[i-3][2], data[i-3][3]\n",
        "        ]\n",
        "    s2 = [\n",
        "            data[i-2][0], data[i-2][1], data[i-2][2], data[i-2][3]\n",
        "        ]\n",
        "    s1 = [\n",
        "            data[i-1][0], data[i-1][1], data[i-1][2], data[i-1][3]\n",
        "        ]\n",
        "        \n",
        "\n",
        "    s1 = scaler(np.array(s1).reshape(-1,1))\n",
        "    s2 = scaler(np.array(s2).reshape(-1,1))\n",
        "    s3 = scaler(np.array(s3).reshape(-1,1))\n",
        "    s4 = scaler(np.array(s4).reshape(-1,1))\n",
        "    s5 = scaler(np.array(s5).reshape(-1,1))\n",
        "    s6 = scaler(np.array(s6).reshape(-1,1))\n",
        "    s7 = scaler(np.array(s7).reshape(-1,1))\n",
        "    s8 = scaler(np.array(s8).reshape(-1,1))\n",
        "    s9 = scaler(np.array(s9).reshape(-1,1))\n",
        "    s10 = scaler(np.array(s10).reshape(-1,1))\n",
        "    s11 = scaler(np.array(s11).reshape(-1,1))\n",
        "    s12 = scaler(np.array(s12).reshape(-1,1))\n",
        "\n",
        "        \n",
        "\n",
        "    grow = np.vstack((s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12))\n",
        "\n",
        "    arr = np.array(grow).flatten()\n",
        "    row.append(arr)\n",
        "\n",
        "    return np.array(row)\n",
        "def make_prediction(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcUSD',exchange='Bitstamp',interval=Interval.in_15_minute,n_bars=30)\n",
        "   return model.predict(process_for_prediction(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgPS4HGIpgT",
        "outputId": "10691acc-3627-4a8f-bd50-4d7e15747839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11967599, 0.7307208 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ],
      "source": [
        "make_prediction(\"s\",\"x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CGI7G0bxqG",
        "outputId": "6465f01c-3a1d-4675-8dc8-db6ec4f5ee45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CM_8G1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5bxbCoe9do9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d820d614-fc5e-4714-cbdb-84abcf593cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 30.9 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 43.5 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.11 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=19a9012074eb69f28cf9a01107611473ea95ddac9cb652911dd37f9676a99dba\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install mplfinance\n",
        "!pip install cairocffi\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib notebook\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "def get_crypto_syms():\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   return symbols\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3]-data[i+z][0])\n",
        "        next_candles = sum(next_candles)\n",
        "        if next_candles > 0:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clf()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 20:\n",
        "          plt.close(\"all\")\n",
        "        if i % 270 ==0:\n",
        "          print(\"\")\n",
        "    plt.close(\"all\")\n",
        "    print(\"\")\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AMR8z1BIS-M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315e8eac-2983-4c64-a7ef-f72c29126e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"max\",\"1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TxTyv_osQAnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587ecf60-950f-4e3c-c2e1-3d672595a2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 90/1715 100/1715 110/1715 120/1715 130/1715 140/1715 150/1715 160/1715 170/1715 180/1715 190/1715 200/1715 210/1715 220/1715 230/1715 240/1715 250/1715 260/1715 270/1715 \n",
            "280/1715 290/1715 300/1715 310/1715 320/1715 330/1715 340/1715 350/1715 360/1715 370/1715 380/1715 390/1715 400/1715 410/1715 420/1715 430/1715 440/1715 450/1715 460/1715 470/1715 480/1715 490/1715 500/1715 510/1715 520/1715 530/1715 540/1715 \n",
            "550/1715 560/1715 570/1715 580/1715 590/1715 600/1715 610/1715 620/1715 630/1715 640/1715 650/1715 660/1715 670/1715 680/1715 690/1715 700/1715 710/1715 720/1715 730/1715 740/1715 750/1715 760/1715 770/1715 780/1715 790/1715 800/1715 810/1715 \n",
            "820/1715 830/1715 840/1715 850/1715 860/1715 870/1715 880/1715 890/1715 900/1715 910/1715 920/1715 930/1715 940/1715 950/1715 960/1715 970/1715 980/1715 990/1715 1000/1715 1010/1715 1020/1715 1030/1715 1040/1715 1050/1715 1060/1715 1070/1715 1080/1715 \n",
            "1090/1715 1100/1715 1110/1715 1120/1715 1130/1715 1140/1715 1150/1715 1160/1715 1170/1715 1180/1715 1190/1715 1200/1715 1210/1715 1220/1715 1230/1715 1240/1715 1250/1715 1260/1715 1270/1715 1280/1715 1290/1715 1300/1715 1310/1715 1320/1715 1330/1715 1340/1715 1350/1715 \n",
            "1360/1715 1370/1715 1380/1715 1390/1715 1400/1715 1410/1715 1420/1715 1430/1715 1440/1715 1450/1715 1460/1715 1470/1715 1480/1715 1490/1715 1500/1715 1510/1715 1520/1715 1530/1715 1540/1715 1550/1715 1560/1715 1570/1715 1580/1715 1590/1715 1600/1715 1610/1715 1620/1715 \n",
            "1630/1715 1640/1715 1650/1715 1660/1715 1670/1715 1680/1715 1690/1715 1700/1715 1710/1715 \n",
            "File Number 2: 90/1715 100/1715 110/1715 120/1715 130/1715 140/1715 150/1715 160/1715 170/1715 180/1715 190/1715 200/1715 210/1715 220/1715 230/1715 240/1715 250/1715 260/1715 270/1715 \n",
            "280/1715 290/1715 300/1715 310/1715 320/1715 330/1715 340/1715 350/1715 360/1715 370/1715 380/1715 390/1715 400/1715 410/1715 420/1715 430/1715 440/1715 450/1715 460/1715 470/1715 480/1715 490/1715 500/1715 510/1715 520/1715 530/1715 540/1715 \n",
            "550/1715 560/1715 570/1715 580/1715 590/1715 600/1715 610/1715 620/1715 630/1715 640/1715 650/1715 660/1715 670/1715 680/1715 690/1715 700/1715 710/1715 720/1715 730/1715 740/1715 750/1715 760/1715 770/1715 780/1715 790/1715 800/1715 810/1715 \n",
            "820/1715 830/1715 840/1715 850/1715 860/1715 870/1715 880/1715 890/1715 900/1715 910/1715 920/1715 930/1715 940/1715 950/1715 960/1715 970/1715 980/1715 990/1715 1000/1715 1010/1715 1020/1715 1030/1715 1040/1715 1050/1715 1060/1715 1070/1715 1080/1715 \n",
            "1090/1715 1100/1715 1110/1715 1120/1715 1130/1715 1140/1715 1150/1715 1160/1715 1170/1715 1180/1715 1190/1715 1200/1715 1210/1715 1220/1715 1230/1715 1240/1715 1250/1715 1260/1715 1270/1715 1280/1715 1290/1715 1300/1715 1310/1715 1320/1715 1330/1715 1340/1715 1350/1715 \n",
            "1360/1715 1370/1715 1380/1715 1390/1715 1400/1715 1410/1715 1420/1715 1430/1715 1440/1715 1450/1715 1460/1715 1470/1715 1480/1715 1490/1715 1500/1715 1510/1715 1520/1715 1530/1715 1540/1715 1550/1715 1560/1715 1570/1715 1580/1715 1590/1715 1600/1715 1610/1715 1620/1715 \n",
            "1630/1715 1640/1715 1650/1715 1660/1715 1670/1715 1680/1715 1690/1715 1700/1715 1710/1715 \n",
            "File Number 3: 90/2864 100/2864 110/2864 120/2864 130/2864 140/2864 150/2864 160/2864 170/2864 180/2864 190/2864 200/2864 210/2864 220/2864 230/2864 240/2864 250/2864 260/2864 270/2864 \n",
            "280/2864 290/2864 300/2864 310/2864 320/2864 330/2864 340/2864 350/2864 360/2864 370/2864 380/2864 390/2864 400/2864 410/2864 420/2864 430/2864 440/2864 450/2864 460/2864 470/2864 480/2864 490/2864 500/2864 510/2864 520/2864 530/2864 540/2864 \n",
            "550/2864 560/2864 570/2864 580/2864 590/2864 600/2864 610/2864 620/2864 630/2864 640/2864 650/2864 660/2864 670/2864 680/2864 690/2864 700/2864 710/2864 720/2864 730/2864 740/2864 750/2864 760/2864 770/2864 780/2864 790/2864 800/2864 810/2864 \n",
            "820/2864 830/2864 840/2864 850/2864 860/2864 870/2864 880/2864 890/2864 900/2864 910/2864 920/2864 930/2864 940/2864 950/2864 960/2864 970/2864 980/2864 990/2864 1000/2864 1010/2864 1020/2864 1030/2864 1040/2864 1050/2864 1060/2864 1070/2864 1080/2864 \n",
            "1090/2864 1100/2864 1110/2864 1120/2864 1130/2864 1140/2864 1150/2864 1160/2864 1170/2864 1180/2864 1190/2864 1200/2864 1210/2864 1220/2864 1230/2864 1240/2864 1250/2864 1260/2864 1270/2864 1280/2864 1290/2864 1300/2864 1310/2864 1320/2864 1330/2864 1340/2864 1350/2864 \n",
            "1360/2864 1370/2864 1380/2864 1390/2864 1400/2864 1410/2864 1420/2864 1430/2864 1440/2864 1450/2864 1460/2864 1470/2864 1480/2864 1490/2864 1500/2864 1510/2864 1520/2864 1530/2864 1540/2864 1550/2864 1560/2864 1570/2864 1580/2864 1590/2864 1600/2864 1610/2864 1620/2864 \n",
            "1630/2864 1640/2864 1650/2864 1660/2864 1670/2864 1680/2864 1690/2864 1700/2864 1710/2864 1720/2864 1730/2864 1740/2864 1750/2864 1760/2864 1770/2864 1780/2864 1790/2864 1800/2864 1810/2864 1820/2864 1830/2864 1840/2864 1850/2864 1860/2864 1870/2864 1880/2864 1890/2864 \n",
            "1900/2864 1910/2864 1920/2864 1930/2864 1940/2864 1950/2864 1960/2864 1970/2864 1980/2864 1990/2864 2000/2864 2010/2864 2020/2864 2030/2864 2040/2864 2050/2864 2060/2864 2070/2864 2080/2864 2090/2864 2100/2864 2110/2864 2120/2864 2130/2864 2140/2864 2150/2864 2160/2864 \n",
            "2170/2864 2180/2864 2190/2864 2200/2864 2210/2864 2220/2864 2230/2864 2240/2864 2250/2864 2260/2864 2270/2864 2280/2864 2290/2864 2300/2864 2310/2864 2320/2864 2330/2864 2340/2864 2350/2864 2360/2864 2370/2864 2380/2864 2390/2864 2400/2864 2410/2864 2420/2864 2430/2864 \n",
            "2440/2864 2450/2864 2460/2864 2470/2864 2480/2864 2490/2864 2500/2864 2510/2864 2520/2864 2530/2864 2540/2864 2550/2864 2560/2864 2570/2864 2580/2864 2590/2864 2600/2864 2610/2864 2620/2864 2630/2864 2640/2864 2650/2864 2660/2864 2670/2864 2680/2864 2690/2864 2700/2864 \n",
            "2710/2864 2720/2864 2730/2864 2740/2864 2750/2864 2760/2864 2770/2864 2780/2864 2790/2864 2800/2864 2810/2864 2820/2864 2830/2864 2840/2864 2850/2864 2860/2864 \n",
            "File Number 4: 90/1715 100/1715 110/1715 120/1715 130/1715 140/1715 150/1715 160/1715 170/1715 180/1715 190/1715 200/1715 210/1715 220/1715 230/1715 240/1715 250/1715 260/1715 270/1715 \n",
            "280/1715 290/1715 300/1715 310/1715 320/1715 330/1715 340/1715 350/1715 360/1715 370/1715 380/1715 390/1715 400/1715 410/1715 420/1715 430/1715 440/1715 450/1715 460/1715 470/1715 480/1715 490/1715 500/1715 510/1715 520/1715 530/1715 540/1715 \n",
            "550/1715 560/1715 570/1715 580/1715 590/1715 600/1715 610/1715 620/1715 630/1715 640/1715 650/1715 660/1715 670/1715 680/1715 690/1715 700/1715 710/1715 720/1715 730/1715 740/1715 750/1715 760/1715 770/1715 780/1715 790/1715 800/1715 810/1715 \n",
            "820/1715 830/1715 840/1715 850/1715 860/1715 870/1715 880/1715 890/1715 900/1715 910/1715 920/1715 930/1715 940/1715 950/1715 960/1715 970/1715 980/1715 990/1715 1000/1715 1010/1715 1020/1715 1030/1715 1040/1715 1050/1715 1060/1715 1070/1715 1080/1715 \n",
            "1090/1715 1100/1715 1110/1715 1120/1715 1130/1715 1140/1715 1150/1715 1160/1715 1170/1715 1180/1715 1190/1715 1200/1715 1210/1715 1220/1715 1230/1715 1240/1715 1250/1715 1260/1715 1270/1715 1280/1715 1290/1715 1300/1715 1310/1715 1320/1715 1330/1715 1340/1715 1350/1715 \n",
            "1360/1715 1370/1715 1380/1715 1390/1715 1400/1715 1410/1715 1420/1715 1430/1715 1440/1715 1450/1715 1460/1715 1470/1715 1480/1715 1490/1715 1500/1715 1510/1715 1520/1715 1530/1715 1540/1715 1550/1715 1560/1715 1570/1715 1580/1715 1590/1715 1600/1715 1610/1715 1620/1715 \n",
            "1630/1715 1640/1715 1650/1715 1660/1715 1670/1715 1680/1715 1690/1715 1700/1715 1710/1715 \n",
            "File Number 5: 90/1715 100/1715 110/1715 120/1715 130/1715 140/1715 150/1715 160/1715 170/1715 180/1715 190/1715 200/1715 210/1715 220/1715 230/1715 240/1715 250/1715 260/1715 270/1715 \n",
            "280/1715 290/1715 300/1715 310/1715 320/1715 330/1715 340/1715 350/1715 360/1715 370/1715 380/1715 390/1715 400/1715 410/1715 420/1715 430/1715 440/1715 450/1715 460/1715 470/1715 480/1715 490/1715 500/1715 510/1715 520/1715 530/1715 540/1715 \n",
            "550/1715 560/1715 570/1715 580/1715 590/1715 600/1715 610/1715 620/1715 630/1715 640/1715 650/1715 660/1715 670/1715 680/1715 690/1715 700/1715 710/1715 720/1715 730/1715 740/1715 750/1715 760/1715 770/1715 780/1715 790/1715 800/1715 810/1715 \n",
            "820/1715 830/1715 840/1715 850/1715 860/1715 870/1715 880/1715 890/1715 900/1715 910/1715 920/1715 930/1715 940/1715 950/1715 960/1715 970/1715 980/1715 990/1715 1000/1715 1010/1715 1020/1715 1030/1715 1040/1715 1050/1715 1060/1715 1070/1715 1080/1715 \n",
            "1090/1715 1100/1715 1110/1715 1120/1715 1130/1715 1140/1715 1150/1715 1160/1715 1170/1715 1180/1715 1190/1715 1200/1715 1210/1715 1220/1715 1230/1715 1240/1715 1250/1715 1260/1715 1270/1715 1280/1715 1290/1715 1300/1715 1310/1715 1320/1715 1330/1715 1340/1715 1350/1715 \n",
            "1360/1715 1370/1715 1380/1715 1390/1715 1400/1715 1410/1715 1420/1715 1430/1715 1440/1715 1450/1715 1460/1715 1470/1715 1480/1715 1490/1715 1500/1715 1510/1715 1520/1715 1530/1715 1540/1715 1550/1715 1560/1715 1570/1715 1580/1715 1590/1715 1600/1715 1610/1715 1620/1715 \n",
            "1630/1715 1640/1715 1650/1715 1660/1715 1670/1715 1680/1715 1690/1715 1700/1715 1710/1715 \n",
            "File Number 6: 90/2864 100/2864 110/2864 120/2864 130/2864 140/2864 150/2864 160/2864 170/2864 180/2864 190/2864 200/2864 210/2864 220/2864 230/2864 240/2864 250/2864 260/2864 270/2864 \n",
            "280/2864 290/2864 300/2864 310/2864 320/2864 330/2864 340/2864 350/2864 360/2864 370/2864 380/2864 390/2864 400/2864 410/2864 420/2864 430/2864 440/2864 450/2864 460/2864 470/2864 480/2864 490/2864 500/2864 510/2864 520/2864 530/2864 540/2864 \n",
            "550/2864 560/2864 570/2864 580/2864 590/2864 600/2864 610/2864 620/2864 630/2864 640/2864 650/2864 660/2864 670/2864 680/2864 690/2864 700/2864 710/2864 720/2864 730/2864 740/2864 750/2864 760/2864 770/2864 780/2864 790/2864 800/2864 810/2864 \n",
            "820/2864 830/2864 840/2864 850/2864 860/2864 870/2864 880/2864 890/2864 900/2864 910/2864 920/2864 930/2864 940/2864 950/2864 960/2864 970/2864 980/2864 990/2864 1000/2864 1010/2864 1020/2864 1030/2864 1040/2864 1050/2864 1060/2864 1070/2864 1080/2864 \n",
            "1090/2864 1100/2864 1110/2864 1120/2864 1130/2864 1140/2864 1150/2864 1160/2864 1170/2864 1180/2864 1190/2864 1200/2864 1210/2864 1220/2864 1230/2864 1240/2864 1250/2864 1260/2864 1270/2864 1280/2864 1290/2864 1300/2864 1310/2864 1320/2864 1330/2864 1340/2864 1350/2864 \n",
            "1360/2864 1370/2864 1380/2864 1390/2864 1400/2864 1410/2864 1420/2864 1430/2864 1440/2864 1450/2864 1460/2864 1470/2864 1480/2864 1490/2864 1500/2864 1510/2864 1520/2864 1530/2864 1540/2864 1550/2864 1560/2864 1570/2864 1580/2864 1590/2864 1600/2864 1610/2864 1620/2864 \n",
            "1630/2864 1640/2864 1650/2864 1660/2864 1670/2864 1680/2864 1690/2864 1700/2864 1710/2864 1720/2864 1730/2864 1740/2864 1750/2864 1760/2864 1770/2864 1780/2864 1790/2864 1800/2864 1810/2864 1820/2864 1830/2864 1840/2864 1850/2864 1860/2864 1870/2864 1880/2864 1890/2864 \n",
            "1900/2864 1910/2864 1920/2864 1930/2864 1940/2864 1950/2864 1960/2864 1970/2864 1980/2864 1990/2864 2000/2864 2010/2864 2020/2864 2030/2864 2040/2864 2050/2864 2060/2864 2070/2864 2080/2864 2090/2864 2100/2864 2110/2864 2120/2864 2130/2864 2140/2864 2150/2864 2160/2864 \n",
            "2170/2864 2180/2864 2190/2864 2200/2864 2210/2864 2220/2864 2230/2864 2240/2864 2250/2864 2260/2864 2270/2864 2280/2864 2290/2864 2300/2864 2310/2864 2320/2864 2330/2864 2340/2864 2350/2864 2360/2864 2370/2864 2380/2864 2390/2864 2400/2864 2410/2864 2420/2864 2430/2864 \n",
            "2440/2864 2450/2864 2460/2864 2470/2864 2480/2864 2490/2864 2500/2864 2510/2864 2520/2864 2530/2864 2540/2864 2550/2864 2560/2864 2570/2864 2580/2864 2590/2864 2600/2864 2610/2864 2620/2864 2630/2864 2640/2864 2650/2864 2660/2864 2670/2864 2680/2864 2690/2864 2700/2864 \n",
            "2710/2864 2720/2864 2730/2864 2740/2864 2750/2864 2760/2864 2770/2864 2780/2864 2790/2864 2800/2864 2810/2864 2820/2864 2830/2864 2840/2864 2850/2864 2860/2864 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12048"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "how_many_future_candles = 10\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 80\n",
        "\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dQpQvhf-pwpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620a8d7f-eee7-4202-ea30-bd1a886e7c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12048, 128, 128)\n",
            "xTrain : 9638 \\ xTest : 2410\n",
            "yn: 6271 nn: 5777\n"
          ]
        }
      ],
      "source": [
        "#folder_name = \"165913\"\n",
        "\n",
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(f\"/content/{folder_name}.zip\",f\"/content/extracted/{folder_name}\")\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xTest,yTest)"
      ],
      "metadata": {
        "id": "qjRn1rKTEFSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7906ff2-95c0-4de8-873d-29ba3e54a0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 127, 127, 128)     640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 42, 42, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 41, 41, 32)        16416     \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 20, 20, 32)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 19, 19, 32)        4128      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 9, 9, 32)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 16)          2064      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 800)               820000    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 800)               640800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 750)               600750    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 750)               563250    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 1502      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,649,550\n",
            "Trainable params: 2,649,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128,     (2, 2),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1)))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Conv2D(32,      (2, 2),activation=\"relu\",)) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32,      (2, 2),activation=\"relu\",)) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16,      (2, 2),activation=\"relu\",)) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dense(750,activation=\"relu\"))\n",
        "model.add(Dense(750,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cytWxowTyInc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564323ae-21b9-4428-d3fb-24439a01d0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "603/603 [==============================] - 242s 400ms/step - loss: 0.6933 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5344\n",
            "Epoch 2/20\n",
            "603/603 [==============================] - 249s 413ms/step - loss: 0.6927 - accuracy: 0.5170 - val_loss: 0.6913 - val_accuracy: 0.5344\n",
            "Epoch 3/20\n",
            "603/603 [==============================] - 247s 410ms/step - loss: 0.6927 - accuracy: 0.5170 - val_loss: 0.6917 - val_accuracy: 0.5344\n",
            "Epoch 4/20\n",
            "603/603 [==============================] - 244s 405ms/step - loss: 0.6927 - accuracy: 0.5170 - val_loss: 0.6913 - val_accuracy: 0.5344\n",
            "Epoch 5/20\n",
            "603/603 [==============================] - 243s 403ms/step - loss: 0.6878 - accuracy: 0.5339 - val_loss: 0.6734 - val_accuracy: 0.5751\n",
            "Epoch 6/20\n",
            "603/603 [==============================] - 244s 404ms/step - loss: 0.6601 - accuracy: 0.6006 - val_loss: 0.6694 - val_accuracy: 0.6129\n",
            "Epoch 7/20\n",
            "603/603 [==============================] - 244s 405ms/step - loss: 0.5767 - accuracy: 0.6875 - val_loss: 0.5461 - val_accuracy: 0.7241\n",
            "Epoch 8/20\n",
            "603/603 [==============================] - 247s 409ms/step - loss: 0.4531 - accuracy: 0.7910 - val_loss: 0.5006 - val_accuracy: 0.7813\n",
            "Epoch 9/20\n",
            "603/603 [==============================] - 245s 406ms/step - loss: 0.3526 - accuracy: 0.8517 - val_loss: 0.4398 - val_accuracy: 0.8145\n",
            "Epoch 10/20\n",
            "603/603 [==============================] - 243s 404ms/step - loss: 0.2917 - accuracy: 0.8794 - val_loss: 0.3815 - val_accuracy: 0.8344\n",
            "Epoch 11/20\n",
            "603/603 [==============================] - 244s 405ms/step - loss: 0.2459 - accuracy: 0.8997 - val_loss: 0.4138 - val_accuracy: 0.8166\n",
            "Epoch 12/20\n",
            "603/603 [==============================] - 243s 402ms/step - loss: 0.2037 - accuracy: 0.9188 - val_loss: 0.3950 - val_accuracy: 0.8469\n",
            "Epoch 13/20\n",
            "443/603 [=====================>........] - ETA: 1:00 - loss: 0.1661 - accuracy: 0.9323"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=16,epochs=20,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUhFkNfwDtr"
      },
      "outputs": [],
      "source": [
        "model.save(f\"1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz7BAj5wwlN"
      },
      "outputs": [],
      "source": [
        "symbol,period,interval=\"btc-usd\",\"10d\",\"5m\"\n",
        "data = yf.download(tickers=symbol,period=period,interval=interval)\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "data = data.astype(float)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, :]\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb2r1l8yB-0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8nJ2wI-ynZw"
      },
      "outputs": [],
      "source": [
        "tv = TvDatafeed()\n",
        "data = tv.get_hist(symbol=\"btcusdt\",exchange=\"binance\",interval=Interval.in_5_minute,n_bars=1000)\n",
        "data = np.array(data)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, 1:5]\n",
        "rows.shape\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpTFxbUd5mXt"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture1.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7lUM_NBNxj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WBt2p6M86D"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "while True:\n",
        "  ans = input()\n",
        "  if ans == \"exit\":\n",
        "    break\n",
        "  lst.append(int(ans))\n",
        "print(sum(max),len(lst))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of G26",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
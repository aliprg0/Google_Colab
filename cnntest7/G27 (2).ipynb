{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "5716f9e2-af37-43b8-cb69-434a47f4bcb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 7.6 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 37.9 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.11 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=354ea8f1110f1ee44802296a002f261a0a52db755bae4f1b4df9237aad4c52c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install mplfinance\n",
        "!pip install cairocffi\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib notebook\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "def get_crypto_syms():\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   return symbols\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3]-data[i+z][0])\n",
        "        next_candles = sum(next_candles)\n",
        "        if next_candles > 0:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clf()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 20:\n",
        "          plt.close(\"all\")\n",
        "        if i % 270 ==0:\n",
        "          print(\"\")\n",
        "    plt.close(\"all\")\n",
        "    print(\"\")\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "187ba667-bcef-44a5-a5be-72ab8ee91b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"6wk\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "8ceec099-d9dd-48dd-cb92-165139399fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            "File Number 2: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            "File Number 3: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            "File Number 4: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            "File Number 5: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            "File Number 6: 100/1000 110/1000 120/1000 130/1000 140/1000 150/1000 160/1000 170/1000 180/1000 190/1000 200/1000 210/1000 220/1000 230/1000 240/1000 250/1000 260/1000 270/1000 \n",
            "280/1000 290/1000 300/1000 310/1000 320/1000 330/1000 340/1000 350/1000 360/1000 370/1000 380/1000 390/1000 400/1000 410/1000 420/1000 430/1000 440/1000 450/1000 460/1000 470/1000 480/1000 490/1000 500/1000 510/1000 520/1000 530/1000 540/1000 \n",
            "550/1000 560/1000 570/1000 580/1000 590/1000 600/1000 610/1000 620/1000 630/1000 640/1000 650/1000 660/1000 670/1000 680/1000 690/1000 700/1000 710/1000 720/1000 730/1000 740/1000 750/1000 760/1000 770/1000 780/1000 790/1000 800/1000 810/1000 \n",
            "820/1000 830/1000 840/1000 850/1000 860/1000 870/1000 880/1000 890/1000 900/1000 910/1000 920/1000 930/1000 940/1000 950/1000 960/1000 970/1000 980/1000 990/1000 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5400"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "how_many_future_candles = 10\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 100\n",
        "\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpQvhf-pwpR",
        "outputId": "52e038e6-b450-4af8-82f9-2e4f09531468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5400, 128, 128)\n",
            "xTrain : 4320 \\ xTest : 1080\n",
            "yn: 2780 nn: 2620\n"
          ]
        }
      ],
      "source": [
        "#folder_name = \"165913\"\n",
        "\n",
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(f\"/content/{folder_name}.zip\",f\"/content/extracted/{folder_name}\")\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjRn1rKTEFSH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(xTest,yTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9stbJK8Nx_0c",
        "outputId": "a890a3f7-cce6-4e07-b43e-d3d3ed94ea9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 126, 126, 64)      640       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 63, 63, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 61, 61, 128)       73856     \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 30, 30, 128)      0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 29, 28, 64)        49216     \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 14, 14, 64)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 30)        7710      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 5070)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 800)               4056800   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 800)               640800    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 800)               640800    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 800)               640800    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 1602      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,112,224\n",
            "Trainable params: 6,112,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,     (3, 3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128,      (3,3),activation=\"relu\",)) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,      (2 ,3),activation=\"relu\",)) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(30,      (2 ,2),activation=\"relu\",)) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(800,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytWxowTyInc",
        "outputId": "e11c3f7c-10e6-4173-d838-6553dbad2afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "135/135 [==============================] - 247s 2s/step - loss: 0.6934 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5065\n",
            "Epoch 2/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.6928 - accuracy: 0.5169 - val_loss: 0.6935 - val_accuracy: 0.5065\n",
            "Epoch 3/20\n",
            "135/135 [==============================] - 244s 2s/step - loss: 0.6928 - accuracy: 0.5169 - val_loss: 0.6928 - val_accuracy: 0.5065\n",
            "Epoch 4/20\n",
            "135/135 [==============================] - 246s 2s/step - loss: 0.6798 - accuracy: 0.5650 - val_loss: 0.6604 - val_accuracy: 0.6213\n",
            "Epoch 5/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.6272 - accuracy: 0.6505 - val_loss: 0.5841 - val_accuracy: 0.6917\n",
            "Epoch 6/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.5038 - accuracy: 0.7569 - val_loss: 0.4560 - val_accuracy: 0.7852\n",
            "Epoch 7/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.3629 - accuracy: 0.8426 - val_loss: 0.3969 - val_accuracy: 0.8278\n",
            "Epoch 8/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.2680 - accuracy: 0.8836 - val_loss: 0.3704 - val_accuracy: 0.8435\n",
            "Epoch 9/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.2213 - accuracy: 0.9127 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
            "Epoch 10/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9241Epoch 11/20\n",
            "135/135 [==============================] - 249s 2s/step - loss: 0.1550 - accuracy: 0.9375 - val_loss: 0.3706 - val_accuracy: 0.8565\n",
            "Epoch 12/20\n",
            "135/135 [==============================] - 246s 2s/step - loss: 0.1248 - accuracy: 0.9498 - val_loss: 0.3980 - val_accuracy: 0.8528\n",
            "Epoch 13/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.1007 - accuracy: 0.9583 - val_loss: 0.4682 - val_accuracy: 0.8639\n",
            "Epoch 14/20\n",
            "135/135 [==============================] - 246s 2s/step - loss: 0.0809 - accuracy: 0.9637 - val_loss: 0.5175 - val_accuracy: 0.8454\n",
            "Epoch 15/20\n",
            "135/135 [==============================] - 246s 2s/step - loss: 0.0608 - accuracy: 0.9748 - val_loss: 0.5885 - val_accuracy: 0.8565\n",
            "Epoch 16/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.0479 - accuracy: 0.9792 - val_loss: 0.6512 - val_accuracy: 0.8463\n",
            "Epoch 17/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.0370 - accuracy: 0.9854 - val_loss: 0.6524 - val_accuracy: 0.8528\n",
            "Epoch 18/20\n",
            "135/135 [==============================] - 246s 2s/step - loss: 0.0216 - accuracy: 0.9914 - val_loss: 0.7701 - val_accuracy: 0.8509\n",
            "Epoch 19/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.8977 - val_accuracy: 0.8463\n",
            "Epoch 20/20\n",
            "135/135 [==============================] - 245s 2s/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.9402 - val_accuracy: 0.8454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa47f55950>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=20,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUhFkNfwDtr"
      },
      "outputs": [],
      "source": [
        "model.save(f\"1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz7BAj5wwlN"
      },
      "outputs": [],
      "source": [
        "symbol,period,interval=\"btc-usd\",\"10d\",\"5m\"\n",
        "data = yf.download(tickers=symbol,period=period,interval=interval)\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "data = data.astype(float)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, :]\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb2r1l8yB-0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8nJ2wI-ynZw"
      },
      "outputs": [],
      "source": [
        "tv = TvDatafeed()\n",
        "data = tv.get_hist(symbol=\"btcusdt\",exchange=\"binance\",interval=Interval.in_5_minute,n_bars=1000)\n",
        "data = np.array(data)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, 1:5]\n",
        "rows.shape\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpTFxbUd5mXt"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture1.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7lUM_NBNxj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WBt2p6M86D"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "while True:\n",
        "  ans = input()\n",
        "  if ans == \"exit\":\n",
        "    break\n",
        "  lst.append(int(ans))\n",
        "print(sum(max),len(lst))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "G27",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "1df20c7e-fc30-467c-9c70-ee32f0f473a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.11 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=ba651aba661d905ddb55119252ea4a796339ccadfb9aef8551669353515309e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install mplfinance\n",
        "!pip install cairocffi\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib notebook\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "def get_crypto_syms():\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   return symbols\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3]-data[i+z][0])\n",
        "        next_candles = sum(next_candles)\n",
        "        if next_candles > 0:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clf()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 20:\n",
        "          plt.close(\"all\")\n",
        "        if i % 270 ==0:\n",
        "          print(\"\")\n",
        "    plt.close(\"all\")\n",
        "    print(\"\")\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AMR8z1BIS-M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78231078-8477-455a-81f4-7ccddd3294d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"15d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TxTyv_osQAnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc19e56d-3c79-44e7-89e9-ddaea6e4a0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            "File Number 2: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            "File Number 3: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            "File Number 4: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            "File Number 5: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            "File Number 6: 80/343 90/343 100/343 110/343 120/343 130/343 140/343 150/343 160/343 170/343 180/343 190/343 200/343 210/343 220/343 230/343 240/343 250/343 260/343 270/343 \n",
            "280/343 290/343 300/343 310/343 320/343 330/343 340/343 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1578"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "how_many_future_candles = 5\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 80\n",
        "\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dQpQvhf-pwpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6254509-ac65-429c-86c6-359c34490b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1578, 128, 128)\n",
            "xTrain : 1262 \\ xTest : 316\n",
            "yn: 825 nn: 753\n"
          ]
        }
      ],
      "source": [
        "#folder_name = \"165913\"\n",
        "\n",
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(f\"/content/{folder_name}.zip\",f\"/content/extracted/{folder_name}\")\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjRn1rKTEFSH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(xTest,yTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5610c1f8-69cb-47f7-8521-f5372ae6c704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 126, 126, 64)      640       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 63, 63, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 61, 61, 100)       57700     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 30, 30, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 28, 28, 64)        57664     \n",
            "                                                                 \n",
            " average_pooling2d_7 (Averag  (None, 14, 14, 64)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 32)        18464     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,283,270\n",
            "Trainable params: 3,283,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,   (3, 3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1), kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(100,   (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,    (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32,    (3,3),activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005))) \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(512,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(512,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(512,activation=\"relu\", kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cytWxowTyInc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da8c6e2-a9db-4ad7-f243-0b2c7f65e3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.7892 - accuracy: 0.5063 - val_loss: 0.7665 - val_accuracy: 0.5380\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 63s 2s/step - loss: 0.7619 - accuracy: 0.5190 - val_loss: 0.7555 - val_accuracy: 0.5380\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 60s 1s/step - loss: 0.7537 - accuracy: 0.5190 - val_loss: 0.7493 - val_accuracy: 0.5380\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.7499 - accuracy: 0.5190 - val_loss: 0.7458 - val_accuracy: 0.5380\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 60s 1s/step - loss: 0.7455 - accuracy: 0.5190 - val_loss: 0.7422 - val_accuracy: 0.5380\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.7427 - accuracy: 0.5190 - val_loss: 0.7395 - val_accuracy: 0.5380\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 60s 1s/step - loss: 0.7398 - accuracy: 0.5190 - val_loss: 0.7368 - val_accuracy: 0.5380\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.7374 - accuracy: 0.5190 - val_loss: 0.7348 - val_accuracy: 0.5380\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 60s 1s/step - loss: 0.7353 - accuracy: 0.5190 - val_loss: 0.7326 - val_accuracy: 0.5380\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.7326 - accuracy: 0.5190 - val_loss: 0.7264 - val_accuracy: 0.5380\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 60s 1s/step - loss: 0.6996 - accuracy: 0.5911 - val_loss: 0.6633 - val_accuracy: 0.6646\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 60s 2s/step - loss: 0.6472 - accuracy: 0.6926 - val_loss: 0.6338 - val_accuracy: 0.6867\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.6025 - accuracy: 0.7211 - val_loss: 0.6065 - val_accuracy: 0.7120\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.5403 - accuracy: 0.7623 - val_loss: 0.5365 - val_accuracy: 0.7595\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.4938 - accuracy: 0.7845 - val_loss: 0.5260 - val_accuracy: 0.7753\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.4485 - accuracy: 0.8177 - val_loss: 0.5188 - val_accuracy: 0.7848\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.4094 - accuracy: 0.8384 - val_loss: 0.5247 - val_accuracy: 0.8038\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.3730 - accuracy: 0.8510 - val_loss: 0.5783 - val_accuracy: 0.8038\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 59s 1s/step - loss: 0.3529 - accuracy: 0.8764 - val_loss: 0.5127 - val_accuracy: 0.7911\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 58s 1s/step - loss: 0.3168 - accuracy: 0.8780 - val_loss: 0.4917 - val_accuracy: 0.8070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85b7df0590>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=20,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUhFkNfwDtr"
      },
      "outputs": [],
      "source": [
        "model.save(f\"1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz7BAj5wwlN"
      },
      "outputs": [],
      "source": [
        "symbol,period,interval=\"btc-usd\",\"10d\",\"5m\"\n",
        "data = yf.download(tickers=symbol,period=period,interval=interval)\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "data = data.astype(float)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, :]\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb2r1l8yB-0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/picture.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "I8nJ2wI-ynZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8d3714c2-1953-42b1-d0e7-01d605c0bc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "do you want to install chromedriver automatically?? y/n\tn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "tv = TvDatafeed()\n",
        "data = tv.get_hist(symbol=\"btcusdt\",exchange=\"binance\",interval=Interval.in_1_hour,n_bars=1000)\n",
        "data = np.array(data)\n",
        "i = -1\n",
        "rows = data[i-each_row_past:i, 1:5]\n",
        "rows.shape\n",
        "df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "df.index.name = \"Date\"\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "fig.savefig(\"picture1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zpTFxbUd5mXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b34819-a6c3-4ca5-83bf-4a0010018754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "image = cv2.imread(\"/content/picture1.png\",0)\n",
        "dim = (128, 128)\n",
        "resized = cv2.resize(image, dim)\n",
        "data = np.array(resized)\n",
        "model.predict([[data.reshape(1,128,128,1)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B7lUM_NBNxj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WBt2p6M86D"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "while True:\n",
        "  ans = input()\n",
        "  if ans == \"exit\":\n",
        "    break\n",
        "  lst.append(int(ans))\n",
        "print(sum(max),len(lst))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "G28_5",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
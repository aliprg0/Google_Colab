{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5bxbCoe9do9"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade mplfinance\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "\n",
        "\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "\n",
        "\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "\n",
        "\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "\n",
        "\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    data = data.dropna()\n",
        "    dfs = []\n",
        "    suggs = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    for i in range(each_row_past, data.shape[0]-which_future_or_past):\n",
        "\n",
        "        rows = data[i-each_row_past:i, :4]\n",
        "\n",
        "        past_candles = []\n",
        "        #for z in range(1, how_many_past_candles+1):\n",
        "        #  past_candles.append(data[i-z][3])\n",
        "        #past_candles = sum(past_candles)/len(past_candles)\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3])\n",
        "        next_candles = sum(next_candles)/len(next_candles)\n",
        "        if next_candles > data[i-1][3]:\n",
        "          suggs.append(1)\n",
        "        else:\n",
        "          suggs.append(0)\n",
        "\n",
        "        x = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "        del rows\n",
        "        del past_candles\n",
        "        del next_candles\n",
        "        dfs.append(x)\n",
        "        del x\n",
        "    del data\n",
        "\n",
        "    index = 0\n",
        "    all_n = np.array(dfs).shape[0]\n",
        "    for df in dfs:\n",
        "        date_list = []\n",
        "        rrng = np.array(df).shape[0]\n",
        "        for i in range(rrng):\n",
        "            date_list.append(datetime.fromordinal(\n",
        "                datetime.today().toordinal()+i).strftime('%Y-%m-%d'))\n",
        "        df.index = date_list\n",
        "        df.index.name = \"Date\"\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{suggs[index]}.png\"\n",
        "        mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                           scale_padding=0.2, returnfig=True, savefig=address, tight_layout=True,figsize =(3,2))\n",
        "        plt.close(\"all\")\n",
        "        del df\n",
        "        del date_list\n",
        "        del rrng\n",
        "        del i\n",
        "        del right_now\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "        index = index + 1\n",
        "        if index % 10 == 0:\n",
        "            print(f\"{index}/{all_n}\", end=\" \")\n",
        "        if index % 160 == 0:\n",
        "          print(\" \")\n",
        "\n",
        "    print(\"\")\n",
        "    del dfs\n",
        "    del suggs\n",
        "    del index\n",
        "    del all_n\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "90e0e91d-2894-4669-91de-4bd932a7374b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\"]\n",
        "download_data(symbols,\"max\",\"1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "c4791521-b3f9-40ac-c53e-d8fc29e9ed42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 3\n",
            "Processing File:\n",
            "File Number 1: 10/1604 20/1604 30/1604 40/1604 50/1604 60/1604 70/1604 80/1604 90/1604 100/1604 110/1604 120/1604 130/1604 140/1604 150/1604 160/1604  \n",
            "170/1604 180/1604 190/1604 200/1604 210/1604 220/1604 230/1604 240/1604 250/1604 260/1604 270/1604 280/1604 290/1604 300/1604 310/1604 320/1604  \n",
            "330/1604 340/1604 350/1604 360/1604 370/1604 380/1604 390/1604 400/1604 410/1604 420/1604 430/1604 440/1604 450/1604 460/1604 470/1604 480/1604  \n",
            "490/1604 500/1604 510/1604 520/1604 530/1604 540/1604 550/1604 560/1604 570/1604 580/1604 590/1604 600/1604 610/1604 620/1604 630/1604 640/1604  \n",
            "650/1604 660/1604 670/1604 680/1604 690/1604 700/1604 710/1604 720/1604 730/1604 740/1604 750/1604 760/1604 770/1604 780/1604 790/1604 800/1604  \n",
            "810/1604 820/1604 830/1604 840/1604 850/1604 860/1604 870/1604 880/1604 890/1604 900/1604 910/1604 920/1604 930/1604 940/1604 950/1604 960/1604  \n",
            "970/1604 980/1604 990/1604 1000/1604 1010/1604 1020/1604 1030/1604 1040/1604 1050/1604 1060/1604 1070/1604 1080/1604 1090/1604 1100/1604 1110/1604 1120/1604  \n",
            "1130/1604 1140/1604 1150/1604 1160/1604 1170/1604 1180/1604 1190/1604 1200/1604 1210/1604 1220/1604 1230/1604 1240/1604 1250/1604 1260/1604 1270/1604 1280/1604  \n",
            "1290/1604 1300/1604 1310/1604 1320/1604 1330/1604 1340/1604 1350/1604 1360/1604 1370/1604 1380/1604 1390/1604 1400/1604 1410/1604 1420/1604 1430/1604 1440/1604  \n",
            "1450/1604 1460/1604 1470/1604 1480/1604 1490/1604 1500/1604 1510/1604 1520/1604 1530/1604 1540/1604 1550/1604 1560/1604 1570/1604 1580/1604 1590/1604 1600/1604  \n",
            "\n",
            "File Number 2: 10/1604 20/1604 30/1604 40/1604 50/1604 60/1604 70/1604 80/1604 90/1604 100/1604 110/1604 120/1604 130/1604 140/1604 150/1604 160/1604  \n",
            "170/1604 180/1604 190/1604 200/1604 210/1604 220/1604 230/1604 240/1604 250/1604 260/1604 270/1604 280/1604 290/1604 300/1604 310/1604 320/1604  \n",
            "330/1604 340/1604 350/1604 360/1604 370/1604 380/1604 390/1604 400/1604 410/1604 420/1604 430/1604 440/1604 450/1604 460/1604 470/1604 480/1604  \n",
            "490/1604 500/1604 510/1604 520/1604 530/1604 540/1604 550/1604 560/1604 570/1604 580/1604 590/1604 600/1604 610/1604 620/1604 630/1604 640/1604  \n",
            "650/1604 660/1604 670/1604 680/1604 690/1604 700/1604 710/1604 720/1604 730/1604 740/1604 750/1604 760/1604 770/1604 780/1604 790/1604 800/1604  \n",
            "810/1604 820/1604 830/1604 840/1604 850/1604 860/1604 870/1604 880/1604 890/1604 900/1604 910/1604 920/1604 930/1604 940/1604 950/1604 960/1604  \n",
            "970/1604 980/1604 990/1604 1000/1604 1010/1604 1020/1604 1030/1604 1040/1604 1050/1604 1060/1604 1070/1604 1080/1604 1090/1604 1100/1604 1110/1604 1120/1604  \n",
            "1130/1604 1140/1604 1150/1604 1160/1604 1170/1604 1180/1604 1190/1604 1200/1604 1210/1604 1220/1604 1230/1604 1240/1604 1250/1604 1260/1604 1270/1604 1280/1604  \n",
            "1290/1604 1300/1604 1310/1604 1320/1604 1330/1604 1340/1604 1350/1604 1360/1604 1370/1604 1380/1604 1390/1604 1400/1604 1410/1604 1420/1604 1430/1604 1440/1604  \n",
            "1450/1604 1460/1604 1470/1604 1480/1604 1490/1604 1500/1604 1510/1604 1520/1604 1530/1604 1540/1604 1550/1604 1560/1604 1570/1604 1580/1604 1590/1604 1600/1604  \n",
            "\n",
            "File Number 3: 10/2753 20/2753 30/2753 40/2753 50/2753 60/2753 70/2753 80/2753 90/2753 100/2753 110/2753 120/2753 130/2753 140/2753 150/2753 160/2753  \n",
            "170/2753 180/2753 190/2753 200/2753 210/2753 220/2753 230/2753 240/2753 250/2753 260/2753 270/2753 280/2753 290/2753 300/2753 310/2753 320/2753  \n",
            "330/2753 340/2753 350/2753 360/2753 370/2753 380/2753 390/2753 400/2753 410/2753 420/2753 430/2753 440/2753 450/2753 460/2753 470/2753 480/2753  \n",
            "490/2753 500/2753 510/2753 520/2753 530/2753 540/2753 550/2753 560/2753 570/2753 580/2753 590/2753 600/2753 610/2753 620/2753 630/2753 640/2753  \n",
            "650/2753 660/2753 670/2753 680/2753 690/2753 700/2753 710/2753 720/2753 730/2753 740/2753 750/2753 760/2753 770/2753 780/2753 790/2753 800/2753  \n",
            "810/2753 820/2753 830/2753 840/2753 850/2753 860/2753 870/2753 880/2753 890/2753 900/2753 910/2753 920/2753 930/2753 940/2753 950/2753 960/2753  \n",
            "970/2753 980/2753 990/2753 1000/2753 1010/2753 1020/2753 1030/2753 1040/2753 1050/2753 1060/2753 1070/2753 1080/2753 1090/2753 1100/2753 1110/2753 1120/2753  \n",
            "1130/2753 1140/2753 1150/2753 1160/2753 1170/2753 1180/2753 1190/2753 1200/2753 1210/2753 1220/2753 1230/2753 1240/2753 1250/2753 1260/2753 1270/2753 1280/2753  \n",
            "1290/2753 1300/2753 1310/2753 1320/2753 1330/2753 1340/2753 1350/2753 1360/2753 1370/2753 1380/2753 1390/2753 1400/2753 1410/2753 1420/2753 1430/2753 1440/2753  \n",
            "1450/2753 1460/2753 1470/2753 1480/2753 1490/2753 1500/2753 1510/2753 1520/2753 1530/2753 1540/2753 1550/2753 1560/2753 1570/2753 1580/2753 1590/2753 1600/2753  \n",
            "1610/2753 1620/2753 1630/2753 1640/2753 1650/2753 1660/2753 1670/2753 1680/2753 1690/2753 1700/2753 1710/2753 1720/2753 1730/2753 1740/2753 1750/2753 1760/2753  \n",
            "1770/2753 1780/2753 1790/2753 1800/2753 1810/2753 1820/2753 1830/2753 1840/2753 1850/2753 1860/2753 1870/2753 1880/2753 1890/2753 1900/2753 1910/2753 1920/2753  \n",
            "1930/2753 1940/2753 1950/2753 1960/2753 1970/2753 1980/2753 1990/2753 2000/2753 2010/2753 2020/2753 2030/2753 2040/2753 2050/2753 2060/2753 2070/2753 2080/2753  \n",
            "2090/2753 2100/2753 2110/2753 2120/2753 2130/2753 2140/2753 2150/2753 2160/2753 2170/2753 2180/2753 2190/2753 2200/2753 2210/2753 2220/2753 2230/2753 2240/2753  \n",
            "2250/2753 2260/2753 2270/2753 2280/2753 2290/2753 2300/2753 2310/2753 2320/2753 2330/2753 2340/2753 2350/2753 2360/2753 2370/2753 2380/2753 2390/2753 2400/2753  \n",
            "2410/2753 2420/2753 2430/2753 2440/2753 2450/2753 2460/2753 2470/2753 2480/2753 2490/2753 2500/2753 2510/2753 2520/2753 2530/2753 2540/2753 2550/2753 2560/2753  \n",
            "2570/2753 2580/2753 2590/2753 2600/2753 2610/2753 2620/2753 2630/2753 2640/2753 2650/2753 2660/2753 2670/2753 2680/2753 2690/2753 2700/2753 2710/2753 2720/2753  \n",
            "2730/2753 2740/2753 2750/2753 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5961"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "how_many_future_candles = 3\n",
        "how_many_past_candles = 3\n",
        "each_row_past = 100\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_name = '083812'\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name)\n",
        "    dim = (75, 75)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255.0\n",
        "data.shape"
      ],
      "metadata": {
        "id": "dQpQvhf-pwpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.1,random_state=99)\n",
        "\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ],
      "metadata": {
        "id": "viaOP2N6xoZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85468a7e-459a-477b-a3ba-8a63fb465933"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xTrain : 5364 \\ xTest : 597\n",
            "yn: 3188 nn: 2773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,  (3, 3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,  (3, 3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(150,  (3, 3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f81defe-1a7b-4b4f-d08a-156fa8f0f91b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_125 (Conv2D)         (None, 73, 73, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_116 (MaxPooli  (None, 36, 36, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_126 (Conv2D)         (None, 34, 34, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_117 (MaxPooli  (None, 17, 17, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_127 (Conv2D)         (None, 15, 15, 150)       86550     \n",
            "                                                                 \n",
            " max_pooling2d_118 (MaxPooli  (None, 7, 7, 150)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_41 (Flatten)        (None, 7350)              0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 1024)              7527424   \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,752,792\n",
            "Trainable params: 9,752,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=25,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n"
      ],
      "metadata": {
        "id": "cytWxowTyInc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584b3fd2-ad58-4ef0-e3d9-65f20b7f1760"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "168/168 [==============================] - 4s 18ms/step - loss: 0.6952 - accuracy: 0.5393 - val_loss: 0.6927 - val_accuracy: 0.5176\n",
            "Epoch 2/25\n",
            "168/168 [==============================] - 2s 15ms/step - loss: 0.6911 - accuracy: 0.5319 - val_loss: 0.6941 - val_accuracy: 0.5176\n",
            "Epoch 3/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6909 - accuracy: 0.5367 - val_loss: 0.6928 - val_accuracy: 0.5176\n",
            "Epoch 4/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6905 - accuracy: 0.5367 - val_loss: 0.6932 - val_accuracy: 0.5176\n",
            "Epoch 5/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6908 - accuracy: 0.5367 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
            "Epoch 6/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6909 - accuracy: 0.5367 - val_loss: 0.6930 - val_accuracy: 0.5176\n",
            "Epoch 7/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6889 - accuracy: 0.5406 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
            "Epoch 8/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.6836 - accuracy: 0.5561 - val_loss: 0.6928 - val_accuracy: 0.5310\n",
            "Epoch 9/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.6747 - accuracy: 0.5805 - val_loss: 0.6974 - val_accuracy: 0.5461\n",
            "Epoch 10/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6582 - accuracy: 0.6068 - val_loss: 0.6935 - val_accuracy: 0.5343\n",
            "Epoch 11/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.6223 - accuracy: 0.6536 - val_loss: 0.7508 - val_accuracy: 0.5343\n",
            "Epoch 12/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.5706 - accuracy: 0.7109 - val_loss: 0.6907 - val_accuracy: 0.5745\n",
            "Epoch 13/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.4884 - accuracy: 0.7657 - val_loss: 0.7536 - val_accuracy: 0.5879\n",
            "Epoch 14/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.3753 - accuracy: 0.8346 - val_loss: 0.7503 - val_accuracy: 0.6298\n",
            "Epoch 15/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.2318 - accuracy: 0.9045 - val_loss: 0.8789 - val_accuracy: 0.6516\n",
            "Epoch 16/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.1026 - accuracy: 0.9620 - val_loss: 1.2407 - val_accuracy: 0.6549\n",
            "Epoch 17/25\n",
            "168/168 [==============================] - 2s 15ms/step - loss: 0.0456 - accuracy: 0.9843 - val_loss: 1.4275 - val_accuracy: 0.6399\n",
            "Epoch 18/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 1.7457 - val_accuracy: 0.6399\n",
            "Epoch 19/25\n",
            "168/168 [==============================] - 3s 16ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 1.7933 - val_accuracy: 0.6600\n",
            "Epoch 20/25\n",
            "168/168 [==============================] - 2s 15ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.9883 - val_accuracy: 0.6348\n",
            "Epoch 21/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 1.9412 - val_accuracy: 0.6432\n",
            "Epoch 22/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 2.1126 - val_accuracy: 0.6516\n",
            "Epoch 23/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 2.3084 - val_accuracy: 0.6449\n",
            "Epoch 24/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 2.2829 - val_accuracy: 0.6382\n",
            "Epoch 25/25\n",
            "168/168 [==============================] - 2s 14ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 1.9325 - val_accuracy: 0.6482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a32dcd190>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CnnPred.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
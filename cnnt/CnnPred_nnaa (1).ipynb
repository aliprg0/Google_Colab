{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "8b437d5a-f556-42db-f84f-3e7a9bf55021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 19.3 MB/s \n",
            "\u001b[?25hCollecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 835 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.10 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220629235552)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade mplfinance\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "\n",
        "\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "\n",
        "\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "\n",
        "\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "\n",
        "\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    data = data.dropna()\n",
        "    dfs = []\n",
        "    suggs = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    for i in range(each_row_past, data.shape[0]-which_future_or_past):\n",
        "\n",
        "        rows = data[i-each_row_past:i, :4]\n",
        "\n",
        "        past_candles = []\n",
        "        #for z in range(1, how_many_past_candles+1):\n",
        "        #  past_candles.append(data[i-z][3])\n",
        "        #past_candles = sum(past_candles)/len(past_candles)\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append(data[i+z][3])\n",
        "        next_candles = sum(next_candles)/len(next_candles)\n",
        "        if next_candles > data[i-1][3]:\n",
        "          suggs.append(1)\n",
        "        else:\n",
        "          suggs.append(0)\n",
        "\n",
        "        x = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
        "        del rows\n",
        "        del past_candles\n",
        "        del next_candles\n",
        "        dfs.append(x)\n",
        "        del x\n",
        "    del data\n",
        "\n",
        "    index = 0\n",
        "    all_n = np.array(dfs).shape[0]\n",
        "    for df in dfs:\n",
        "        date_list = []\n",
        "        rrng = np.array(df).shape[0]\n",
        "        for i in range(rrng):\n",
        "            date_list.append(datetime.fromordinal(\n",
        "                datetime.today().toordinal()+i).strftime('%Y-%m-%d'))\n",
        "        df.index = date_list\n",
        "        df.index.name = \"Date\"\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{suggs[index]}.png\"\n",
        "        mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                           scale_padding=0.2, returnfig=True, savefig=address, tight_layout=True,figsize =(3,2))\n",
        "        plt.close(\"all\")\n",
        "        del df\n",
        "        del date_list\n",
        "        del rrng\n",
        "        del i\n",
        "        del right_now\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "        index = index + 1\n",
        "        if index % 10 == 0:\n",
        "            print(f\"{index}/{all_n}\", end=\" \")\n",
        "        if index % 160 == 0:\n",
        "          print(\" \")\n",
        "\n",
        "    print(\"\")\n",
        "    del dfs\n",
        "    del suggs\n",
        "    del index\n",
        "    del all_n\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "1da322f6-4899-4e3d-ec55-d19a2aefa7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "#symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols[:20],\"2wk\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "TxTyv_osQAnY",
        "outputId": "183c4c60-33e8-4b2d-c732-ecb1cbfb42c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 20\n",
            "Processing File:\n",
            "File Number 1: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 2: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 3: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 4: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 5: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 6: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 7: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 8: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 9: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n",
            "170/208 180/208 190/208 200/208 \n",
            "File Number 10: 10/208 20/208 30/208 40/208 50/208 60/208 70/208 80/208 90/208 100/208 110/208 120/208 130/208 140/208 150/208 160/208  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2f38bd62620c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwhich_future_or_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhow_many_past_candles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfolder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow_many_future_candles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow_many_past_candles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meach_row_past\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/extracted/{folder_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-39557d066785>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(how_many_future_candles, how_many_past_candles, each_row_past)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow_many_future_candles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow_many_past_candles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_row_past\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     folder_name = extract_data(\n\u001b[0;32m--> 147\u001b[0;31m         how_many_future_candles, how_many_past_candles, each_row_past)\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-39557d066785>\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(how_many_future_candles, how_many_past_candles, each_row_past)\u001b[0m\n\u001b[1;32m     61\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File Number {index}:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m      each_file_proc(file, now, how_many_future_candles,\n\u001b[0;32m---> 63\u001b[0;31m                     how_many_past_candles, each_row_past)\n\u001b[0m\u001b[1;32m     64\u001b[0m      \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-39557d066785>\u001b[0m in \u001b[0;36meach_file_proc\u001b[0;34m(file, now, how_many_future_candles, how_many_past_candles, each_row_past)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mright_now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "how_many_future_candles = 10\n",
        "how_many_past_candles = 10\n",
        "each_row_past = 120\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = '114752'\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "    dim = (100, 80)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpQvhf-pwpR",
        "outputId": "0fe25ed1-e7e7-4acc-df18-c6639c434b35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2041, 80, 100)\n",
            "xTrain : 1632 \\ xTest : 409\n",
            "yn: 990 nn: 1051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,  (2,2),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,  (2,2),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (2,2),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(900,activation=\"relu\"))\n",
        "model.add(Dense(900,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d37a43-6302-4763-a46d-b5e4191349b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 79, 99, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 39, 49, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 38, 48, 64)        16448     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 19, 24, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 18, 23, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 11, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12672)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              12977152  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 900)               922500    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 900)               810900    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 1802      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,762,018\n",
            "Trainable params: 14,762,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.fit(xTrain,yTrain,batch_size=16,epochs=20,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n"
      ],
      "metadata": {
        "id": "cytWxowTyInc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8d33d3-50fe-4bde-fae7-9febf7979abf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "102/102 [==============================] - 15s 20ms/step - loss: 0.7110 - accuracy: 0.4902 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
            "Epoch 2/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.6926 - accuracy: 0.5190 - val_loss: 0.6905 - val_accuracy: 0.5159\n",
            "Epoch 3/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.6810 - accuracy: 0.5741 - val_loss: 0.6657 - val_accuracy: 0.6210\n",
            "Epoch 4/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.6544 - accuracy: 0.6109 - val_loss: 0.6315 - val_accuracy: 0.6577\n",
            "Epoch 5/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.6201 - accuracy: 0.6685 - val_loss: 0.5846 - val_accuracy: 0.6895\n",
            "Epoch 6/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.5605 - accuracy: 0.7151 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
            "Epoch 7/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.5096 - accuracy: 0.7512 - val_loss: 0.5326 - val_accuracy: 0.7139\n",
            "Epoch 8/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.4374 - accuracy: 0.7911 - val_loss: 0.4912 - val_accuracy: 0.7531\n",
            "Epoch 9/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3785 - accuracy: 0.8248 - val_loss: 0.5008 - val_accuracy: 0.7579\n",
            "Epoch 10/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.2902 - accuracy: 0.8762 - val_loss: 0.4659 - val_accuracy: 0.7751\n",
            "Epoch 11/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.2083 - accuracy: 0.9210 - val_loss: 0.5367 - val_accuracy: 0.7824\n",
            "Epoch 12/20\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.1352 - accuracy: 0.9412 - val_loss: 0.5625 - val_accuracy: 0.7995\n",
            "Epoch 13/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.1019 - accuracy: 0.9645 - val_loss: 0.6869 - val_accuracy: 0.7726\n",
            "Epoch 14/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.7054 - val_accuracy: 0.8044\n",
            "Epoch 15/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.7500 - val_accuracy: 0.8044\n",
            "Epoch 16/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.9533 - val_accuracy: 0.7775\n",
            "Epoch 17/20\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.6953 - val_accuracy: 0.8215\n",
            "Epoch 18/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.7724 - val_accuracy: 0.7946\n",
            "Epoch 19/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.9450 - val_accuracy: 0.7995\n",
            "Epoch 20/20\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 1.1016 - val_accuracy: 0.7971\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26004ad0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = yf.download(\"msft\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PJmf2qWl_jk",
        "outputId": "f44238c3-d50f-4c7e-d6eb-e24e4d99690f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHqNfjatmCBy",
        "outputId": "3575c660-fef3-4375-d614-b1fc74b04216"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9157"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CnnPred_nnaa.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5bxbCoe9do9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129fc81c-d45d-442c-c54b-628c89ac97a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.26.9)\n",
            "Requirement already satisfied: yahooquery in /usr/local/lib/python3.7/dist-packages (2.2.15)\n",
            "Requirement already satisfied: requests-futures>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.0.0)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: tvdatafeed in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (4.1.5)\n",
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (0.3.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.20.0)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (1.26.9)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium->tvdatafeed) (0.9.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.1.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium->tvdatafeed) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (22.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (37.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "clmns = [\n",
        "  \"Open 1\", \"Open 2\", \"Open 3\", \"Open 4\", \"Open 5\", \"Open 6\", \"Open 7\", \"Open 8\", \"Open 9\", \"Open 10\", \"Open 11\", \"Open 12\", \"Open 13\", \"Open 14\", \"Open 15\", \"Open 16\", \"Open 17\", \"Open 18\", \"Open 19\", \"Open 20\", \"Open 21\", \"Open 22\", \"Open 23\", \"Open 24\", \"Open 25\", \"Open 26\", \"Open 27\", \"Open 28\", \"Open 29\", \"Open 30\", \n",
        "  \"High 1\", \"High 2\", \"High 3\", \"High 4\", \"High 5\", \"High 6\", \"High 7\", \"High 8\", \"High 9\", \"High 10\", \"High 11\", \"High 12\", \"High 13\", \"High 14\", \"High 15\", \"High 16\", \"High 17\", \"High 18\", \"High 19\", \"High 20\", \"High 21\", \"High 22\", \"High 23\", \"High 24\", \"High 25\", \"High 26\", \"High 27\", \"High 28\", \"High 29\", \"High 30\",\n",
        "  \"Low 1\", \"Low 2\", \"Low 3\", \"Low 4\", \"Low 5\", \"Low 6\", \"Low 7\", \"Low 8\", \"Low 9\", \"Low 10\", \"Low 11\", \"Low 12\", \"Low 13\", \"Low 14\", \"Low 15\", \"Low 16\", \"Low 17\", \"Low 18\", \"Low 19\", \"Low 20\", \"Low 21\", \"Low 22\", \"Low 23\", \"Low 24\", \"Low 25\", \"Low 26\", \"Low 27\", \"Low 28\", \"Low 29\", \"Low 30\",\n",
        "  \"Close 1\", \"Close 2\", \"Close 3\", \"Close 4\", \"Close 5\", \"Close 6\", \"Close 7\", \"Close 8\", \"Close 9\", \"Close 10\", \"Close 11\", \"Close 12\", \"Close 13\", \"Close 14\", \"Close 15\", \"Close 16\", \"Close 17\", \"Close 18\", \"Close 19\", \"Close 20\", \"Close 21\", \"Close 22\", \"Close 23\", \"Close 24\", \"Close 25\", \"Close 26\", \"Close 27\", \"Close 28\", \"Close 29\", \"Close 30\",\n",
        "  \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"buy\",\"sell\"], axis=1)\n",
        "  y = data[[\"buy\",\"sell\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1,random_state=99)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-10,10))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    data = data.dropna()\n",
        "    row = []\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    data = np.array(data)\n",
        "    for i in range(31, data.shape[0]-1):\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        ggggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x][0] - data[i-(x-1)][0]] )\n",
        "            ggrow.append([data[i-x][1] - data[i-(x-1)][1]] )\n",
        "            gggrow.append([data[i-x][2] - data[i-(x-1)][2]] )\n",
        "            ggggrow.append([data[i-x][3] - data[i-(x-1)][3]] )\n",
        "\n",
        "        sugg = \"sell\"\n",
        "        if data[i][3] > data[i][0]:\n",
        "            sugg = \"buy\"\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr2 = np.array(ggrow).flatten()\n",
        "        arr3 = np.array(gggrow).flatten()\n",
        "        arr4 = np.array(ggggrow).flatten()\n",
        "\n",
        "        arr = scaler(arr.reshape(-1, 1))\n",
        "        arr2 = scaler(arr2.reshape(-1, 1))\n",
        "        arr3 = scaler(arr3.reshape(-1, 1))\n",
        "        arr4 = scaler(arr4.reshape(-1, 1))\n",
        "\n",
        "        arr = np.concatenate((arr, arr2, arr3, arr4), axis=0).reshape(-1,1)\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "    grow = []\n",
        "    ggrow = []\n",
        "    gggrow = []\n",
        "    arr = []\n",
        "    return np.array(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rl4JHnPmp5z7"
      },
      "outputs": [],
      "source": [
        "def download_data(symbols,periodd,intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\",end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,interval=intervall, progress=False,show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "           if data.shape[0] > 30:\n",
        "             data.to_csv(f\"/content/data/{symbol}.csv\")         \n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        try:\n",
        "           unattached_dfs.append(process(pd.read_csv(address)))\n",
        "        except:\n",
        "          print(\" EP \")\n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\" Null \")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     unattached_dfs = []\n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AMR8z1BIS-M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ff0058-0837-4b85-935d-92342b382655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            "Data Folder Removed\n",
            " -- 100 -- 200 -- 300 -- 400 -- 500 -- 600 -- 700 -- 800 -- 900 -- 1000 -- 1100 -- 1200 -- 1300 -- 1400 -- 1500 \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "download_data(symbols,\"100d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT3YU88Edyb3"
      },
      "outputs": [],
      "source": [
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest = spliting(pd.read_parquet(\"/content/drive/MyDrive/data.parquet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VCJBYN5jjzL",
        "outputId": "17a356ef-c94e-4990-b352-2659ca1d9697"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2940686, 120) (2940686, 2)\n",
            "(326743, 120) (326743, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xN93WT9e8ueQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76f7535-eb2f-4e2c-c681-8b450767ffdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              123904    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,324,354\n",
            "Trainable params: 4,324,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1024, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"HOG122_9670.h5\")"
      ],
      "metadata": {
        "id": "hsXtED_wBq97"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_SBxPzRd89uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348df3ca-b0f8-488f-d659-e367022976a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2872/2872 [==============================] - 91s 31ms/step - loss: 0.0558 - accuracy: 0.9777 - val_loss: 0.1277 - val_accuracy: 0.9606\n",
            "Epoch 2/3\n",
            "2872/2872 [==============================] - 86s 30ms/step - loss: 0.0574 - accuracy: 0.9770 - val_loss: 0.1253 - val_accuracy: 0.9608\n",
            "Epoch 3/3\n",
            "2872/2872 [==============================] - 88s 31ms/step - loss: 0.0551 - accuracy: 0.9780 - val_loss: 0.1237 - val_accuracy: 0.9603\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0754937f50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.fit(xTrain,yTrain,epochs=3,batch_size=1024,validation_data=(xTest,yTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VJU4ShbMU8tz"
      },
      "outputs": [],
      "source": [
        "model.save(\"HOG122_9670.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6bqkwjROb3lL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "97c1150a-8088-4e12-f3d3-7a4a0551fb57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Open          High           Low  \\\n",
              "2022-04-09 00:00:00+00:00  42294.703125  42433.007812  42285.593750   \n",
              "2022-04-09 01:00:00+00:00  42446.722656  42472.070312  42343.445312   \n",
              "2022-04-09 02:00:00+00:00  42431.281250  42442.773438  42225.066406   \n",
              "2022-04-09 03:00:00+00:00  42217.382812  42438.730469  42183.253906   \n",
              "2022-04-09 04:00:00+00:00  42409.160156  42532.078125  42372.222656   \n",
              "...                                 ...           ...           ...   \n",
              "2022-05-08 12:00:00+00:00  34784.156250  34818.761719  34632.125000   \n",
              "2022-05-08 13:00:00+00:00  34645.781250  34661.250000  34443.843750   \n",
              "2022-05-08 14:00:00+00:00  34445.277344  34552.015625  34395.136719   \n",
              "2022-05-08 15:00:00+00:00  34465.386719  34538.480469  34465.386719   \n",
              "2022-05-08 15:11:00+00:00  34497.703125  34497.703125  34497.703125   \n",
              "\n",
              "                                  Close     Adj Close      Volume  \n",
              "2022-04-09 00:00:00+00:00  42433.007812  42433.007812           0  \n",
              "2022-04-09 01:00:00+00:00  42404.140625  42404.140625           0  \n",
              "2022-04-09 02:00:00+00:00  42225.066406  42225.066406           0  \n",
              "2022-04-09 03:00:00+00:00  42417.109375  42417.109375   416466944  \n",
              "2022-04-09 04:00:00+00:00  42456.734375  42456.734375   186609664  \n",
              "...                                 ...           ...         ...  \n",
              "2022-05-08 12:00:00+00:00  34644.054688  34644.054688   145690624  \n",
              "2022-05-08 13:00:00+00:00  34443.843750  34443.843750   341708800  \n",
              "2022-05-08 14:00:00+00:00  34466.621094  34466.621094  1075826688  \n",
              "2022-05-08 15:00:00+00:00  34510.832031  34510.832031   109846528  \n",
              "2022-05-08 15:11:00+00:00  34497.703125  34497.703125           0  \n",
              "\n",
              "[713 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46788560-c44f-4d0b-a611-9de12a604a2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-09 00:00:00+00:00</th>\n",
              "      <td>42294.703125</td>\n",
              "      <td>42433.007812</td>\n",
              "      <td>42285.593750</td>\n",
              "      <td>42433.007812</td>\n",
              "      <td>42433.007812</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-09 01:00:00+00:00</th>\n",
              "      <td>42446.722656</td>\n",
              "      <td>42472.070312</td>\n",
              "      <td>42343.445312</td>\n",
              "      <td>42404.140625</td>\n",
              "      <td>42404.140625</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-09 02:00:00+00:00</th>\n",
              "      <td>42431.281250</td>\n",
              "      <td>42442.773438</td>\n",
              "      <td>42225.066406</td>\n",
              "      <td>42225.066406</td>\n",
              "      <td>42225.066406</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-09 03:00:00+00:00</th>\n",
              "      <td>42217.382812</td>\n",
              "      <td>42438.730469</td>\n",
              "      <td>42183.253906</td>\n",
              "      <td>42417.109375</td>\n",
              "      <td>42417.109375</td>\n",
              "      <td>416466944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-09 04:00:00+00:00</th>\n",
              "      <td>42409.160156</td>\n",
              "      <td>42532.078125</td>\n",
              "      <td>42372.222656</td>\n",
              "      <td>42456.734375</td>\n",
              "      <td>42456.734375</td>\n",
              "      <td>186609664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08 12:00:00+00:00</th>\n",
              "      <td>34784.156250</td>\n",
              "      <td>34818.761719</td>\n",
              "      <td>34632.125000</td>\n",
              "      <td>34644.054688</td>\n",
              "      <td>34644.054688</td>\n",
              "      <td>145690624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08 13:00:00+00:00</th>\n",
              "      <td>34645.781250</td>\n",
              "      <td>34661.250000</td>\n",
              "      <td>34443.843750</td>\n",
              "      <td>34443.843750</td>\n",
              "      <td>34443.843750</td>\n",
              "      <td>341708800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08 14:00:00+00:00</th>\n",
              "      <td>34445.277344</td>\n",
              "      <td>34552.015625</td>\n",
              "      <td>34395.136719</td>\n",
              "      <td>34466.621094</td>\n",
              "      <td>34466.621094</td>\n",
              "      <td>1075826688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08 15:00:00+00:00</th>\n",
              "      <td>34465.386719</td>\n",
              "      <td>34538.480469</td>\n",
              "      <td>34465.386719</td>\n",
              "      <td>34510.832031</td>\n",
              "      <td>34510.832031</td>\n",
              "      <td>109846528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08 15:11:00+00:00</th>\n",
              "      <td>34497.703125</td>\n",
              "      <td>34497.703125</td>\n",
              "      <td>34497.703125</td>\n",
              "      <td>34497.703125</td>\n",
              "      <td>34497.703125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>713 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46788560-c44f-4d0b-a611-9de12a604a2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46788560-c44f-4d0b-a611-9de12a604a2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46788560-c44f-4d0b-a611-9de12a604a2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "yf.download(\"btc-usd\",period=\"30d\",interval=\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fEcDYXMtSPUz"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -2\n",
        "        if len(pd.DataFrame(data).columns) == 7:\n",
        "          data = data.iloc[: , 1:]        \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        ggggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x][0] - data[i-(x-1)][0]] )\n",
        "            ggrow.append([data[i-x][1] - data[i-(x-1)][1]] )\n",
        "            gggrow.append([data[i-x][2] - data[i-(x-1)][2]] )\n",
        "            ggggrow.append([data[i-x][3] - data[i-(x-1)][3]] )\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr2 = np.array(ggrow).flatten()\n",
        "        arr3 = np.array(gggrow).flatten()\n",
        "        arr4 = np.array(ggggrow).flatten()\n",
        "\n",
        "        arr = scaler(arr.reshape(-1, 1))\n",
        "        arr2 = scaler(arr2.reshape(-1, 1))\n",
        "        arr3 = scaler(arr3.reshape(-1, 1))\n",
        "        arr4 = scaler(arr4.reshape(-1, 1))\n",
        "\n",
        "        arr = np.concatenate((arr, arr2, arr3, arr4), axis=0).reshape(-1,1)\n",
        "        return arr\n",
        "def make_prediction_for_yf(symbol,period,timeframe):\n",
        "    raw_data = process_for_prediction(yf.download(symbol,period=period,interval=timeframe))\n",
        "    return  model.predict(np.array(raw_data).reshape(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RuUzTsN-SfnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2a8129-b1cc-4b0b-fb3e-c2d58a0cfcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9995184e-01, 7.2661867e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "make_prediction_for_yf(\"btc-usd\",\"30d\",\"1h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fA3NoIBLIHLY"
      },
      "outputs": [],
      "source": [
        "def process_for_prediction(data):\n",
        "        i = -1\n",
        "        row = []\n",
        "        data.drop(\"symbol\",axis=1,inplace=True) \n",
        "        data = np.array(data)\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        ggggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x][0] - data[i-(x-1)][0]] )\n",
        "            ggrow.append([data[i-x][1] - data[i-(x-1)][1]] )\n",
        "            gggrow.append([data[i-x][2] - data[i-(x-1)][2]] )\n",
        "            ggggrow.append([data[i-x][3] - data[i-(x-1)][3]] )\n",
        "\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr2 = np.array(ggrow).flatten()\n",
        "        arr3 = np.array(gggrow).flatten()\n",
        "        arr4 = np.array(ggggrow).flatten()\n",
        "\n",
        "        arr = scaler(arr.reshape(-1, 1))\n",
        "        arr2 = scaler(arr2.reshape(-1, 1))\n",
        "        arr3 = scaler(arr3.reshape(-1, 1))\n",
        "        arr4 = scaler(arr4.reshape(-1, 1))\n",
        "\n",
        "        arr = np.concatenate((arr, arr2, arr3, arr4), axis=0).reshape(-1,1)\n",
        "        return arr\n",
        "def make_prediction_for_tv(symbol,timeframe):\n",
        "   tv = TvDatafeed()\n",
        "   data = tv.get_hist(symbol='btcUSD',exchange='bitstamp',interval=Interval.in_1_hour,n_bars=100)\n",
        "   return model.predict(np.array(process_for_prediction(data)).reshape(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aLgPS4HGIpgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96137eac-c462-4681-9e39-d636c6249309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9977216 , 0.00254014]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "make_prediction_for_tv(\"s\",\"x\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HOG122.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
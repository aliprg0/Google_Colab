{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "e267648a-122c-41d4-fcfd-1c3ea2b16768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 13.4 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 16.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.10 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/twopirllc/pandas-ta\n",
            "  Cloning https://github.com/twopirllc/pandas-ta to /tmp/pip-req-build-erci62xg\n",
            "  Running command git clone -q https://github.com/twopirllc/pandas-ta /tmp/pip-req-build-erci62xg\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas-ta==0.3.14b0) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas-ta==0.3.14b0) (1.15.0)\n",
            "Building wheels for collected packages: pandas-ta\n",
            "  Building wheel for pandas-ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=219766 sha256=f8221753481906ab51c7033649fa95e2f05cce1569613feb59213453597d76ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f712yqiy/wheels/2d/b0/97/98814700c6859229dac6f4c0b1bc1546331add62e7f6c9bf15\n",
            "Successfully built pandas-ta\n",
            "Installing collected packages: pandas-ta\n",
            "Successfully installed pandas-ta-0.3.14b0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade mplfinance\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "!pip install -U git+https://github.com/twopirllc/pandas-ta\n",
        "import pandas_ta as pta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "\n",
        "\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "\n",
        "\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "\n",
        "\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "\n",
        "\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "        past_candles = []\n",
        "        for z in range(1, how_many_past_candles+1):\n",
        "          past_candles.append((data[i-z][3]+data[i-z][0])/2)\n",
        "        past_candles = sum(past_candles)/len(past_candles)\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append((data[i+z][3]+data[i+z][0])/2)\n",
        "        next_candles = sum(next_candles)/len(next_candles)\n",
        "        if next_candles > past_candles:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "\n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clear()\n",
        "        plt.close(fig)\n",
        "\n",
        "        del fig,_a\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 300 == 0:\n",
        "          print(\" \")\n",
        "       \n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMR8z1BIS-M_",
        "outputId": "9535107d-ad05-4e48-87d5-fb0871fd21c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols : 1500\n",
            " \n"
          ]
        }
      ],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"max\",\"1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "048ff91f-83c4-4e6b-86ec-e65f3c17ac60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 150/1698 160/1698 170/1698 180/1698 190/1698 200/1698 210/1698 220/1698 230/1698 240/1698 250/1698 260/1698 270/1698 280/1698 290/1698 300/1698  \n",
            "310/1698 320/1698 330/1698 340/1698 350/1698 360/1698 370/1698 380/1698 390/1698 400/1698 410/1698 420/1698 430/1698 440/1698 450/1698 460/1698 470/1698 480/1698 490/1698 500/1698 510/1698 520/1698 530/1698 540/1698 550/1698 560/1698 570/1698 580/1698 590/1698 600/1698  \n",
            "610/1698 620/1698 630/1698 640/1698 650/1698 660/1698 670/1698 680/1698 690/1698 700/1698 710/1698 720/1698 730/1698 740/1698 750/1698 760/1698 770/1698 780/1698 790/1698 800/1698 810/1698 820/1698 830/1698 840/1698 850/1698 860/1698 870/1698 880/1698 890/1698 900/1698  \n",
            "910/1698 920/1698 930/1698 940/1698 950/1698 960/1698 970/1698 980/1698 990/1698 1000/1698 1010/1698 1020/1698 1030/1698 1040/1698 1050/1698 1060/1698 1070/1698 1080/1698 1090/1698 1100/1698 1110/1698 1120/1698 1130/1698 1140/1698 1150/1698 1160/1698 1170/1698 1180/1698 1190/1698 1200/1698  \n",
            "1210/1698 1220/1698 1230/1698 1240/1698 1250/1698 1260/1698 1270/1698 1280/1698 1290/1698 1300/1698 1310/1698 1320/1698 1330/1698 1340/1698 1350/1698 1360/1698 1370/1698 1380/1698 1390/1698 1400/1698 1410/1698 1420/1698 1430/1698 1440/1698 1450/1698 1460/1698 1470/1698 1480/1698 1490/1698 1500/1698  \n",
            "1510/1698 1520/1698 1530/1698 1540/1698 1550/1698 1560/1698 1570/1698 1580/1698 1590/1698 1600/1698 1610/1698 1620/1698 1630/1698 1640/1698 1650/1698 1660/1698 1670/1698 1680/1698 1690/1698 \n",
            "File Number 2: 150/1698 160/1698 170/1698 180/1698 190/1698 200/1698 210/1698 220/1698 230/1698 240/1698 250/1698 260/1698 270/1698 280/1698 290/1698 300/1698  \n",
            "310/1698 320/1698 330/1698 340/1698 350/1698 360/1698 370/1698 380/1698 390/1698 400/1698 410/1698 420/1698 430/1698 440/1698 450/1698 460/1698 470/1698 480/1698 490/1698 500/1698 510/1698 520/1698 530/1698 540/1698 550/1698 560/1698 570/1698 580/1698 590/1698 600/1698  \n",
            "610/1698 620/1698 630/1698 640/1698 650/1698 660/1698 670/1698 680/1698 690/1698 700/1698 710/1698 720/1698 730/1698 740/1698 750/1698 760/1698 770/1698 780/1698 790/1698 800/1698 810/1698 820/1698 830/1698 840/1698 850/1698 860/1698 870/1698 880/1698 890/1698 900/1698  \n",
            "910/1698 920/1698 930/1698 940/1698 950/1698 960/1698 970/1698 980/1698 990/1698 1000/1698 1010/1698 1020/1698 1030/1698 1040/1698 1050/1698 1060/1698 1070/1698 1080/1698 1090/1698 1100/1698 1110/1698 1120/1698 1130/1698 1140/1698 1150/1698 1160/1698 1170/1698 1180/1698 1190/1698 1200/1698  \n",
            "1210/1698 1220/1698 1230/1698 1240/1698 1250/1698 1260/1698 1270/1698 1280/1698 1290/1698 1300/1698 1310/1698 1320/1698 1330/1698 1340/1698 1350/1698 1360/1698 1370/1698 1380/1698 1390/1698 1400/1698 1410/1698 1420/1698 1430/1698 1440/1698 1450/1698 1460/1698 1470/1698 1480/1698 1490/1698 1500/1698  \n",
            "1510/1698 1520/1698 1530/1698 1540/1698 1550/1698 1560/1698 1570/1698 1580/1698 1590/1698 1600/1698 1610/1698 1620/1698 1630/1698 1640/1698 1650/1698 1660/1698 1670/1698 1680/1698 1690/1698 \n",
            "File Number 3: 150/1698 160/1698 170/1698 180/1698 190/1698 200/1698 210/1698 220/1698 230/1698 240/1698 250/1698 260/1698 270/1698 280/1698 290/1698 300/1698  \n",
            "310/1698 320/1698 330/1698 340/1698 350/1698 360/1698 370/1698 380/1698 390/1698 400/1698 410/1698 420/1698 430/1698 440/1698 450/1698 460/1698 470/1698 480/1698 490/1698 500/1698 510/1698 520/1698 530/1698 540/1698 550/1698 560/1698 570/1698 580/1698 590/1698 600/1698  \n",
            "610/1698 620/1698 630/1698 640/1698 650/1698 660/1698 670/1698 680/1698 690/1698 700/1698 710/1698 720/1698 730/1698 740/1698 750/1698 760/1698 770/1698 780/1698 790/1698 800/1698 810/1698 820/1698 830/1698 840/1698 850/1698 860/1698 870/1698 880/1698 890/1698 900/1698  \n",
            "910/1698 920/1698 930/1698 940/1698 950/1698 960/1698 970/1698 980/1698 990/1698 1000/1698 1010/1698 1020/1698 1030/1698 1040/1698 1050/1698 1060/1698 1070/1698 1080/1698 1090/1698 1100/1698 1110/1698 1120/1698 1130/1698 1140/1698 1150/1698 1160/1698 1170/1698 1180/1698 1190/1698 1200/1698  \n",
            "1210/1698 1220/1698 1230/1698 1240/1698 1250/1698 1260/1698 1270/1698 1280/1698 1290/1698 1300/1698 1310/1698 1320/1698 1330/1698 1340/1698 1350/1698 1360/1698 1370/1698 1380/1698 1390/1698 1400/1698 1410/1698 1420/1698 1430/1698 1440/1698 1450/1698 1460/1698 1470/1698 1480/1698 1490/1698 1500/1698  \n",
            "1510/1698 1520/1698 1530/1698 1540/1698 1550/1698 1560/1698 1570/1698 1580/1698 1590/1698 1600/1698 1610/1698 1620/1698 1630/1698 1640/1698 1650/1698 1660/1698 1670/1698 1680/1698 1690/1698 \n",
            "File Number 4: 150/2847 160/2847 170/2847 180/2847 190/2847 200/2847 210/2847 220/2847 230/2847 240/2847 250/2847 260/2847 270/2847 280/2847 290/2847 300/2847  \n",
            "310/2847 320/2847 330/2847 340/2847 350/2847 360/2847 370/2847 380/2847 390/2847 400/2847 410/2847 420/2847 430/2847 440/2847 450/2847 460/2847 470/2847 480/2847 490/2847 500/2847 510/2847 520/2847 530/2847 540/2847 550/2847 560/2847 570/2847 580/2847 590/2847 600/2847  \n",
            "610/2847 620/2847 630/2847 640/2847 650/2847 660/2847 670/2847 680/2847 690/2847 700/2847 710/2847 720/2847 730/2847 740/2847 750/2847 760/2847 770/2847 780/2847 790/2847 800/2847 810/2847 820/2847 830/2847 840/2847 850/2847 860/2847 870/2847 880/2847 890/2847 900/2847  \n",
            "910/2847 920/2847 930/2847 940/2847 950/2847 960/2847 970/2847 980/2847 990/2847 1000/2847 1010/2847 1020/2847 1030/2847 1040/2847 1050/2847 1060/2847 1070/2847 1080/2847 1090/2847 1100/2847 1110/2847 1120/2847 1130/2847 1140/2847 1150/2847 1160/2847 1170/2847 1180/2847 1190/2847 1200/2847  \n",
            "1210/2847 1220/2847 1230/2847 1240/2847 1250/2847 1260/2847 1270/2847 1280/2847 1290/2847 1300/2847 1310/2847 1320/2847 1330/2847 1340/2847 1350/2847 1360/2847 1370/2847 1380/2847 1390/2847 1400/2847 1410/2847 1420/2847 1430/2847 1440/2847 1450/2847 1460/2847 1470/2847 1480/2847 1490/2847 1500/2847  \n",
            "1510/2847 1520/2847 1530/2847 1540/2847 1550/2847 1560/2847 1570/2847 1580/2847 1590/2847 1600/2847 1610/2847 1620/2847 1630/2847 1640/2847 1650/2847 1660/2847 1670/2847 1680/2847 1690/2847 1700/2847 1710/2847 1720/2847 1730/2847 1740/2847 1750/2847 1760/2847 1770/2847 1780/2847 1790/2847 1800/2847  \n",
            "1810/2847 1820/2847 1830/2847 1840/2847 1850/2847 1860/2847 1870/2847 1880/2847 1890/2847 1900/2847 1910/2847 1920/2847 1930/2847 1940/2847 1950/2847 1960/2847 1970/2847 1980/2847 1990/2847 2000/2847 2010/2847 2020/2847 2030/2847 2040/2847 2050/2847 2060/2847 2070/2847 2080/2847 2090/2847 2100/2847  \n",
            "2110/2847 2120/2847 2130/2847 2140/2847 2150/2847 2160/2847 2170/2847 2180/2847 2190/2847 2200/2847 2210/2847 2220/2847 2230/2847 2240/2847 2250/2847 2260/2847 2270/2847 2280/2847 2290/2847 2300/2847 2310/2847 2320/2847 2330/2847 2340/2847 2350/2847 2360/2847 2370/2847 2380/2847 2390/2847 2400/2847  \n",
            "2410/2847 2420/2847 2430/2847 2440/2847 2450/2847 2460/2847 2470/2847 2480/2847 2490/2847 2500/2847 2510/2847 2520/2847 2530/2847 2540/2847 2550/2847 2560/2847 2570/2847 2580/2847 2590/2847 2600/2847 2610/2847 2620/2847 2630/2847 2640/2847 2650/2847 2660/2847 2670/2847 2680/2847 2690/2847 2700/2847  \n",
            "2710/2847 2720/2847 2730/2847 2740/2847 2750/2847 2760/2847 2770/2847 2780/2847 2790/2847 2800/2847 2810/2847 2820/2847 2830/2847 2840/2847 \n",
            "File Number 5: 150/1698 160/1698 170/1698 180/1698 190/1698 200/1698 210/1698 220/1698 230/1698 240/1698 250/1698 260/1698 270/1698 280/1698 290/1698 300/1698  \n",
            "310/1698 320/1698 330/1698 340/1698 350/1698 360/1698 370/1698 380/1698 390/1698 400/1698 410/1698 420/1698 430/1698 440/1698 450/1698 460/1698 470/1698 480/1698 490/1698 500/1698 510/1698 520/1698 530/1698 540/1698 550/1698 560/1698 570/1698 580/1698 590/1698 600/1698  \n",
            "610/1698 620/1698 630/1698 640/1698 650/1698 660/1698 670/1698 680/1698 690/1698 700/1698 710/1698 720/1698 730/1698 740/1698 750/1698 760/1698 770/1698 780/1698 790/1698 800/1698 810/1698 820/1698 830/1698 840/1698 850/1698 860/1698 870/1698 880/1698 890/1698 900/1698  \n",
            "910/1698 920/1698 930/1698 940/1698 950/1698 960/1698 970/1698 980/1698 990/1698 1000/1698 1010/1698 1020/1698 1030/1698 1040/1698 1050/1698 1060/1698 1070/1698 1080/1698 1090/1698 1100/1698 1110/1698 1120/1698 1130/1698 1140/1698 1150/1698 1160/1698 1170/1698 1180/1698 1190/1698 1200/1698  \n",
            "1210/1698 1220/1698 1230/1698 1240/1698 1250/1698 1260/1698 1270/1698 1280/1698 1290/1698 1300/1698 1310/1698 1320/1698 1330/1698 1340/1698 1350/1698 1360/1698 1370/1698 1380/1698 1390/1698 1400/1698 1410/1698 1420/1698 1430/1698 1440/1698 1450/1698 1460/1698 1470/1698 1480/1698 1490/1698 1500/1698  \n",
            "1510/1698 1520/1698 1530/1698 1540/1698 1550/1698 1560/1698 1570/1698 1580/1698 1590/1698 1600/1698 1610/1698 1620/1698 1630/1698 1640/1698 1650/1698 1660/1698 1670/1698 1680/1698 1690/1698 \n",
            "File Number 6: 150/2847 160/2847 170/2847 180/2847 190/2847 200/2847 210/2847 220/2847 230/2847 240/2847 250/2847 260/2847 270/2847 280/2847 290/2847 300/2847  \n",
            "310/2847 320/2847 330/2847 340/2847 350/2847 360/2847 370/2847 380/2847 390/2847 400/2847 410/2847 420/2847 430/2847 440/2847 450/2847 460/2847 470/2847 480/2847 490/2847 500/2847 510/2847 520/2847 530/2847 540/2847 550/2847 560/2847 570/2847 580/2847 590/2847 600/2847  \n",
            "610/2847 620/2847 630/2847 640/2847 650/2847 660/2847 670/2847 680/2847 690/2847 700/2847 710/2847 720/2847 730/2847 740/2847 750/2847 760/2847 770/2847 780/2847 790/2847 800/2847 810/2847 820/2847 830/2847 840/2847 850/2847 860/2847 870/2847 880/2847 890/2847 900/2847  \n",
            "910/2847 920/2847 930/2847 940/2847 950/2847 960/2847 970/2847 980/2847 990/2847 1000/2847 1010/2847 1020/2847 1030/2847 1040/2847 1050/2847 1060/2847 1070/2847 1080/2847 1090/2847 1100/2847 1110/2847 1120/2847 1130/2847 1140/2847 1150/2847 1160/2847 1170/2847 1180/2847 1190/2847 1200/2847  \n",
            "1210/2847 1220/2847 1230/2847 1240/2847 1250/2847 1260/2847 1270/2847 1280/2847 1290/2847 1300/2847 1310/2847 1320/2847 1330/2847 1340/2847 1350/2847 1360/2847 1370/2847 1380/2847 1390/2847 1400/2847 1410/2847 1420/2847 1430/2847 1440/2847 1450/2847 1460/2847 1470/2847 1480/2847 1490/2847 1500/2847  \n",
            "1510/2847 1520/2847 1530/2847 1540/2847 1550/2847 1560/2847 1570/2847 1580/2847 1590/2847 1600/2847 1610/2847 1620/2847 1630/2847 1640/2847 1650/2847 1660/2847 1670/2847 1680/2847 1690/2847 1700/2847 1710/2847 1720/2847 1730/2847 1740/2847 1750/2847 1760/2847 1770/2847 1780/2847 1790/2847 1800/2847  \n",
            "1810/2847 1820/2847 1830/2847 1840/2847 1850/2847 1860/2847 1870/2847 1880/2847 1890/2847 1900/2847 1910/2847 1920/2847 1930/2847 1940/2847 1950/2847 1960/2847 1970/2847 1980/2847 1990/2847 2000/2847 2010/2847 2020/2847 2030/2847 2040/2847 2050/2847 2060/2847 2070/2847 2080/2847 2090/2847 2100/2847  \n",
            "2110/2847 2120/2847 2130/2847 2140/2847 2150/2847 2160/2847 2170/2847 2180/2847 2190/2847 2200/2847 2210/2847 2220/2847 2230/2847 2240/2847 2250/2847 2260/2847 2270/2847 2280/2847 2290/2847 2300/2847 2310/2847 2320/2847 2330/2847 2340/2847 2350/2847 2360/2847 2370/2847 2380/2847 2390/2847 2400/2847  \n",
            "2410/2847 2420/2847 2430/2847 2440/2847 2450/2847 2460/2847 2470/2847 2480/2847 2490/2847 2500/2847 2510/2847 2520/2847 2530/2847 2540/2847 2550/2847 2560/2847 2570/2847 2580/2847 2590/2847 2600/2847 2610/2847 2620/2847 2630/2847 2640/2847 2650/2847 2660/2847 2670/2847 2680/2847 2690/2847 2700/2847  \n",
            "2710/2847 2720/2847 2730/2847 2740/2847 2750/2847 2760/2847 2770/2847 2780/2847 2790/2847 2800/2847 2810/2847 2820/2847 2830/2847 2840/2847 \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11586"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "how_many_future_candles = 20\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 150\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EATThOC_BfB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47fa5ae1-bb6b-4474-9afa-3cd9826b9e5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/191751.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(\"/content/extracted/084505.zip\",\"/content/extracted/455\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dQpQvhf-pwpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8c2ce8-646d-4dca-d1ed-cebc80be3220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11586, 128, 128)\n",
            "xTrain : 9268 \\ xTest : 2318\n",
            "yn: 6178 nn: 5408\n"
          ]
        }
      ],
      "source": [
        "#folder_name = '112904'\n",
        "\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name,0)\n",
        "\n",
        "    dim = (128, 128)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9stbJK8Nx_0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "976a4e4a-7027-4fc3-c870-08d5313af449"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-240b3404632f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xTrain' is not defined"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128,    (3, 3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],1)))\n",
        "model.add(Conv2D(100,    (3, 3),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,    (3, 3),activation=\"relu\",))\n",
        "model.add(Conv2D(64,    (3, 3),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,    (2, 2),activation=\"relu\",))\n",
        "model.add(Conv2D(32,    (2, 2),activation=\"relu\",))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cytWxowTyInc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d57e378-1d0e-49b4-ea81-e97acc3b3510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  2/290 [..............................] - ETA: 47:52 - loss: 2.2425 - accuracy: 0.5469"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=32,epochs=20,validation_data=(xTest,yTest))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "testsubject3fro_ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
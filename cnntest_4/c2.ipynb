{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bxbCoe9do9",
        "outputId": "eaf363eb-5117-4767-f1b5-5be83e84f252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 657 kB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.1\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.9.1 requests-2.28.1 yfinance-0.1.74\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 385 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.9.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2022.6.15)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 12.2 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2022.6.15)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.10 websocket-client-1.3.3 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.1)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=7c6c474cfcdeffe4b1cfc2a5a98cf29308b81f0993823144ebc1fd52a5715af9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "!pip install tensorflow\n",
        "!pip install --upgrade mplfinance\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "import mplfinance as mpl \n",
        "from datetime import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "!pip install cairocffi\n",
        "matplotlib.use('Cairo')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,AveragePooling2D,GlobalAveragePooling2D\n",
        "!pip install -U git+https://github.com/twopirllc/pandas-ta\n",
        "import pandas_ta as pta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB_YMoe09qVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "  if not os.path.exists(\"/content/checkpoints/\"):\n",
        "    os.mkdir(\"/content/checkpoints/\")\n",
        "\n",
        "\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "\n",
        "\n",
        "def download_data(symbols, periodd, intervall):\n",
        "  indexx = 100\n",
        "  work_with_dir()\n",
        "  for symbol in symbols:\n",
        "    if ((symbols.index(symbol)+1) % 100 == 0):\n",
        "      print(f\" -- {indexx}\", end=\"\")\n",
        "      indexx = indexx + 100\n",
        "    try:\n",
        "        data = yf.download(symbol, period=periodd,\n",
        "                           interval=intervall, progress=False, show_errors=False)\n",
        "        if data.empty:\n",
        "           pass\n",
        "        else:\n",
        "            data.to_csv(f\"/content/data/{symbol}.csv\")\n",
        "    except:\n",
        "       print(\"Error!\")\n",
        "  print(\" \")\n",
        "\n",
        "\n",
        "def extract_data(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  index = 1\n",
        "  for file in files:\n",
        "     print(f\"File Number {index}:\", end=\" \")\n",
        "     each_file_proc(file, now, how_many_future_candles,\n",
        "                    how_many_past_candles, each_row_past)\n",
        "     index = index + 1\n",
        "  print(\" \")\n",
        "  return now\n",
        "\n",
        "\n",
        "def each_file_proc(file, now, how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "\n",
        "    address = f\"/content/data/{file}\"\n",
        "    data = pd.read_csv(address)\n",
        "    data = data.dropna()\n",
        "    dfs = []\n",
        "    suggs = []\n",
        "    df = None\n",
        "    _a = None\n",
        "    if len(data.columns) == 7:\n",
        "      data = data.iloc[:, 1:]\n",
        "    #data[\"6_rsi\"] =  pta.rsi(data['Close'], length = 6)\n",
        "    #data[\"14_rsi\"] = pta.rsi(data['Close'], length = 14)\n",
        "    #data[\"26_rsi\"] = pta.rsi(data['Close'], length = 26)\n",
        "    #data[\"52_rsi\"] = pta.rsi(data['Close'], length = 52)\n",
        "\n",
        "    data = np.array(data)\n",
        "    data = data.astype(float)\n",
        "    max_index = data.shape[0]-which_future_or_past\n",
        "    for i in range(each_row_past,max_index):\n",
        "\n",
        "        rows = data[i-each_row_past:i, :]\n",
        "        past_candles = []\n",
        "        for z in range(1, how_many_past_candles+1):\n",
        "          past_candles.append((data[i-z][3]+data[i-z][0])/2)\n",
        "        past_candles = sum(past_candles)/len(past_candles)\n",
        "        next_candles = []\n",
        "        for z in range(0, how_many_future_candles):\n",
        "          next_candles.append((data[i+z][3]+data[i+z][0])/2)\n",
        "        next_candles = sum(next_candles)/len(next_candles)\n",
        "        if next_candles > past_candles:\n",
        "          sugg = 1\n",
        "        else:\n",
        "          sugg = 0\n",
        "\n",
        "        #x = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"6_rsi\", \"14_rsi\", \"26_rsi\",\"52_rsi\"])\n",
        "        df = pd.DataFrame(rows, columns=[\"Open\", \"High\", \"Low\", \"Close\",\"Adj Close\",\"Volume\"])\n",
        "\n",
        "        df.index.name = \"Date\"\n",
        "        #date_list = []\n",
        "        #rng = np.array(df).shape[0]\n",
        "        #for i in range(rrng):\n",
        "        #    date_list.append(datetime.fromordinal(\n",
        "        #        datetime.today().toordinal()+i).strftime('%Y-%m-%d'))\n",
        "        #df.index = date_list\n",
        "        #df.index.name = \"Date\"\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "        address = f\"/content/extracted/{now}/{right_now}_{sugg}.png\"\n",
        "        \n",
        "        #apds = [ \n",
        "        # mpl.make_addplot(df[\"6_rsi\"],color='b',width=2),\n",
        "        # mpl.make_addplot(df[\"14_rsi\"],color='g',width=2),\n",
        "        # mpl.make_addplot(df[\"26_rsi\"],color='r',width=2),\n",
        "        # mpl.make_addplot(df[\"52_rsi\"],color='y',width=2),\n",
        "       #]\n",
        "        \n",
        "        fig, _a = mpl.plot(df, type=\"candle\", style=\"yahoo\", axisoff=True,\n",
        "                            returnfig=True, tight_layout=True,figsize =(1.5,1.5))\n",
        "        \n",
        "        fig.savefig(address)\n",
        "        fig.clear()\n",
        "    \n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i}/{max_index}\", end=\" \")\n",
        "        if i % 160 == 0:\n",
        "          print(\" \")\n",
        "        if i % 19 == 0:\n",
        "          plt.close(\"all\")\n",
        "    plt.close(\"all\")\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "def start(how_many_future_candles, how_many_past_candles, each_row_past):\n",
        "    folder_name = extract_data(\n",
        "        how_many_future_candles, how_many_past_candles, each_row_past)\n",
        "    return folder_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMR8z1BIS-M_"
      },
      "outputs": [],
      "source": [
        "symbols = get_crypto_syms()\n",
        "print(f\"Symbols : {len(symbols)}\")\n",
        "symbols = [\"btc-usd\",\"eth-usd\",\"trx-usd\",\"ltc-usd\",\"xrp-usd\",\"bnb-usd\"]\n",
        "download_data(symbols,\"max\",\"1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTyv_osQAnY",
        "outputId": "6895278f-b581-45df-fd98-bf3de2a0937f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files In Data : 6\n",
            "Processing File:\n",
            "File Number 1: 10/1548 20/1548 30/1548 40/1548 50/1548 60/1548 70/1548 80/1548 90/1548 100/1548 110/1548 120/1548 130/1548 140/1548 150/1548 160/1548  \n",
            "170/1548 180/1548 190/1548 200/1548 210/1548 220/1548 230/1548 240/1548 250/1548 260/1548 270/1548 280/1548 290/1548 300/1548 310/1548 320/1548  \n",
            "330/1548 340/1548 350/1548 360/1548 370/1548 380/1548 390/1548 400/1548 410/1548 420/1548 430/1548 440/1548 450/1548 460/1548 470/1548 480/1548  \n",
            "490/1548 500/1548 510/1548 520/1548 530/1548 540/1548 550/1548 560/1548 570/1548 580/1548 590/1548 600/1548 610/1548 620/1548 630/1548 640/1548  \n",
            "650/1548 660/1548 670/1548 680/1548 690/1548 700/1548 710/1548 720/1548 730/1548 740/1548 750/1548 760/1548 770/1548 780/1548 790/1548 800/1548  \n",
            "810/1548 820/1548 830/1548 840/1548 850/1548 860/1548 870/1548 880/1548 890/1548 900/1548 910/1548 920/1548 930/1548 940/1548 950/1548 960/1548  \n",
            "970/1548 980/1548 990/1548 1000/1548 1010/1548 1020/1548 1030/1548 1040/1548 1050/1548 1060/1548 1070/1548 1080/1548 1090/1548 1100/1548 1110/1548 1120/1548  \n",
            "1130/1548 1140/1548 1150/1548 1160/1548 1170/1548 1180/1548 1190/1548 1200/1548 1210/1548 1220/1548 1230/1548 1240/1548 1250/1548 1260/1548 1270/1548 1280/1548  \n",
            "1290/1548 1300/1548 1310/1548 1320/1548 1330/1548 1340/1548 1350/1548 1360/1548 1370/1548 1380/1548 1390/1548 1400/1548 1410/1548 1420/1548 1430/1548 1440/1548  \n",
            "1450/1548 1460/1548 1470/1548 1480/1548 1490/1548 1500/1548 1510/1548 1520/1548 1530/1548 1540/1548 \n",
            "File Number 2: 10/1548 20/1548 30/1548 40/1548 50/1548 60/1548 70/1548 80/1548 90/1548 100/1548 110/1548 120/1548 130/1548 140/1548 150/1548 160/1548  \n",
            "170/1548 180/1548 190/1548 200/1548 210/1548 220/1548 230/1548 240/1548 250/1548 260/1548 270/1548 280/1548 290/1548 300/1548 310/1548 320/1548  \n",
            "330/1548 340/1548 350/1548 360/1548 370/1548 380/1548 390/1548 400/1548 410/1548 420/1548 430/1548 440/1548 450/1548 460/1548 470/1548 480/1548  \n",
            "490/1548 500/1548 510/1548 520/1548 530/1548 540/1548 550/1548 560/1548 570/1548 580/1548 590/1548 600/1548 610/1548 620/1548 630/1548 640/1548  \n",
            "650/1548 660/1548 670/1548 680/1548 690/1548 700/1548 710/1548 720/1548 730/1548 740/1548 750/1548 760/1548 770/1548 780/1548 790/1548 800/1548  \n",
            "810/1548 820/1548 830/1548 840/1548 850/1548 860/1548 870/1548 880/1548 890/1548 900/1548 910/1548 920/1548 930/1548 940/1548 950/1548 960/1548  \n",
            "970/1548 980/1548 990/1548 1000/1548 1010/1548 1020/1548 1030/1548 1040/1548 1050/1548 1060/1548 1070/1548 1080/1548 1090/1548 1100/1548 1110/1548 1120/1548  \n",
            "1130/1548 1140/1548 1150/1548 1160/1548 1170/1548 1180/1548 1190/1548 1200/1548 1210/1548 1220/1548 1230/1548 1240/1548 1250/1548 1260/1548 1270/1548 1280/1548  \n",
            "1290/1548 1300/1548 1310/1548 1320/1548 1330/1548 1340/1548 1350/1548 1360/1548 1370/1548 1380/1548 1390/1548 1400/1548 1410/1548 1420/1548 1430/1548 1440/1548  \n",
            "1450/1548 1460/1548 1470/1548 1480/1548 1490/1548 1500/1548 1510/1548 1520/1548 1530/1548 1540/1548 \n",
            "File Number 3: 10/1548 20/1548 30/1548 40/1548 50/1548 60/1548 70/1548 80/1548 90/1548 100/1548 110/1548 120/1548 130/1548 140/1548 150/1548 160/1548  \n",
            "170/1548 180/1548 190/1548 200/1548 210/1548 220/1548 230/1548 240/1548 250/1548 260/1548 270/1548 280/1548 290/1548 300/1548 310/1548 320/1548  \n",
            "330/1548 340/1548 350/1548 360/1548 370/1548 380/1548 390/1548 400/1548 410/1548 420/1548 430/1548 440/1548 450/1548 460/1548 470/1548 480/1548  \n",
            "490/1548 500/1548 510/1548 520/1548 530/1548 540/1548 550/1548 560/1548 570/1548 580/1548 590/1548 600/1548 610/1548 620/1548 630/1548 640/1548  \n",
            "650/1548 660/1548 670/1548 680/1548 690/1548 700/1548 710/1548 720/1548 730/1548 740/1548 750/1548 760/1548 770/1548 780/1548 790/1548 800/1548  \n",
            "810/1548 820/1548 830/1548 840/1548 850/1548 860/1548 870/1548 880/1548 890/1548 900/1548 910/1548 920/1548 930/1548 940/1548 950/1548 960/1548  \n",
            "970/1548 980/1548 990/1548 1000/1548 1010/1548 1020/1548 1030/1548 1040/1548 1050/1548 1060/1548 1070/1548 1080/1548 1090/1548 1100/1548 1110/1548 1120/1548  \n",
            "1130/1548 1140/1548 1150/1548 1160/1548 1170/1548 1180/1548 1190/1548 1200/1548 1210/1548 1220/1548 1230/1548 1240/1548 1250/1548 1260/1548 1270/1548 1280/1548  \n",
            "1290/1548 1300/1548 1310/1548 1320/1548 1330/1548 1340/1548 1350/1548 1360/1548 1370/1548 1380/1548 1390/1548 1400/1548 1410/1548 1420/1548 1430/1548 1440/1548  \n",
            "1450/1548 1460/1548 1470/1548 1480/1548 1490/1548 1500/1548 1510/1548 1520/1548 1530/1548 1540/1548 \n",
            "File Number 4: 10/2697 20/2697 30/2697 40/2697 50/2697 60/2697 70/2697 80/2697 90/2697 100/2697 110/2697 120/2697 130/2697 140/2697 150/2697 160/2697  \n",
            "170/2697 180/2697 190/2697 200/2697 210/2697 220/2697 230/2697 240/2697 250/2697 260/2697 270/2697 280/2697 290/2697 300/2697 310/2697 320/2697  \n",
            "330/2697 340/2697 350/2697 360/2697 370/2697 380/2697 390/2697 400/2697 410/2697 420/2697 430/2697 440/2697 450/2697 460/2697 470/2697 480/2697  \n",
            "490/2697 500/2697 510/2697 520/2697 530/2697 540/2697 550/2697 560/2697 570/2697 580/2697 590/2697 600/2697 610/2697 620/2697 630/2697 640/2697  \n",
            "650/2697 660/2697 670/2697 680/2697 690/2697 700/2697 710/2697 720/2697 730/2697 740/2697 750/2697 760/2697 770/2697 780/2697 790/2697 800/2697  \n",
            "810/2697 820/2697 830/2697 840/2697 850/2697 860/2697 870/2697 880/2697 890/2697 900/2697 910/2697 920/2697 930/2697 940/2697 950/2697 960/2697  \n",
            "970/2697 980/2697 990/2697 1000/2697 1010/2697 1020/2697 1030/2697 1040/2697 1050/2697 1060/2697 1070/2697 1080/2697 1090/2697 1100/2697 1110/2697 1120/2697  \n",
            "1130/2697 1140/2697 1150/2697 1160/2697 1170/2697 1180/2697 1190/2697 1200/2697 1210/2697 1220/2697 1230/2697 1240/2697 1250/2697 1260/2697 1270/2697 1280/2697  \n",
            "1290/2697 1300/2697 1310/2697 1320/2697 1330/2697 1340/2697 1350/2697 1360/2697 1370/2697 1380/2697 1390/2697 1400/2697 1410/2697 1420/2697 1430/2697 1440/2697  \n",
            "1450/2697 1460/2697 1470/2697 1480/2697 1490/2697 1500/2697 1510/2697 1520/2697 1530/2697 1540/2697 1550/2697 1560/2697 1570/2697 1580/2697 1590/2697 1600/2697  \n",
            "1610/2697 1620/2697 1630/2697 1640/2697 1650/2697 1660/2697 1670/2697 1680/2697 1690/2697 1700/2697 1710/2697 1720/2697 1730/2697 1740/2697 1750/2697 1760/2697  \n",
            "1770/2697 1780/2697 1790/2697 1800/2697 1810/2697 1820/2697 1830/2697 1840/2697 1850/2697 1860/2697 1870/2697 1880/2697 1890/2697 1900/2697 1910/2697 1920/2697  \n",
            "1930/2697 1940/2697 1950/2697 1960/2697 1970/2697 1980/2697 1990/2697 2000/2697 2010/2697 2020/2697 2030/2697 2040/2697 2050/2697 2060/2697 2070/2697 2080/2697  \n",
            "2090/2697 2100/2697 2110/2697 2120/2697 2130/2697 2140/2697 2150/2697 2160/2697 2170/2697 2180/2697 2190/2697 2200/2697 2210/2697 2220/2697 2230/2697 2240/2697  \n",
            "2250/2697 2260/2697 2270/2697 2280/2697 2290/2697 2300/2697 2310/2697 2320/2697 2330/2697 2340/2697 2350/2697 2360/2697 2370/2697 2380/2697 2390/2697 2400/2697  \n",
            "2410/2697 2420/2697 2430/2697 2440/2697 2450/2697 2460/2697 2470/2697 2480/2697 2490/2697 2500/2697 2510/2697 2520/2697 2530/2697 2540/2697 2550/2697 2560/2697  \n",
            "2570/2697 2580/2697 2590/2697 2600/2697 2610/2697 2620/2697 2630/2697 2640/2697 2650/2697 2660/2697 2670/2697 2680/2697 2690/2697 \n",
            "File Number 5: 10/1548 20/1548 30/1548 40/1548 50/1548 60/1548 70/1548 80/1548 90/1548 100/1548 110/1548 120/1548 130/1548 140/1548 150/1548 160/1548  \n",
            "170/1548 180/1548 190/1548 200/1548 210/1548 220/1548 230/1548 240/1548 250/1548 260/1548 270/1548 280/1548 290/1548 300/1548 310/1548 320/1548  \n",
            "330/1548 340/1548 350/1548 360/1548 370/1548 380/1548 390/1548 400/1548 410/1548 420/1548 430/1548 440/1548 450/1548 460/1548 470/1548 480/1548  \n",
            "490/1548 500/1548 510/1548 520/1548 530/1548 540/1548 550/1548 560/1548 570/1548 580/1548 590/1548 600/1548 610/1548 620/1548 630/1548 640/1548  \n",
            "650/1548 660/1548 670/1548 680/1548 690/1548 700/1548 710/1548 720/1548 730/1548 740/1548 750/1548 760/1548 770/1548 780/1548 790/1548 800/1548  \n",
            "810/1548 820/1548 830/1548 840/1548 850/1548 860/1548 870/1548 880/1548 890/1548 900/1548 910/1548 920/1548 930/1548 940/1548 950/1548 960/1548  \n",
            "970/1548 980/1548 990/1548 1000/1548 1010/1548 1020/1548 1030/1548 1040/1548 1050/1548 1060/1548 1070/1548 1080/1548 1090/1548 1100/1548 1110/1548 1120/1548  \n",
            "1130/1548 1140/1548 1150/1548 1160/1548 1170/1548 1180/1548 1190/1548 1200/1548 1210/1548 1220/1548 1230/1548 1240/1548 1250/1548 1260/1548 1270/1548 1280/1548  \n",
            "1290/1548 1300/1548 1310/1548 1320/1548 1330/1548 1340/1548 1350/1548 1360/1548 1370/1548 1380/1548 1390/1548 1400/1548 1410/1548 1420/1548 1430/1548 1440/1548  \n",
            "1450/1548 1460/1548 1470/1548 1480/1548 1490/1548 1500/1548 1510/1548 1520/1548 1530/1548 1540/1548 \n",
            "File Number 6: 10/2697 20/2697 30/2697 40/2697 50/2697 60/2697 70/2697 80/2697 90/2697 100/2697 110/2697 120/2697 130/2697 140/2697 150/2697 160/2697  \n",
            "170/2697 180/2697 190/2697 200/2697 210/2697 220/2697 230/2697 240/2697 250/2697 260/2697 270/2697 280/2697 290/2697 300/2697 310/2697 320/2697  \n",
            "330/2697 340/2697 350/2697 360/2697 370/2697 380/2697 390/2697 400/2697 410/2697 420/2697 430/2697 440/2697 450/2697 460/2697 470/2697 480/2697  \n",
            "490/2697 500/2697 510/2697 520/2697 530/2697 540/2697 550/2697 560/2697 570/2697 580/2697 590/2697 600/2697 610/2697 620/2697 630/2697 640/2697  \n",
            "650/2697 660/2697 670/2697 680/2697 690/2697 700/2697 710/2697 720/2697 730/2697 740/2697 750/2697 760/2697 770/2697 780/2697 790/2697 800/2697  \n",
            "810/2697 820/2697 830/2697 840/2697 850/2697 860/2697 870/2697 880/2697 890/2697 900/2697 910/2697 920/2697 930/2697 940/2697 950/2697 960/2697  \n",
            "970/2697 980/2697 990/2697 1000/2697 1010/2697 1020/2697 1030/2697 1040/2697 1050/2697 1060/2697 1070/2697 1080/2697 1090/2697 1100/2697 1110/2697 1120/2697  \n",
            "1130/2697 1140/2697 1150/2697 1160/2697 1170/2697 1180/2697 1190/2697 1200/2697 1210/2697 1220/2697 1230/2697 1240/2697 1250/2697 1260/2697 1270/2697 1280/2697  \n",
            "1290/2697 1300/2697 1310/2697 1320/2697 1330/2697 1340/2697 1350/2697 1360/2697 1370/2697 1380/2697 1390/2697 1400/2697 1410/2697 1420/2697 1430/2697 1440/2697  \n",
            "1450/2697 1460/2697 1470/2697 1480/2697 1490/2697 1500/2697 1510/2697 1520/2697 1530/2697 1540/2697 1550/2697 1560/2697 1570/2697 1580/2697 1590/2697 1600/2697  \n",
            "1610/2697 1620/2697 1630/2697 1640/2697 1650/2697 1660/2697 1670/2697 1680/2697 1690/2697 1700/2697 1710/2697 1720/2697 1730/2697 1740/2697 1750/2697 1760/2697  \n",
            "1770/2697 1780/2697 1790/2697 1800/2697 1810/2697 1820/2697 1830/2697 1840/2697 1850/2697 1860/2697 1870/2697 1880/2697 1890/2697 1900/2697 1910/2697 1920/2697  \n",
            "1930/2697 1940/2697 1950/2697 1960/2697 1970/2697 1980/2697 1990/2697 2000/2697 2010/2697 2020/2697 2030/2697 2040/2697 2050/2697 2060/2697 2070/2697 2080/2697  \n",
            "2090/2697 2100/2697 2110/2697 2120/2697 2130/2697 2140/2697 2150/2697 2160/2697 2170/2697 2180/2697 2190/2697 2200/2697 2210/2697 2220/2697 2230/2697 2240/2697  \n",
            "2250/2697 2260/2697 2270/2697 2280/2697 2290/2697 2300/2697 2310/2697 2320/2697 2330/2697 2340/2697 2350/2697 2360/2697 2370/2697 2380/2697 2390/2697 2400/2697  \n",
            "2410/2697 2420/2697 2430/2697 2440/2697 2450/2697 2460/2697 2470/2697 2480/2697 2490/2697 2500/2697 2510/2697 2520/2697 2530/2697 2540/2697 2550/2697 2560/2697  \n",
            "2570/2697 2580/2697 2590/2697 2600/2697 2610/2697 2620/2697 2630/2697 2640/2697 2650/2697 2660/2697 2670/2697 2680/2697 2690/2697 \n",
            " \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "11586"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "how_many_future_candles = 20\n",
        "how_many_past_candles = 1\n",
        "each_row_past = 150\n",
        "\n",
        "global which_future_or_past\n",
        "which_future_or_past = None\n",
        "if how_many_future_candles > how_many_past_candles:\n",
        "    which_future_or_past = how_many_future_candles\n",
        "else:\n",
        "    which_future_or_past = how_many_past_candles\n",
        "\n",
        "folder_name = start(how_many_future_candles,how_many_past_candles,each_row_past)\n",
        "len(os.listdir(f\"/content/extracted/{folder_name}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EATThOC_BfB2",
        "outputId": "9cc8d37d-6432-4ac3-8cb9-0705b8818fa1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/120943.zip'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shutil.make_archive(folder_name,\"zip\",f\"/content/extracted/{folder_name}/\")\n",
        "#shutil.unpack_archive(\"/content/extracted/084505.zip\",\"/content/extracted/455\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpQvhf-pwpR",
        "outputId": "d4ec6407-e13c-40aa-bf27-8a8b44ce7a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11586, 90, 120, 3)\n",
            "xTrain : 9268 \\ xTest : 2318\n",
            "yn: 6178 nn: 5408\n"
          ]
        }
      ],
      "source": [
        "#folder_name = '112904'\n",
        "\n",
        "label = []\n",
        "data  = []\n",
        "files = os.listdir(f\"/content/extracted/{folder_name}/\")\n",
        "for i, image_name in enumerate(files):\n",
        "  if image_name.split(\".\")[1] == \"png\":\n",
        "    image = cv2.imread(f\"/content/extracted/{folder_name}\"+\"/\"+image_name)\n",
        "\n",
        "    dim = (120, 90)\n",
        "    resized = cv2.resize(image, dim)\n",
        "    data.append(np.array(resized))\n",
        "    sugg = image_name.split(\"_\")[1].split(\".\")[0]\n",
        "    label.append(int(sugg))\n",
        "data = np.array(data)\n",
        "data = data / 255\n",
        "print(data.shape)\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data,label,test_size=0.2,random_state=99)\n",
        "\n",
        "data = None\n",
        "label = None\n",
        "print(f\"xTrain : {len(xTrain)} \\\\ xTest : {len(xTest)}\")\n",
        "\n",
        "nytrain = []\n",
        "nytest = []\n",
        "yn = 0\n",
        "nn = 0\n",
        "\n",
        "for i in yTrain:\n",
        "  if i == 1:\n",
        "    nytrain.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytrain.append([0,1])\n",
        "    nn += 1\n",
        "for i in yTest:\n",
        "  if i == 1:\n",
        "    nytest.append([1,0])\n",
        "    yn += 1\n",
        "  else:\n",
        "    nytest.append([0,1])\n",
        "    nn += 1\n",
        "\n",
        "yTrain = np.array(nytrain)\n",
        "yTest = np.array(nytest)\n",
        "\n",
        "print(f\"yn: {yn} nn: {nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9stbJK8Nx_0c",
        "outputId": "1a950a53-5b46-4433-980d-4dd1dabed219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 88, 118, 128)      3584      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 117, 100)      51300     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 43, 58, 100)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 56, 64)        57664     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 40, 55, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 20, 27, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 18, 25, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 17, 24, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 8, 12, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 750)               2304750   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              769024    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,322,516\n",
            "Trainable params: 5,322,516\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128,    (3, 3),activation=\"relu\", input_shape=(xTrain.shape[1], xTrain.shape[2],3)))\n",
        "model.add(Conv2D(100,     (2, 2),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,    (3, 3),activation=\"relu\",))\n",
        "model.add(Conv2D(32,    (2, 2),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,    (3, 3),activation=\"relu\",))\n",
        "model.add(Conv2D(32,    (2, 2),activation=\"relu\",))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(750,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "adamax = tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adamax,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytWxowTyInc",
        "outputId": "75275d19-67b2-48ef-8ec8-c6593698ca09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1159/1159 [==============================] - 1225s 1s/step - loss: 0.6921 - accuracy: 0.5296 - val_loss: 0.6916 - val_accuracy: 0.5393\n",
            "Epoch 2/20\n",
            "1159/1159 [==============================] - 1230s 1s/step - loss: 0.6915 - accuracy: 0.5306 - val_loss: 0.6903 - val_accuracy: 0.5393\n",
            "Epoch 3/20\n",
            "1159/1159 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5317"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/checkpoints/{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#model.fit(xTrain,yTrain,batch_size=64,epochs=30,validation_data=(xTest,yTest), callbacks=model_checkpoint_callback)\n",
        "model.fit(xTrain,yTrain,batch_size=8,epochs=20,validation_data=(xTest,yTest))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "c2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
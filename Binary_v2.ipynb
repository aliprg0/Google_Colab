{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/aliprg0/Google_Colab/blob/main/Binary_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "cell_id": "59634d8d-c681-4f83-b452-a974a2ab8df0",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 90
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5bxbCoe9do9",
    "outputId": "e8632a7e-5594-4887-b4bc-a7b3c9e13ad2",
    "cell_id": "00001-0b126cdf-5aab-405d-8abe-73aa7d99aa90",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4856123a",
    "execution_start": 1649751458119,
    "execution_millis": 14538,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1061
   },
   "source": "!pip install yfinance\n!pip install yahooquery\nfrom yahooquery import Screener\nimport yfinance as yf   \nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport tensorflow as tf\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sys import getsizeof",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: yfinance in /root/venv/lib/python3.7/site-packages (0.1.70)\nRequirement already satisfied: lxml>=4.5.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yfinance) (4.8.0)\nRequirement already satisfied: requests>=2.26 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yfinance) (2.27.1)\nRequirement already satisfied: numpy>=1.15 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yfinance) (1.21.5)\nRequirement already satisfied: multitasking>=0.0.7 in /root/venv/lib/python3.7/site-packages (from yfinance) (0.0.10)\nRequirement already satisfied: pandas>=0.24.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yfinance) (1.2.5)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests>=2.26->yfinance) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests>=2.26->yfinance) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests>=2.26->yfinance) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests>=2.26->yfinance) (3.3)\nRequirement already satisfied: pytz>=2017.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas>=0.24.0->yfinance) (2022.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.16.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: yahooquery in /root/venv/lib/python3.7/site-packages (2.2.15)\nRequirement already satisfied: tqdm>=4.54.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yahooquery) (4.63.0)\nRequirement already satisfied: pandas>=0.24.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yahooquery) (1.2.5)\nRequirement already satisfied: lxml>=4.6.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from yahooquery) (4.8.0)\nRequirement already satisfied: requests-futures>=1.0.0 in /root/venv/lib/python3.7/site-packages (from yahooquery) (1.0.0)\nRequirement already satisfied: pytz>=2017.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas>=0.24.0->yahooquery) (2022.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\nRequirement already satisfied: numpy>=1.16.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas>=0.24.0->yahooquery) (1.21.5)\nRequirement already satisfied: requests>=1.2.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.16.0)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IB_YMoe09qVP",
    "cell_id": "00002-9d0eaf85-fcb5-491e-8185-a5520e47d6f5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d4bbbcec",
    "execution_start": 1649751497745,
    "execution_millis": 13,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 2745
   },
   "source": "#symbols = get_crypto_syms()\n#dfs = []\n#for symbol in symbols:\n#           data = yf.download(symbol,period=\"MAX\",interval=\"1d\",progress=False)\n#           if data.empty :\n#             print(\"Passing...\")\n#           else:\n#               dfs.append(data)\n#ndfs = dfs\n#dfs = []\n#for df in ndfs:\n#        if df.shape[0] > 21:\n#           dfs.append(df)\n#data = process(dfs)\n#df = pd.read_parquet(\"/content/drive/MyDrive/Colab Files/250_crypto_1d_scaled_yf.parquet\")\n#xTrain, xTest, yTrain, yTest = spliting(data)\n\ndef read_syms_from_txt():  \n  with open(\"syms.txt\",\"r\") as f:\n    lines = f.readlines()\n    f.close()\n  lst = []\n  for line in lines:\n    line = line.strip()\n    lst.append(line)\n  symbols = lst\n  return symbols\n\n\n#symbols = [\"MSFT\",\"AAPL\",\"GOOG\",\"TSLA\",\"GGPI\",\"AI\",\"AMZN\"]\n#symbols = [\"BTC-USD\",\"LTC-USD\",\"TRX-USD\",\"XRP-USD\",\"ETH-USD\",\"BNB-USD\",\"DASH-USD\",\"VET-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"SOL-USD\",\"BCH-USD\",\"FTT-USD\",\"FIL-USD\",\"XMR-USD\"]\n#symbols = [\"AAPL\",\"MSFT\",\"TSLA\",\"GOOG\"]\n#symbols = [\"BTC-USD\",\"ETH-USD\"]\n#symbols = [\"BTC-USD\"]\ndef get_crypto_syms():\n   screens = ['all_cryptocurrencies_au',\n 'all_cryptocurrencies_ca',\n 'all_cryptocurrencies_eu',\n 'all_cryptocurrencies_gb',\n 'all_cryptocurrencies_in',\n 'all_cryptocurrencies_us']\n   s = Screener()\n   symbols = []\n   for i in screens:\n      data = s.get_screeners(i, count=250)\n      dicts = data[i]['quotes']\n      syms = [d['symbol'] for d in dicts]\n      for sym in syms:\n        symbols.append(sym)\n   #print(len(symbols))\n   #pieces = 15\n   # new_arrays = np.array_split(symbols, pieces)\n   return symbols\n\ndef process(dfs): \n   fixed_dfs = []\n   for df in dfs:\n       fixed_df = []\n       df = np.array(df)\n       for i in range(20, df.shape[0]-1):\n           twenty_days_ago = i-20\n           ninteen_days_ago = i-19\n           eighteen_days_ago = i-18\n           seventeen_days_ago = i-17\n           sixteen_days_ago = i-16\n           fifteen_days_ago = i-15\n           fourteen_days_ago = i-14\n           thirteen_days_ago = i-13\n           twelve_days_ago = i-12\n           eleven_days_ago = i-11\n           ten_days_ago = i-10\n           nine_days_ago = i-9\n           eight_days_ago = i-8\n           seven_days_ago = i-7\n           six_days_ago = i-6\n           five_days_ago = i-5\n           four_days_ago = i-4\n           three_days_ago = i-3\n           two_days_ago = i - 2\n           yesterday = i - 1\n           today = i\n           tomorrow = i + 1\n           if df[tomorrow][3] > df[today][3]:\n               future = 1\n           else:\n               future = 0\n\n\n           row = [df[twenty_days_ago][3],df[ninteen_days_ago][3],df[eighteen_days_ago][3],df[seventeen_days_ago][3],\n                  df[sixteen_days_ago][3],df[fifteen_days_ago][3],df[fourteen_days_ago][3],df[thirteen_days_ago][3],\n                  df[twelve_days_ago][3],df[eleven_days_ago][3],df[ten_days_ago][3], df[nine_days_ago][3], \n                  df[eight_days_ago][3], df[seven_days_ago][3], df[six_days_ago][3], df[five_days_ago][3], \n                  df[four_days_ago][3], df[three_days_ago][3], df[two_days_ago][3], df[yesterday][3],\n                  df[today][3], future]\n\n           fixed_df.append(row)\n\n\n       arrayed_fixed_df = np.array([fixed_df])\n       two_d_fixed_df = []\n       for i in range(0, arrayed_fixed_df.shape[1]):\n          two_d_fixed_df.append(arrayed_fixed_df[0][i])\n    \n       mm = np.array(two_d_fixed_df)\n\n\n       column_names = [\"twenty_days_ago\",\"ninteen_days_ago\",\"eighteen_days_ago\",\n                       \"seventeen_days_ago\",\"sixteen_days_ago\",\"fifteen_days_ago\",\n                       \"fourteen_days_ago\",\"thirteen_days_ago\",\"twelve_days_ago\",\n                       \"eleven_days_ago\",\"ten_days_ago\", \"nine_days_ago\", \n                       \"eight_days_ago\", \"seven_days_ago\", \"six_days_ago\",\n                       \"five_days_ago\", \"four_days_ago\", \"three_days_ago\",\n                       \"two_days_ago\", \"yesterday\",\"today\", \"result\"]\n    \n       column_names_without_result = [\"twenty_days_ago\",\"ninteen_days_ago\",\"eighteen_days_ago\",\n                                      \"seventeen_days_ago\",\"sixteen_days_ago\",\"fifteen_days_ago\",\n                                      \"fourteen_days_ago\",\"thirteen_days_ago\",\"twelve_days_ago\",\n                                      \"eleven_days_ago\",   \"ten_days_ago\", \"nine_days_ago\", \n                                      \"eight_days_ago\", \"seven_days_ago\", \"six_days_ago\",\n                                      \"five_days_ago\", \"four_days_ago\", \"three_days_ago\", \n                                      \"two_days_ago\", \"yesterday\",\"today\"]\n       dff = pd.DataFrame(mm, columns=column_names)\n       scaler = MinMaxScaler()\n       result = dff[\"result\"]\n       dff = dff.drop([\"result\"],axis=1)\n       scaled = pd.DataFrame(scaler.fit_transform(dff.T).T, columns=column_names_without_result,dtype=object)\n\n       scaled[\"result\"] = result\n       \n       fixed_dfs.append(scaled)\n\n   data = fixed_dfs[0]\n   for i in range(1,len(dfs)):\n     data = pd.concat([data,fixed_dfs[i]], ignore_index = True)\n   data = data.astype(float)\n   data = data.dropna()\n   ttext = getsizeof(data)\n   #data.to_parquet(f\"{name}.parquet\")\n   return data\n   \ndef spliting(data):\n  X = data.drop([\"result\"],axis=1)\n  y = data[\"result\"]\n  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1,random_state=99)\n  print(xTrain.shape,end=\" \")\n  print(yTrain.shape)\n  print(xTest.shape,end=\" \")\n  print(yTest.shape)\n  return xTrain, xTest, yTrain, yTest",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "qvoRFiuEwlku",
    "outputId": "7d42f1a1-b4b1-4e5f-82a9-0bb97ddd706b",
    "cell_id": "00005-09e60e83-c228-4ccc-802a-4dd2ce75a4f2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5a0e57fe",
    "execution_start": 1649751520678,
    "execution_millis": 7178,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 755.375
   },
   "source": "\ndata = pd.read_parquet(\"/datasets/dff/Colab Files/250_crypto_1h_scaled_yf.parquet\")\nxTrain, xTest, yTrain, yTest = spliting(data)\n\ndata",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "(1391110, 21) (1391110,)\n(154568, 21) (154568,)\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 22,
       "row_count": 1545678,
       "columns": [
        {
         "name": "twenty_days_ago",
         "dtype": "float64"
        },
        {
         "name": "ninteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "eighteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "seventeen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "sixteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "fifteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "fourteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "thirteen_days_ago",
         "dtype": "float64"
        },
        {
         "name": "twelve_days_ago",
         "dtype": "float64"
        },
        {
         "name": "eleven_days_ago",
         "dtype": "float64"
        },
        {
         "name": "ten_days_ago",
         "dtype": "float64"
        },
        {
         "name": "nine_days_ago",
         "dtype": "float64"
        },
        {
         "name": "eight_days_ago",
         "dtype": "float64"
        },
        {
         "name": "seven_days_ago",
         "dtype": "float64"
        },
        {
         "name": "six_days_ago",
         "dtype": "float64"
        },
        {
         "name": "five_days_ago",
         "dtype": "float64"
        },
        {
         "name": "four_days_ago",
         "dtype": "float64"
        },
        {
         "name": "three_days_ago",
         "dtype": "float64"
        },
        {
         "name": "two_days_ago",
         "dtype": "float64"
        },
        {
         "name": "yesterday",
         "dtype": "float64"
        },
        {
         "name": "today",
         "dtype": "float64"
        },
        {
         "name": "result",
         "dtype": "float64"
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows": [
        {
         "twenty_days_ago": 0.20592205208421532,
         "ninteen_days_ago": 0.16969809464254482,
         "eighteen_days_ago": 0.018891385794788107,
         "seventeen_days_ago": 0,
         "sixteen_days_ago": 0.011830768648554368,
         "fifteen_days_ago": 0.06673166230859451,
         "fourteen_days_ago": 0.03273149291144861,
         "thirteen_days_ago": 0.05615335127020771,
         "twelve_days_ago": 0.07233258065737047,
         "eleven_days_ago": 0.11533062177762332,
         "ten_days_ago": 0.09003638434409922,
         "nine_days_ago": 0.1350383576406209,
         "eight_days_ago": 0.27672285005289154,
         "seven_days_ago": 0.36348662573503177,
         "six_days_ago": 0.5611658848567949,
         "five_days_ago": 0.6229832278806064,
         "four_days_ago": 0.8917984750652792,
         "three_days_ago": 0.87668068097652,
         "two_days_ago": 0.823477362955007,
         "yesterday": 1,
         "today": 0.9373014314058707,
         "result": 1,
         "_deepnote_index_column": 0
        },
        {
         "twenty_days_ago": 0.16969809464254482,
         "ninteen_days_ago": 0.018891385794788107,
         "eighteen_days_ago": 0,
         "seventeen_days_ago": 0.011830768648554368,
         "sixteen_days_ago": 0.06673166230859451,
         "fifteen_days_ago": 0.03273149291144861,
         "fourteen_days_ago": 0.05615335127020771,
         "thirteen_days_ago": 0.07233258065737047,
         "twelve_days_ago": 0.11533062177762332,
         "eleven_days_ago": 0.09003638434409922,
         "ten_days_ago": 0.1350383576406209,
         "nine_days_ago": 0.27672285005289154,
         "eight_days_ago": 0.36348662573503177,
         "seven_days_ago": 0.5611658848567949,
         "six_days_ago": 0.6229832278806064,
         "five_days_ago": 0.8917984750652792,
         "four_days_ago": 0.87668068097652,
         "three_days_ago": 0.823477362955007,
         "two_days_ago": 1,
         "yesterday": 0.9373014314058707,
         "today": 0.9603340367519735,
         "result": 0,
         "_deepnote_index_column": 1
        },
        {
         "twenty_days_ago": 0.018891385794788107,
         "ninteen_days_ago": 0,
         "eighteen_days_ago": 0.011830768648554368,
         "seventeen_days_ago": 0.06673166230859451,
         "sixteen_days_ago": 0.03273149291144861,
         "fifteen_days_ago": 0.05615335127020771,
         "fourteen_days_ago": 0.07233258065737047,
         "thirteen_days_ago": 0.11533062177762332,
         "twelve_days_ago": 0.09003638434409922,
         "eleven_days_ago": 0.1350383576406209,
         "ten_days_ago": 0.27672285005289154,
         "nine_days_ago": 0.36348662573503177,
         "eight_days_ago": 0.5611658848567949,
         "seven_days_ago": 0.6229832278806064,
         "six_days_ago": 0.8917984750652792,
         "five_days_ago": 0.87668068097652,
         "four_days_ago": 0.823477362955007,
         "three_days_ago": 1,
         "two_days_ago": 0.9373014314058707,
         "yesterday": 0.9603340367519735,
         "today": 0.7017907440679458,
         "result": 0,
         "_deepnote_index_column": 2
        },
        {
         "twenty_days_ago": 0.21725177875202206,
         "ninteen_days_ago": 0.22651229186767452,
         "eighteen_days_ago": 0.26948586872499547,
         "seventeen_days_ago": 0.24287229660724918,
         "sixteen_days_ago": 0.26120571457589037,
         "fifteen_days_ago": 0.27386997759985476,
         "fourteen_days_ago": 0.30752661780388024,
         "thirteen_days_ago": 0.28772759844496676,
         "twelve_days_ago": 0.3229528129954673,
         "eleven_days_ago": 0.43385609740959197,
         "ten_days_ago": 0.501770288493546,
         "nine_days_ago": 0.6565033769487272,
         "eight_days_ago": 0.7048907922428889,
         "seven_days_ago": 0.9153054488210302,
         "six_days_ago": 0.9034720223888577,
         "five_days_ago": 0.861827219843029,
         "four_days_ago": 1,
         "three_days_ago": 0.9509228069581503,
         "two_days_ago": 0.9689515378235178,
         "yesterday": 0.7665772353595024,
         "today": 0,
         "result": 0,
         "_deepnote_index_column": 3
        },
        {
         "twenty_days_ago": 0.34323767546591455,
         "ninteen_days_ago": 0.3797262013127032,
         "eighteen_days_ago": 0.3571288267139394,
         "seventeen_days_ago": 0.3726955876012106,
         "sixteen_days_ago": 0.3834487136492122,
         "fifteen_days_ago": 0.412026301921145,
         "fourteen_days_ago": 0.3952151104297421,
         "thirteen_days_ago": 0.42512456283236943,
         "twelve_days_ago": 0.5192916686628664,
         "eleven_days_ago": 0.5769570737316165,
         "ten_days_ago": 0.7083397211708906,
         "nine_days_ago": 0.7494250946198449,
         "eight_days_ago": 0.9280865232597151,
         "seven_days_ago": 0.918038854021944,
         "six_days_ago": 0.8826785799837111,
         "five_days_ago": 1,
         "four_days_ago": 0.9583289416950151,
         "three_days_ago": 0.9736369951612147,
         "two_days_ago": 0.8018025679106984,
         "yesterday": 0.15090787141283002,
         "today": 0,
         "result": 1,
         "_deepnote_index_column": 4
        },
        {
         "twenty_days_ago": 0.3797262013127032,
         "ninteen_days_ago": 0.3571288267139394,
         "eighteen_days_ago": 0.3726955876012106,
         "seventeen_days_ago": 0.3834487136492122,
         "sixteen_days_ago": 0.412026301921145,
         "fifteen_days_ago": 0.3952151104297421,
         "fourteen_days_ago": 0.42512456283236943,
         "thirteen_days_ago": 0.5192916686628664,
         "twelve_days_ago": 0.5769570737316165,
         "eleven_days_ago": 0.7083397211708906,
         "ten_days_ago": 0.7494250946198449,
         "nine_days_ago": 0.9280865232597151,
         "eight_days_ago": 0.918038854021944,
         "seven_days_ago": 0.8826785799837111,
         "six_days_ago": 1,
         "five_days_ago": 0.9583289416950151,
         "four_days_ago": 0.9736369951612147,
         "three_days_ago": 0.8018025679106984,
         "two_days_ago": 0.15090787141283002,
         "yesterday": 0,
         "today": 0.08119221003209987,
         "result": 0,
         "_deepnote_index_column": 5
        },
        {
         "twenty_days_ago": 0.3571288267139394,
         "ninteen_days_ago": 0.3726955876012106,
         "eighteen_days_ago": 0.3834487136492122,
         "seventeen_days_ago": 0.412026301921145,
         "sixteen_days_ago": 0.3952151104297421,
         "fifteen_days_ago": 0.42512456283236943,
         "fourteen_days_ago": 0.5192916686628664,
         "thirteen_days_ago": 0.5769570737316165,
         "twelve_days_ago": 0.7083397211708906,
         "eleven_days_ago": 0.7494250946198449,
         "ten_days_ago": 0.9280865232597151,
         "nine_days_ago": 0.918038854021944,
         "eight_days_ago": 0.8826785799837111,
         "seven_days_ago": 1,
         "six_days_ago": 0.9583289416950151,
         "five_days_ago": 0.9736369951612147,
         "four_days_ago": 0.8018025679106984,
         "three_days_ago": 0.15090787141283002,
         "two_days_ago": 0,
         "yesterday": 0.08119221003209987,
         "today": 0.012670675034733847,
         "result": 1,
         "_deepnote_index_column": 6
        },
        {
         "twenty_days_ago": 0.3726955876012106,
         "ninteen_days_ago": 0.3834487136492122,
         "eighteen_days_ago": 0.412026301921145,
         "seventeen_days_ago": 0.3952151104297421,
         "sixteen_days_ago": 0.42512456283236943,
         "fifteen_days_ago": 0.5192916686628664,
         "fourteen_days_ago": 0.5769570737316165,
         "thirteen_days_ago": 0.7083397211708906,
         "twelve_days_ago": 0.7494250946198449,
         "eleven_days_ago": 0.9280865232597151,
         "ten_days_ago": 0.918038854021944,
         "nine_days_ago": 0.8826785799837111,
         "eight_days_ago": 1,
         "seven_days_ago": 0.9583289416950151,
         "six_days_ago": 0.9736369951612147,
         "five_days_ago": 0.8018025679106984,
         "four_days_ago": 0.15090787141283002,
         "three_days_ago": 0,
         "two_days_ago": 0.08119221003209987,
         "yesterday": 0.012670675034733847,
         "today": 0.04547381785081228,
         "result": 1,
         "_deepnote_index_column": 7
        },
        {
         "twenty_days_ago": 0.3834487136492122,
         "ninteen_days_ago": 0.412026301921145,
         "eighteen_days_ago": 0.3952151104297421,
         "seventeen_days_ago": 0.42512456283236943,
         "sixteen_days_ago": 0.5192916686628664,
         "fifteen_days_ago": 0.5769570737316165,
         "fourteen_days_ago": 0.7083397211708906,
         "thirteen_days_ago": 0.7494250946198449,
         "twelve_days_ago": 0.9280865232597151,
         "eleven_days_ago": 0.918038854021944,
         "ten_days_ago": 0.8826785799837111,
         "nine_days_ago": 1,
         "eight_days_ago": 0.9583289416950151,
         "seven_days_ago": 0.9736369951612147,
         "six_days_ago": 0.8018025679106984,
         "five_days_ago": 0.15090787141283002,
         "four_days_ago": 0,
         "three_days_ago": 0.08119221003209987,
         "two_days_ago": 0.012670675034733847,
         "yesterday": 0.04547381785081228,
         "today": 0.051482776792987295,
         "result": 1,
         "_deepnote_index_column": 8
        },
        {
         "twenty_days_ago": 0.412026301921145,
         "ninteen_days_ago": 0.3952151104297421,
         "eighteen_days_ago": 0.42512456283236943,
         "seventeen_days_ago": 0.5192916686628664,
         "sixteen_days_ago": 0.5769570737316165,
         "fifteen_days_ago": 0.7083397211708906,
         "fourteen_days_ago": 0.7494250946198449,
         "thirteen_days_ago": 0.9280865232597151,
         "twelve_days_ago": 0.918038854021944,
         "eleven_days_ago": 0.8826785799837111,
         "ten_days_ago": 1,
         "nine_days_ago": 0.9583289416950151,
         "eight_days_ago": 0.9736369951612147,
         "seven_days_ago": 0.8018025679106984,
         "six_days_ago": 0.15090787141283002,
         "five_days_ago": 0,
         "four_days_ago": 0.08119221003209987,
         "three_days_ago": 0.012670675034733847,
         "two_days_ago": 0.04547381785081228,
         "yesterday": 0.051482776792987295,
         "today": 0.11073635797441739,
         "result": 0,
         "_deepnote_index_column": 9
        }
       ]
      },
      "text/plain": "         twenty_days_ago  ninteen_days_ago  eighteen_days_ago  \\\n0               0.205922          0.169698           0.018891   \n1               0.169698          0.018891           0.000000   \n2               0.018891          0.000000           0.011831   \n3               0.217252          0.226512           0.269486   \n4               0.343238          0.379726           0.357129   \n...                  ...               ...                ...   \n1545673         0.644193          0.609480           0.705308   \n1545674         0.687264          0.764006           0.779553   \n1545675         0.795713          0.809172           0.839616   \n1545676         0.820169          0.848858           0.947267   \n1545677         0.848858          0.947267           0.973057   \n\n         seventeen_days_ago  sixteen_days_ago  fifteen_days_ago  \\\n0                  0.000000          0.011831          0.066732   \n1                  0.011831          0.066732          0.032731   \n2                  0.066732          0.032731          0.056153   \n3                  0.242872          0.261206          0.273870   \n4                  0.372696          0.383449          0.412026   \n...                     ...               ...               ...   \n1545673            0.724723          0.768640          0.919279   \n1545674            0.814723          0.935357          0.966972   \n1545675            0.944042          0.971410          1.000000   \n1545676            0.973057          1.000000          0.968528   \n1545677            1.000000          0.968528          0.947375   \n\n         fourteen_days_ago  thirteen_days_ago  twelve_days_ago  \\\n0                 0.032731           0.056153         0.072333   \n1                 0.056153           0.072333         0.115331   \n2                 0.072333           0.115331         0.090036   \n3                 0.307527           0.287728         0.322953   \n4                 0.395215           0.425125         0.519292   \n...                    ...                ...              ...   \n1545673           0.958757           1.000000         0.951825   \n1545674           1.000000           0.961420         0.935489   \n1545675           0.966604           0.944157         0.744705   \n1545676           0.947375           0.759416         0.751960   \n1545677           0.759416           0.751960         0.646856   \n\n         eleven_days_ago  ...  eight_days_ago  seven_days_ago  six_days_ago  \\\n0               0.115331  ...        0.276723        0.363487      0.561166   \n1               0.090036  ...        0.363487        0.561166      0.622983   \n2               0.135038  ...        0.561166        0.622983      0.891798   \n3               0.433856  ...        0.704891        0.915305      0.903472   \n4               0.576957  ...        0.928087        0.918039      0.882679   \n...                  ...  ...             ...             ...           ...   \n1545673         0.919444  ...        0.459425        0.371224      0.231671   \n1545674         0.705080  ...        0.496465        0.384708      0.439426   \n1545675         0.736792  ...        0.467377        0.514742      0.480390   \n1545676         0.646856  ...        0.542706        0.510334      0.561642   \n1545677         0.589236  ...        0.510334        0.561642      0.488400   \n\n         five_days_ago  four_days_ago  three_days_ago  two_days_ago  \\\n0             0.622983       0.891798        0.876681      0.823477   \n1             0.891798       0.876681        0.823477      1.000000   \n2             0.876681       0.823477        1.000000      0.937301   \n3             0.861827       1.000000        0.950923      0.968952   \n4             1.000000       0.958329        0.973637      0.801803   \n...                ...            ...             ...           ...   \n1545673       0.299998       0.250443        0.328983      0.216869   \n1545674       0.399742       0.462638        0.372854      0.379069   \n1545675       0.534836       0.457115        0.462494      0.306777   \n1545676       0.488400       0.493469        0.346725      0.184240   \n1545677       0.493469       0.346725        0.184240      0.057627   \n\n         yesterday     today  result  \n0         1.000000  0.937301     1.0  \n1         0.937301  0.960334     0.0  \n2         0.960334  0.701791     0.0  \n3         0.766577  0.000000     0.0  \n4         0.150908  0.000000     1.0  \n...            ...       ...     ...  \n1545673   0.224628  0.000000     0.0  \n1545674   0.199182  0.000000     0.0  \n1545675   0.134356  0.000000     0.0  \n1545676   0.057627  0.000000     1.0  \n1545677   0.000000  0.062703     1.0  \n\n[1545678 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twenty_days_ago</th>\n      <th>ninteen_days_ago</th>\n      <th>eighteen_days_ago</th>\n      <th>seventeen_days_ago</th>\n      <th>sixteen_days_ago</th>\n      <th>fifteen_days_ago</th>\n      <th>fourteen_days_ago</th>\n      <th>thirteen_days_ago</th>\n      <th>twelve_days_ago</th>\n      <th>eleven_days_ago</th>\n      <th>...</th>\n      <th>eight_days_ago</th>\n      <th>seven_days_ago</th>\n      <th>six_days_ago</th>\n      <th>five_days_ago</th>\n      <th>four_days_ago</th>\n      <th>three_days_ago</th>\n      <th>two_days_ago</th>\n      <th>yesterday</th>\n      <th>today</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.205922</td>\n      <td>0.169698</td>\n      <td>0.018891</td>\n      <td>0.000000</td>\n      <td>0.011831</td>\n      <td>0.066732</td>\n      <td>0.032731</td>\n      <td>0.056153</td>\n      <td>0.072333</td>\n      <td>0.115331</td>\n      <td>...</td>\n      <td>0.276723</td>\n      <td>0.363487</td>\n      <td>0.561166</td>\n      <td>0.622983</td>\n      <td>0.891798</td>\n      <td>0.876681</td>\n      <td>0.823477</td>\n      <td>1.000000</td>\n      <td>0.937301</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.169698</td>\n      <td>0.018891</td>\n      <td>0.000000</td>\n      <td>0.011831</td>\n      <td>0.066732</td>\n      <td>0.032731</td>\n      <td>0.056153</td>\n      <td>0.072333</td>\n      <td>0.115331</td>\n      <td>0.090036</td>\n      <td>...</td>\n      <td>0.363487</td>\n      <td>0.561166</td>\n      <td>0.622983</td>\n      <td>0.891798</td>\n      <td>0.876681</td>\n      <td>0.823477</td>\n      <td>1.000000</td>\n      <td>0.937301</td>\n      <td>0.960334</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.018891</td>\n      <td>0.000000</td>\n      <td>0.011831</td>\n      <td>0.066732</td>\n      <td>0.032731</td>\n      <td>0.056153</td>\n      <td>0.072333</td>\n      <td>0.115331</td>\n      <td>0.090036</td>\n      <td>0.135038</td>\n      <td>...</td>\n      <td>0.561166</td>\n      <td>0.622983</td>\n      <td>0.891798</td>\n      <td>0.876681</td>\n      <td>0.823477</td>\n      <td>1.000000</td>\n      <td>0.937301</td>\n      <td>0.960334</td>\n      <td>0.701791</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.217252</td>\n      <td>0.226512</td>\n      <td>0.269486</td>\n      <td>0.242872</td>\n      <td>0.261206</td>\n      <td>0.273870</td>\n      <td>0.307527</td>\n      <td>0.287728</td>\n      <td>0.322953</td>\n      <td>0.433856</td>\n      <td>...</td>\n      <td>0.704891</td>\n      <td>0.915305</td>\n      <td>0.903472</td>\n      <td>0.861827</td>\n      <td>1.000000</td>\n      <td>0.950923</td>\n      <td>0.968952</td>\n      <td>0.766577</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.343238</td>\n      <td>0.379726</td>\n      <td>0.357129</td>\n      <td>0.372696</td>\n      <td>0.383449</td>\n      <td>0.412026</td>\n      <td>0.395215</td>\n      <td>0.425125</td>\n      <td>0.519292</td>\n      <td>0.576957</td>\n      <td>...</td>\n      <td>0.928087</td>\n      <td>0.918039</td>\n      <td>0.882679</td>\n      <td>1.000000</td>\n      <td>0.958329</td>\n      <td>0.973637</td>\n      <td>0.801803</td>\n      <td>0.150908</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1545673</th>\n      <td>0.644193</td>\n      <td>0.609480</td>\n      <td>0.705308</td>\n      <td>0.724723</td>\n      <td>0.768640</td>\n      <td>0.919279</td>\n      <td>0.958757</td>\n      <td>1.000000</td>\n      <td>0.951825</td>\n      <td>0.919444</td>\n      <td>...</td>\n      <td>0.459425</td>\n      <td>0.371224</td>\n      <td>0.231671</td>\n      <td>0.299998</td>\n      <td>0.250443</td>\n      <td>0.328983</td>\n      <td>0.216869</td>\n      <td>0.224628</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1545674</th>\n      <td>0.687264</td>\n      <td>0.764006</td>\n      <td>0.779553</td>\n      <td>0.814723</td>\n      <td>0.935357</td>\n      <td>0.966972</td>\n      <td>1.000000</td>\n      <td>0.961420</td>\n      <td>0.935489</td>\n      <td>0.705080</td>\n      <td>...</td>\n      <td>0.496465</td>\n      <td>0.384708</td>\n      <td>0.439426</td>\n      <td>0.399742</td>\n      <td>0.462638</td>\n      <td>0.372854</td>\n      <td>0.379069</td>\n      <td>0.199182</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1545675</th>\n      <td>0.795713</td>\n      <td>0.809172</td>\n      <td>0.839616</td>\n      <td>0.944042</td>\n      <td>0.971410</td>\n      <td>1.000000</td>\n      <td>0.966604</td>\n      <td>0.944157</td>\n      <td>0.744705</td>\n      <td>0.736792</td>\n      <td>...</td>\n      <td>0.467377</td>\n      <td>0.514742</td>\n      <td>0.480390</td>\n      <td>0.534836</td>\n      <td>0.457115</td>\n      <td>0.462494</td>\n      <td>0.306777</td>\n      <td>0.134356</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1545676</th>\n      <td>0.820169</td>\n      <td>0.848858</td>\n      <td>0.947267</td>\n      <td>0.973057</td>\n      <td>1.000000</td>\n      <td>0.968528</td>\n      <td>0.947375</td>\n      <td>0.759416</td>\n      <td>0.751960</td>\n      <td>0.646856</td>\n      <td>...</td>\n      <td>0.542706</td>\n      <td>0.510334</td>\n      <td>0.561642</td>\n      <td>0.488400</td>\n      <td>0.493469</td>\n      <td>0.346725</td>\n      <td>0.184240</td>\n      <td>0.057627</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1545677</th>\n      <td>0.848858</td>\n      <td>0.947267</td>\n      <td>0.973057</td>\n      <td>1.000000</td>\n      <td>0.968528</td>\n      <td>0.947375</td>\n      <td>0.759416</td>\n      <td>0.751960</td>\n      <td>0.646856</td>\n      <td>0.589236</td>\n      <td>...</td>\n      <td>0.510334</td>\n      <td>0.561642</td>\n      <td>0.488400</td>\n      <td>0.493469</td>\n      <td>0.346725</td>\n      <td>0.184240</td>\n      <td>0.057627</td>\n      <td>0.000000</td>\n      <td>0.062703</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1545678 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1rI1oRc9VRwO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "05f49a84-cc69-4162-8b08-b00c818b7cd8",
    "cell_id": "00006-cfb01540-58ba-457e-81a2-0bea926ee64e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c6d1a559",
    "execution_start": 1649751682038,
    "execution_millis": 708,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 597.1875
   },
   "source": "model = Sequential()\n\nmodel.add(Dense(3000, activation='relu', kernel_initializer='he_normal', input_shape=(xTrain.shape[1],)))\nmodel.add(Dense(2000, activation='relu', kernel_initializer='he_normal'))\nmodel.add(Dense(1000, activation='relu', kernel_initializer='he_normal'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\nmodel.summary()",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_17 (Dense)            (None, 3000)              66000     \n                                                                 \n dense_18 (Dense)            (None, 2000)              6002000   \n                                                                 \n dense_19 (Dense)            (None, 1000)              2001000   \n                                                                 \n dense_20 (Dense)            (None, 1)                 1001      \n                                                                 \n=================================================================\nTotal params: 8,070,001\nTrainable params: 8,070,001\nNon-trainable params: 0\n_________________________________________________________________\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JDTaW4WnX330",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3caf285b-9ef9-49f2-854c-df06079bb594",
    "cell_id": "00007-f6100b92-d1d7-4592-850e-40124fb50258",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "686fafb9",
    "execution_start": 1649751686362,
    "execution_millis": 11814,
    "owner_user_id": "85c39880-66d6-4580-b95e-fedaac7f2e56",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 132.375
   },
   "source": "model.fit(xTrain,yTrain,epochs=15,batch_size=16,validation_data=(xTest,yTest))",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/15\n 5654/86945 [>.............................] - ETA: 1:47:07 - loss: 0.7003 - accuracy: 0.5020",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "46M8IzrdKgf8",
    "outputId": "316938e6-4d09-4ffd-be95-a33e2c1c04f3",
    "cell_id": "00009-fc52f0aa-6496-492e-acff-97e2b0fbda3d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 576.1875
   },
   "source": "clf = RandomForestClassifier(n_estimators=100)\nclf.fit(xTrain,yTrain)\nprint(f\"Random Forest :  {clf.score(xTest,yTest)}\")\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(xTrain, yTrain)\nprint(f\"Logistic Regression: {logisticRegr.score(xTest, yTest)}\")\nnc = NearestCentroid()\nnc.fit(xTrain,yTrain)\nprint(f\"Nearest Centroid: {nc.score(xTest,yTest)}\")\ngnb = GaussianNB()\ngnb.fit(xTrain, yTrain)\nprint(f\"GaussianNB: {gnb.score(xTest,yTest)}\")\nclf2 = KNeighborsClassifier(n_neighbors=2)\nclf2.fit(xTrain, yTrain)\nprint(f\"K-Neighbors: {clf2.score(xTest,yTest)}\")\ntree = DecisionTreeClassifier()\ntree.fit(xTrain, yTrain)\nprint(f\"Decision Tree: {tree.score(xTest,yTest)}\")\ngb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n   max_depth=1, random_state=0).fit(xTrain, yTrain)\ngb.fit(xTrain,yTrain)\nprint(f\"Gradient Boost: {gb.score(xTest, yTest)}\")\nsvm = SVC()\nsvm.fit(xTrain,yTrain)\nprint(f\"SVM: {svm.score(xTest,yTest)}\")",
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7dcc7ed1ff41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Random Forest :  {clf.score(xTest,yTest)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogisticRegr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c111ad63-b103-4e84-b06d-c12ff65e6887' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Binary_v2.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyMNQ3e5cXA93gKQJC6hI4Iu",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "deepnote_notebook_id": "6df2983b-37ac-419c-9d20-d265269b60f1",
  "deepnote": {},
  "deepnote_execution_queue": [
   {
    "cellId": "00007-f6100b92-d1d7-4592-850e-40124fb50258",
    "sessionId": "e563f883-fa06-4c14-8be1-4cb4fb85dad6",
    "msgId": "1b104e87-4ddb-4722-ba32-feb9b6cebcd8"
   }
  ]
 }
}
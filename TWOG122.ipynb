{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "!pip install yahooquery\n",
        "!pip install tvdatafeed\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from yahooquery import Screener\n",
        "import yfinance as yf   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import random \n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import multiprocessing\n",
        "import time\n",
        "import glob"
      ],
      "metadata": {
        "id": "BqIra2YIBJsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a283f746-3438-43bf-dea6-b06af572b506"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "Collecting yahooquery\n",
            "  Downloading yahooquery-2.2.15-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.64.0)\n",
            "Collecting requests-futures>=1.0.0\n",
            "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (4.8.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yahooquery) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yahooquery) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yahooquery) (1.15.0)\n",
            "Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures>=1.0.0->yahooquery) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures>=1.0.0->yahooquery) (1.24.3)\n",
            "Installing collected packages: requests-futures, yahooquery\n",
            "Successfully installed requests-futures-1.0.0 yahooquery-2.2.15\n",
            "Collecting tvdatafeed\n",
            "  Downloading tvdatafeed-1.2.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.5-py3-none-any.whl (979 kB)\n",
            "\u001b[K     |████████████████████████████████| 979 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (57.4.0)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.3.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tvdatafeed) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tvdatafeed) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->tvdatafeed) (1.15.0)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 64.9 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->tvdatafeed) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2021.10.8)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->tvdatafeed) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium->tvdatafeed) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, websocket-client, selenium, chromedriver-autoinstaller, tvdatafeed\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 chromedriver-autoinstaller-0.3.1 cryptography-37.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.5 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 tvdatafeed-1.2.1 urllib3-1.26.9 websocket-client-1.3.2 wsproto-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_bad_files():\n",
        "  for file in os.listdir(\"/content/data/\"):\n",
        "     data = pd.read_csv(f\"/content/data/{file}\")\n",
        "     if data.shape[0] <= 30:\n",
        "       os.remove(f\"/content/data/{file}\")\n",
        "def get_nasq_syms():\n",
        "  with open(\"watchlist_NASDAQ.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  line = lines[0].split(\",\")\n",
        "  symbols = []\n",
        "  for l in line:\n",
        "    x = l.split(\":\")\n",
        "    symbols.append(x[1])\n",
        "  return symbols\n",
        "def download_data_p(tv,sym):\n",
        "    data =tv.get_hist(sym,exchange=\"binance\", interval=Interval.in_weekly, n_bars=50000)\n",
        "    if data.empty:\n",
        "      pass\n",
        "    else:\n",
        "         try:\n",
        "           if np.array(data).shape[0] > 15:\n",
        "             data.to_csv(f\"/content/data/{sym}.csv\")\n",
        "         except:\n",
        "            pass\n",
        "def download_data(symbols):\n",
        "  work_with_dir()\n",
        "  tv = TvDatafeed()\n",
        "  for sym in symbols:\n",
        "    print(f'{symbols.index(sym)+1}/{len(symbols)} ',end=\" \")\n",
        "    p = multiprocessing.Process(target=download_data_p, name=\"dd\", args=(tv,sym,))\n",
        "    p.start()\n",
        "    time.sleep(2)\n",
        "    p.terminate()\n",
        "    p.join()\n",
        "  remove_bad_files()"
      ],
      "metadata": {
        "id": "Cku-whunBURi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"bsymbols.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "nl = []\n",
        "for line in lines:\n",
        "  nl.append(line.strip())"
      ],
      "metadata": {
        "id": "q1JQGtGtK7A8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_data(nl)\n",
        "#download_data(get_nasq_syms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZHam_kdREbf",
        "outputId": "abc7d18a-4af5-4ba8-c960-12d07fb0bf0b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Folder Removed\n",
            "1/1428  2/1428  3/1428  4/1428  5/1428  6/1428  7/1428  8/1428  9/1428  10/1428  11/1428  12/1428  13/1428  14/1428  15/1428  16/1428  17/1428  18/1428  19/1428  20/1428  21/1428  22/1428  23/1428  24/1428  25/1428  26/1428  27/1428  28/1428  29/1428  30/1428  31/1428  32/1428  33/1428  34/1428  35/1428  36/1428  37/1428  38/1428  39/1428  40/1428  41/1428  42/1428  43/1428  44/1428  45/1428  46/1428  47/1428  48/1428  49/1428  50/1428  51/1428  52/1428  53/1428  54/1428  55/1428  56/1428  57/1428  58/1428  59/1428  60/1428  61/1428  62/1428  63/1428  64/1428  65/1428  66/1428  67/1428  68/1428  69/1428  70/1428  71/1428  72/1428  73/1428  74/1428  75/1428  76/1428  77/1428  78/1428  79/1428  80/1428  81/1428  82/1428  83/1428  84/1428  85/1428  86/1428  87/1428  88/1428  89/1428  90/1428  91/1428  92/1428  93/1428  94/1428  95/1428  96/1428  97/1428  98/1428  99/1428  100/1428  101/1428  102/1428  103/1428  104/1428  105/1428  106/1428  107/1428  108/1428  109/1428  110/1428  111/1428  112/1428  113/1428  114/1428  115/1428  116/1428  117/1428  118/1428  119/1428  120/1428  121/1428  122/1428  123/1428  124/1428  125/1428  126/1428  127/1428  128/1428  129/1428  130/1428  131/1428  132/1428  133/1428  134/1428  135/1428  136/1428  137/1428  138/1428  139/1428  140/1428  141/1428  142/1428  143/1428  144/1428  145/1428  146/1428  147/1428  148/1428  149/1428  150/1428  151/1428  152/1428  153/1428  154/1428  155/1428  156/1428  157/1428  158/1428  159/1428  160/1428  161/1428  162/1428  163/1428  164/1428  165/1428  166/1428  167/1428  168/1428  169/1428  170/1428  171/1428  172/1428  173/1428  174/1428  175/1428  176/1428  177/1428  178/1428  179/1428  180/1428  181/1428  182/1428  183/1428  184/1428  185/1428  186/1428  187/1428  188/1428  189/1428  190/1428  191/1428  192/1428  193/1428  194/1428  195/1428  196/1428  197/1428  198/1428  199/1428  200/1428  201/1428  202/1428  203/1428  204/1428  205/1428  206/1428  207/1428  208/1428  209/1428  210/1428  211/1428  212/1428  213/1428  214/1428  215/1428  216/1428  217/1428  218/1428  219/1428  220/1428  221/1428  222/1428  223/1428  224/1428  225/1428  226/1428  227/1428  228/1428  229/1428  230/1428  231/1428  232/1428  233/1428  234/1428  235/1428  236/1428  237/1428  238/1428  239/1428  240/1428  241/1428  242/1428  243/1428  244/1428  245/1428  246/1428  247/1428  248/1428  249/1428  250/1428  251/1428  252/1428  253/1428  254/1428  255/1428  256/1428  257/1428  258/1428  259/1428  260/1428  261/1428  262/1428  263/1428  264/1428  265/1428  266/1428  267/1428  268/1428  269/1428  270/1428  271/1428  272/1428  273/1428  274/1428  275/1428  276/1428  277/1428  278/1428  279/1428  280/1428  281/1428  282/1428  283/1428  284/1428  285/1428  286/1428  287/1428  288/1428  289/1428  290/1428  291/1428  292/1428  293/1428  294/1428  295/1428  296/1428  297/1428  298/1428  299/1428  300/1428  301/1428  302/1428  303/1428  304/1428  305/1428  306/1428  307/1428  308/1428  309/1428  310/1428  311/1428  312/1428  313/1428  314/1428  315/1428  316/1428  317/1428  318/1428  319/1428  320/1428  321/1428  322/1428  323/1428  324/1428  325/1428  326/1428  327/1428  328/1428  329/1428  330/1428  331/1428  332/1428  333/1428  334/1428  335/1428  336/1428  337/1428  338/1428  339/1428  340/1428  341/1428  342/1428  343/1428  344/1428  345/1428  346/1428  347/1428  348/1428  349/1428  350/1428  351/1428  352/1428  353/1428  354/1428  355/1428  356/1428  357/1428  358/1428  359/1428  360/1428  361/1428  362/1428  363/1428  364/1428  365/1428  366/1428  367/1428  368/1428  369/1428  370/1428  371/1428  372/1428  373/1428  374/1428  375/1428  376/1428  377/1428  378/1428  379/1428  380/1428  381/1428  382/1428  383/1428  384/1428  385/1428  386/1428  387/1428  388/1428  389/1428  390/1428  391/1428  392/1428  393/1428  394/1428  395/1428  396/1428  397/1428  398/1428  399/1428  400/1428  401/1428  402/1428  403/1428  404/1428  405/1428  406/1428  407/1428  408/1428  409/1428  410/1428  411/1428  412/1428  413/1428  414/1428  415/1428  416/1428  417/1428  418/1428  419/1428  420/1428  421/1428  422/1428  423/1428  424/1428  425/1428  426/1428  427/1428  428/1428  429/1428  430/1428  431/1428  432/1428  433/1428  434/1428  435/1428  436/1428  437/1428  438/1428  439/1428  440/1428  441/1428  442/1428  443/1428  444/1428  445/1428  446/1428  447/1428  448/1428  449/1428  450/1428  451/1428  452/1428  453/1428  454/1428  455/1428  456/1428  457/1428  458/1428  459/1428  460/1428  461/1428  462/1428  463/1428  464/1428  465/1428  466/1428  467/1428  468/1428  469/1428  470/1428  471/1428  472/1428  473/1428  474/1428  475/1428  476/1428  477/1428  478/1428  479/1428  480/1428  481/1428  482/1428  483/1428  484/1428  485/1428  486/1428  487/1428  488/1428  489/1428  490/1428  491/1428  492/1428  493/1428  494/1428  495/1428  496/1428  497/1428  498/1428  499/1428  500/1428  501/1428  502/1428  503/1428  504/1428  505/1428  506/1428  507/1428  508/1428  509/1428  510/1428  511/1428  512/1428  513/1428  514/1428  515/1428  516/1428  517/1428  518/1428  519/1428  520/1428  521/1428  522/1428  523/1428  524/1428  525/1428  526/1428  527/1428  528/1428  529/1428  530/1428  531/1428  532/1428  533/1428  534/1428  535/1428  536/1428  537/1428  538/1428  539/1428  540/1428  541/1428  542/1428  543/1428  544/1428  545/1428  546/1428  547/1428  548/1428  549/1428  550/1428  551/1428  552/1428  553/1428  554/1428  555/1428  556/1428  557/1428  558/1428  559/1428  560/1428  561/1428  562/1428  563/1428  564/1428  565/1428  566/1428  567/1428  568/1428  569/1428  570/1428  571/1428  572/1428  573/1428  574/1428  575/1428  576/1428  577/1428  578/1428  579/1428  580/1428  581/1428  582/1428  583/1428  584/1428  585/1428  586/1428  587/1428  588/1428  589/1428  590/1428  591/1428  592/1428  593/1428  594/1428  595/1428  596/1428  597/1428  598/1428  599/1428  600/1428  601/1428  602/1428  603/1428  604/1428  605/1428  606/1428  607/1428  608/1428  609/1428  610/1428  611/1428  612/1428  613/1428  614/1428  615/1428  616/1428  617/1428  618/1428  619/1428  620/1428  621/1428  622/1428  623/1428  624/1428  625/1428  626/1428  627/1428  628/1428  629/1428  630/1428  631/1428  632/1428  633/1428  634/1428  635/1428  636/1428  637/1428  638/1428  639/1428  640/1428  641/1428  642/1428  643/1428  644/1428  645/1428  646/1428  647/1428  648/1428  649/1428  650/1428  651/1428  652/1428  653/1428  654/1428  655/1428  656/1428  657/1428  658/1428  659/1428  660/1428  661/1428  662/1428  663/1428  664/1428  665/1428  666/1428  667/1428  668/1428  669/1428  670/1428  671/1428  672/1428  673/1428  674/1428  675/1428  676/1428  677/1428  678/1428  679/1428  680/1428  681/1428  682/1428  683/1428  684/1428  685/1428  686/1428  687/1428  688/1428  689/1428  690/1428  691/1428  692/1428  693/1428  694/1428  695/1428  696/1428  697/1428  698/1428  699/1428  700/1428  701/1428  702/1428  703/1428  704/1428  705/1428  706/1428  707/1428  708/1428  709/1428  710/1428  711/1428  712/1428  713/1428  714/1428  715/1428  716/1428  717/1428  718/1428  719/1428  720/1428  721/1428  722/1428  723/1428  724/1428  725/1428  726/1428  727/1428  728/1428  729/1428  730/1428  731/1428  732/1428  733/1428  734/1428  735/1428  736/1428  737/1428  738/1428  739/1428  740/1428  741/1428  742/1428  743/1428  744/1428  745/1428  746/1428  747/1428  748/1428  749/1428  750/1428  751/1428  752/1428  753/1428  754/1428  755/1428  756/1428  757/1428  758/1428  759/1428  760/1428  761/1428  762/1428  763/1428  764/1428  765/1428  766/1428  767/1428  768/1428  769/1428  770/1428  771/1428  772/1428  773/1428  774/1428  775/1428  776/1428  777/1428  778/1428  779/1428  780/1428  781/1428  782/1428  783/1428  784/1428  785/1428  786/1428  787/1428  788/1428  789/1428  790/1428  791/1428  792/1428  793/1428  794/1428  795/1428  796/1428  797/1428  798/1428  799/1428  800/1428  801/1428  802/1428  803/1428  804/1428  805/1428  806/1428  807/1428  808/1428  809/1428  810/1428  811/1428  812/1428  813/1428  814/1428  815/1428  816/1428  817/1428  818/1428  819/1428  820/1428  821/1428  822/1428  823/1428  824/1428  825/1428  826/1428  827/1428  828/1428  829/1428  830/1428  831/1428  832/1428  833/1428  834/1428  835/1428  836/1428  837/1428  838/1428  839/1428  840/1428  841/1428  842/1428  843/1428  844/1428  845/1428  846/1428  847/1428  848/1428  849/1428  850/1428  851/1428  852/1428  853/1428  854/1428  855/1428  856/1428  857/1428  858/1428  859/1428  860/1428  861/1428  862/1428  863/1428  864/1428  865/1428  866/1428  867/1428  868/1428  869/1428  870/1428  871/1428  872/1428  873/1428  874/1428  875/1428  876/1428  877/1428  878/1428  879/1428  880/1428  881/1428  882/1428  883/1428  884/1428  885/1428  886/1428  887/1428  888/1428  889/1428  890/1428  891/1428  892/1428  893/1428  894/1428  895/1428  896/1428  897/1428  898/1428  899/1428  900/1428  901/1428  902/1428  903/1428  904/1428  905/1428  906/1428  907/1428  908/1428  909/1428  910/1428  911/1428  912/1428  913/1428  914/1428  915/1428  916/1428  917/1428  918/1428  919/1428  920/1428  921/1428  922/1428  923/1428  924/1428  925/1428  926/1428  927/1428  928/1428  929/1428  930/1428  931/1428  932/1428  933/1428  934/1428  935/1428  936/1428  937/1428  938/1428  939/1428  940/1428  941/1428  942/1428  943/1428  944/1428  945/1428  946/1428  947/1428  948/1428  949/1428  950/1428  951/1428  952/1428  953/1428  954/1428  955/1428  956/1428  957/1428  958/1428  959/1428  960/1428  961/1428  962/1428  963/1428  964/1428  965/1428  966/1428  967/1428  968/1428  969/1428  970/1428  971/1428  972/1428  973/1428  974/1428  975/1428  976/1428  977/1428  978/1428  979/1428  980/1428  981/1428  982/1428  983/1428  984/1428  985/1428  986/1428  987/1428  988/1428  989/1428  990/1428  991/1428  992/1428  993/1428  994/1428  995/1428  996/1428  997/1428  998/1428  999/1428  1000/1428  1001/1428  1002/1428  1003/1428  1004/1428  1005/1428  1006/1428  1007/1428  1008/1428  1009/1428  1010/1428  1011/1428  1012/1428  1013/1428  1014/1428  1015/1428  1016/1428  1017/1428  1018/1428  1019/1428  1020/1428  1021/1428  1022/1428  1023/1428  1024/1428  1025/1428  1026/1428  1027/1428  1028/1428  1029/1428  1030/1428  1031/1428  1032/1428  1033/1428  1034/1428  1035/1428  1036/1428  1037/1428  1038/1428  1039/1428  1040/1428  1041/1428  1042/1428  1043/1428  1044/1428  1045/1428  1046/1428  1047/1428  1048/1428  1049/1428  1050/1428  1051/1428  1052/1428  1053/1428  1054/1428  1055/1428  1056/1428  1057/1428  1058/1428  1059/1428  1060/1428  1061/1428  1062/1428  1063/1428  1064/1428  1065/1428  1066/1428  1067/1428  1068/1428  1069/1428  1070/1428  1071/1428  1072/1428  1073/1428  1074/1428  1075/1428  1076/1428  1077/1428  1078/1428  1079/1428  1080/1428  1081/1428  1082/1428  1083/1428  1084/1428  1085/1428  1086/1428  1087/1428  1088/1428  1089/1428  1090/1428  1091/1428  1092/1428  1093/1428  1094/1428  1095/1428  1096/1428  1097/1428  1098/1428  1099/1428  1100/1428  1101/1428  1102/1428  1103/1428  1104/1428  1105/1428  1106/1428  1107/1428  1108/1428  1109/1428  1110/1428  1111/1428  1112/1428  1113/1428  1114/1428  1115/1428  1116/1428  1117/1428  1118/1428  1119/1428  1120/1428  1121/1428  1122/1428  1123/1428  1124/1428  1125/1428  1126/1428  1127/1428  1128/1428  1129/1428  1130/1428  1131/1428  1132/1428  1133/1428  1134/1428  1135/1428  1136/1428  1137/1428  1138/1428  1139/1428  1140/1428  1141/1428  1142/1428  1143/1428  1144/1428  1145/1428  1146/1428  1147/1428  1148/1428  1149/1428  1150/1428  1151/1428  1152/1428  1153/1428  1154/1428  1155/1428  1156/1428  1157/1428  1158/1428  1159/1428  1160/1428  1161/1428  1162/1428  1163/1428  1164/1428  1165/1428  1166/1428  1167/1428  1168/1428  1169/1428  1170/1428  1171/1428  1172/1428  1173/1428  1174/1428  1175/1428  1176/1428  1177/1428  1178/1428  1179/1428  1180/1428  1181/1428  1182/1428  1183/1428  1184/1428  1185/1428  1186/1428  1187/1428  1188/1428  1189/1428  1190/1428  1191/1428  1192/1428  1193/1428  1194/1428  1195/1428  1196/1428  1197/1428  1198/1428  1199/1428  1200/1428  1201/1428  1202/1428  1203/1428  1204/1428  1205/1428  1206/1428  1207/1428  1208/1428  1209/1428  1210/1428  1211/1428  1212/1428  1213/1428  1214/1428  1215/1428  1216/1428  1217/1428  1218/1428  1219/1428  1220/1428  1221/1428  1222/1428  1223/1428  1224/1428  1225/1428  1226/1428  1227/1428  1228/1428  1229/1428  1230/1428  1231/1428  1232/1428  1233/1428  1234/1428  1235/1428  1236/1428  1237/1428  1238/1428  1239/1428  1240/1428  1241/1428  1242/1428  1243/1428  1244/1428  1245/1428  1246/1428  1247/1428  1248/1428  1249/1428  1250/1428  1251/1428  1252/1428  1253/1428  1254/1428  1255/1428  1256/1428  1257/1428  1258/1428  1259/1428  1260/1428  1261/1428  1262/1428  1263/1428  1264/1428  1265/1428  1266/1428  1267/1428  1268/1428  1269/1428  1270/1428  1271/1428  1272/1428  1273/1428  1274/1428  1275/1428  1276/1428  1277/1428  1278/1428  1279/1428  1280/1428  1281/1428  1282/1428  1283/1428  1284/1428  1285/1428  1286/1428  1287/1428  1288/1428  1289/1428  1290/1428  1291/1428  1292/1428  1293/1428  1294/1428  1295/1428  1296/1428  1297/1428  1298/1428  1299/1428  1300/1428  1301/1428  1302/1428  1303/1428  1304/1428  1305/1428  1306/1428  1307/1428  1308/1428  1309/1428  1310/1428  1311/1428  1312/1428  1313/1428  1314/1428  1315/1428  1316/1428  1317/1428  1318/1428  1319/1428  1320/1428  1321/1428  1322/1428  1323/1428  1324/1428  1325/1428  1326/1428  1327/1428  1328/1428  1329/1428  1330/1428  1331/1428  1332/1428  1333/1428  1334/1428  1335/1428  1336/1428  1337/1428  1338/1428  1339/1428  1340/1428  1341/1428  1342/1428  1343/1428  1344/1428  1345/1428  1346/1428  1347/1428  1348/1428  1349/1428  1350/1428  1351/1428  1352/1428  1353/1428  1354/1428  1355/1428  1356/1428  1357/1428  1358/1428  1359/1428  1360/1428  1361/1428  1362/1428  1363/1428  1364/1428  1365/1428  1366/1428  1367/1428  1368/1428  1369/1428  1370/1428  1371/1428  1372/1428  1373/1428  1374/1428  1375/1428  1376/1428  1377/1428  1378/1428  1379/1428  1380/1428  1381/1428  1382/1428  1383/1428  1384/1428  1385/1428  1386/1428  1387/1428  1388/1428  1389/1428  1390/1428  1391/1428  1392/1428  1393/1428  1394/1428  1395/1428  1396/1428  1397/1428  1398/1428  1399/1428  1400/1428  1401/1428  1402/1428  1403/1428  1404/1428  1405/1428  1406/1428  1407/1428  1408/1428  1409/1428  1410/1428  1411/1428  1412/1428  1413/1428  1414/1428  1415/1428  1416/1428  1417/1428  1418/1428  1419/1428  1420/1428  1421/1428  1422/1428  1423/1428  1424/1428  1425/1428  1426/1428  1427/1428  1428/1428  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clmns = [\n",
        "  \"Open 1\", \"Open 2\", \"Open 3\", \"Open 4\", \"Open 5\", \"Open 6\", \"Open 7\", \"Open 8\", \"Open 9\", \"Open 10\", \"Open 11\", \"Open 12\", \"Open 13\", \"Open 14\", \"Open 15\", \"Open 16\", \"Open 17\", \"Open 18\", \"Open 19\", \"Open 20\", \"Open 21\", \"Open 22\", \"Open 23\", \"Open 24\", \"Open 25\", \"Open 26\", \"Open 27\", \"Open 28\", \"Open 29\", \"Open 30\", \n",
        "  \"High 1\", \"High 2\", \"High 3\", \"High 4\", \"High 5\", \"High 6\", \"High 7\", \"High 8\", \"High 9\", \"High 10\", \"High 11\", \"High 12\", \"High 13\", \"High 14\", \"High 15\", \"High 16\", \"High 17\", \"High 18\", \"High 19\", \"High 20\", \"High 21\", \"High 22\", \"High 23\", \"High 24\", \"High 25\", \"High 26\", \"High 27\", \"High 28\", \"High 29\", \"High 30\",\n",
        "  \"Low 1\", \"Low 2\", \"Low 3\", \"Low 4\", \"Low 5\", \"Low 6\", \"Low 7\", \"Low 8\", \"Low 9\", \"Low 10\", \"Low 11\", \"Low 12\", \"Low 13\", \"Low 14\", \"Low 15\", \"Low 16\", \"Low 17\", \"Low 18\", \"Low 19\", \"Low 20\", \"Low 21\", \"Low 22\", \"Low 23\", \"Low 24\", \"Low 25\", \"Low 26\", \"Low 27\", \"Low 28\", \"Low 29\", \"Low 30\",\n",
        "  \"Close 1\", \"Close 2\", \"Close 3\", \"Close 4\", \"Close 5\", \"Close 6\", \"Close 7\", \"Close 8\", \"Close 9\", \"Close 10\", \"Close 11\", \"Close 12\", \"Close 13\", \"Close 14\", \"Close 15\", \"Close 16\", \"Close 17\", \"Close 18\", \"Close 19\", \"Close 20\", \"Close 21\", \"Close 22\", \"Close 23\", \"Close 24\", \"Close 25\", \"Close 26\", \"Close 27\", \"Close 28\", \"Close 29\", \"Close 30\",\n",
        "  \"suggestion\"]\n",
        "def work_with_dir():\n",
        "  if os.path.exists(\"/content/data/\"):\n",
        "    shutil.rmtree(\"/content/data/\", ignore_errors=True)\n",
        "    print(\"Data Folder Removed\")\n",
        "    os.mkdir(\"/content/data/\")\n",
        "\n",
        "  if not os.path.exists(\"/content/data/\"):\n",
        "    os.mkdir(\"/content/data/\")\n",
        "  \n",
        "  if not os.path.exists(\"/content/extracted/\"):\n",
        "    os.mkdir(\"/content/extracted/\")\n",
        "def read_txt_list():\n",
        "  with open(\"yahoo_stocklist.txt\",\"r\")as f:\n",
        "    lines = f.readlines()\n",
        "    nlines = []\n",
        "    for line in lines:\n",
        "       nlines.append(line.strip())\n",
        "    return nlines\n",
        "def read_syms_from_txt():\n",
        "  with open(\"syms.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  lst = []\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    lst.append(line)\n",
        "  symbols = lst\n",
        "  return symbols\n",
        "def get_crypto_syms():\n",
        "   # 'all_cryptocurrencies_au','all_cryptocurrencies_ca','all_cryptocurrencies_eu','all_cryptocurrencies_gb','all_cryptocurrencies_in',\n",
        "   screens = [\n",
        "       'all_cryptocurrencies_us', 'all_cryptocurrencies_au', 'all_cryptocurrencies_ca', 'all_cryptocurrencies_eu', 'all_cryptocurrencies_gb', 'all_cryptocurrencies_in', ]\n",
        "   s = Screener()\n",
        "   symbols = []\n",
        "   for i in screens:\n",
        "      data = s.get_screeners(i, count=250)\n",
        "      dicts = data[i]['quotes']\n",
        "      syms = [d['symbol'] for d in dicts]\n",
        "      for sym in syms:\n",
        "        symbols.append(sym)\n",
        "   # print(len(symbols))\n",
        "   # pieces = 15\n",
        "   # new_arrays = np.array_split(symbols, pieces)\n",
        "   return symbols\n",
        "def spliting(data):\n",
        "  X = data.drop([\"buy\",\"sell\"], axis=1)\n",
        "  y = data[[\"buy\",\"sell\"]]\n",
        "  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.1)\n",
        "  print(xTrain.shape, end=\" \")\n",
        "  print(yTrain.shape)\n",
        "  print(xTest.shape, end=\" \")\n",
        "  print(yTest.shape)\n",
        "  return xTrain, xTest, yTrain, yTest\n",
        "def scaler(row):\n",
        "    scaler = MinMaxScaler(feature_range=(-10,10))\n",
        "    row = scaler.fit_transform(row)\n",
        "    return row\n",
        "def process(data):\n",
        "    row = []\n",
        "    data.drop(\"symbol\",axis=1,inplace=True)\n",
        "    data.drop(\"datetime\",axis=1,inplace=True)\n",
        "    data = np.array(data)\n",
        "    for i in range(31, data.shape[0]-1):\n",
        "        grow = []\n",
        "        ggrow = []\n",
        "        gggrow = []\n",
        "        ggggrow = []\n",
        "        for x in range(1, 31):\n",
        "            grow.append([data[i-x][0] - data[i-(x-1)][0]] )\n",
        "            ggrow.append([data[i-x][1] - data[i-(x-1)][1]] )\n",
        "            gggrow.append([data[i-x][2] - data[i-(x-1)][2]] )\n",
        "            ggggrow.append([data[i-x][3] - data[i-(x-1)][3]] )\n",
        "\n",
        "        sugg = \"sell\"\n",
        "        if data[i+1][0] > data[i][0]:\n",
        "            sugg = \"buy\"\n",
        "        arr = np.array(grow).flatten()\n",
        "        arr2 = np.array(ggrow).flatten()\n",
        "        arr3 = np.array(gggrow).flatten()\n",
        "        arr4 = np.array(ggggrow).flatten()\n",
        "\n",
        "        arr = scaler(arr.reshape(-1, 1))\n",
        "        arr2 = scaler(arr2.reshape(-1, 1))\n",
        "        arr3 = scaler(arr3.reshape(-1, 1))\n",
        "        arr4 = scaler(arr4.reshape(-1, 1))\n",
        "\n",
        "        arr = np.concatenate((arr, arr2, arr3, arr4), axis=0).reshape(-1,1)\n",
        "        arr = np.append(arr, sugg)\n",
        "        row.append(arr)\n",
        "    grow = []\n",
        "    ggrow = []\n",
        "    gggrow = []\n",
        "    arr = []\n",
        "    return np.array(row)"
      ],
      "metadata": {
        "id": "Yc7-yg1RMYBQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def each_file_proc(files,now,index):\n",
        "     data = []\n",
        "     unattached_dfs = []\n",
        "     files = list(files)\n",
        "     for file in files:\n",
        "        print(f\"{files.index(file)+1+index}\",end=\" \")\n",
        "        if (files.index(file)+index+1) % 40 == 0:\n",
        "          print(\" \")\n",
        "        address = f\"/content/data/{file}\"\n",
        "        try:\n",
        "           unattached_dfs.append(process(pd.read_csv(address)))\n",
        "        except:\n",
        "          print(\" EP \")\n",
        "     if np.array(unattached_dfs[0]).shape[0] == 0:\n",
        "            print(\" Null \")\n",
        "            data = np.array(unattached_dfs[1])\n",
        "            for z in unattached_dfs[2:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     else:\n",
        "            data = np.array(unattached_dfs[0])\n",
        "            for z in unattached_dfs[1:]:\n",
        "               try: \n",
        "                  data = np.append(data, np.array(z), axis=0)\n",
        "               except:\n",
        "                  pass\n",
        "     unattached_dfs = []\n",
        "     data = pd.DataFrame(data, columns=clmns)\n",
        "     sugg = data[\"suggestion\"]\n",
        "     data.drop(\"suggestion\",axis=1,inplace=True)\n",
        "     sugg = pd.get_dummies(sugg)\n",
        "     data = pd.concat([data,sugg],axis=1)\n",
        "     data = data.astype(float)\n",
        "     right_now = datetime.now().strftime(\"%H%M%S%f\")\n",
        "     data.to_csv(f\"/content/extracted/{now}/{right_now}.csv\")  \n",
        "def extract_data(pieces):\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  print(f\"Files In Data : {len(os.listdir('/content/data/'))}\")\n",
        "  files = os.listdir(\"/content/data/\")\n",
        "  new_files = np.array_split(files, pieces)\n",
        "  print(\"Processing File:\")\n",
        "  now = datetime.now().strftime(\"%H%M%S\")\n",
        "  os.mkdir(f\"/content/extracted/{now}/\")\n",
        "  \n",
        "  index = 0 \n",
        "  for files in new_files:\n",
        "     \n",
        "     each_file_proc(files,now,index)\n",
        "     index = index + len(files)\n",
        "  print(\" \")\n",
        "  return now\n",
        "def delete_all_csv(now):\n",
        "   path = f'/content/extracted/{now}/*.csv'\n",
        "   files = glob.glob(path)\n",
        "   for file in files:\n",
        "       os.remove(file)\n",
        "def make_df(now):\n",
        "   path = f'/content/extracted/{now}/*.parquet'\n",
        "   files = glob.glob(path)\n",
        "   #data = pd.DataFrame()\n",
        "   data = pd.DataFrame()\n",
        "   for adr in files:\n",
        "     data =pd.concat([data,pd.read_parquet(adr)])\n",
        "   if \"Unnamed: 0\" in data:\n",
        "     data.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "   print(data.shape)\n",
        "   xTrain,xTest,yTrain,yTest = spliting(data)\n",
        "   data.to_parquet(f'/content/extracted/{now}/data.parquet')\n",
        "   delete_all_csv(now)\n",
        "   data = []\n",
        "   return xTrain,xTest,yTrain,yTest\n",
        "def to_par(now,howmanyfiles): \n",
        "    files = os.listdir(f\"/content/extracted/{now}/\")\n",
        "    addresses = []\n",
        "    for file in files:\n",
        "      addresses.append(f\"/content/extracted/{now}/{file}\")\n",
        "    new_adr = np.array_split(addresses,howmanyfiles)\n",
        "    for adrs in new_adr:\n",
        "      datas = []\n",
        "      for adr in adrs:\n",
        "        datas.append(pd.read_csv(adr))\n",
        "      rnow = datetime.now().strftime(\"%H%M%S%f\")\n",
        "      datas = pd.concat(datas)\n",
        "      datas.to_parquet(f\"/content/extracted/{now}/part_{rnow}.parquet\")      "
      ],
      "metadata": {
        "id": "RwcfzqyPMq27"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = extract_data(100)\n",
        "to_par(folder_name,10)\n",
        "xTrain,xTest,yTrain,yTest = make_df(folder_name)"
      ],
      "metadata": {
        "id": "nacRKx3ZMy2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc18652-f5db-4228-da3d-273f924aff61"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files In Data : 910\n",
            "Processing File:\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  \n",
            "41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  \n",
            "81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  \n",
            "121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160  \n",
            "161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200  \n",
            "201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240  \n",
            "241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280  \n",
            "281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320  \n",
            "321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360  \n",
            "361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400  \n",
            "401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440  \n",
            "441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480  \n",
            "481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520  \n",
            "521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560  \n",
            "561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600  \n",
            "601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640  \n",
            "641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680  \n",
            "681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720  \n",
            "721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760  \n",
            "761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800  \n",
            "801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840  \n",
            "841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880  \n",
            "881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910  \n",
            "(90982, 122)\n",
            "(81883, 120) (81883, 2)\n",
            "(9099, 120) (9099, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(1024, activation='relu', input_shape=(xTrain.shape[1],)))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "G5asREmlN2U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99ca929-f7c7-4346-aafd-9f48fb5d3c3d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 1024)              123904    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,274,754\n",
            "Trainable params: 3,274,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xTrain,yTrain,epochs=33,batch_size=32,validation_data=(xTest,yTest))"
      ],
      "metadata": {
        "id": "pjwc42r1N5yA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6deb765a-efd5-4401-ef2f-42fe923221cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/33\n",
            "2559/2559 [==============================] - 148s 58ms/step - loss: 0.2329 - accuracy: 0.8965 - val_loss: 0.1821 - val_accuracy: 0.9231\n",
            "Epoch 2/33\n",
            "2559/2559 [==============================] - 147s 58ms/step - loss: 0.1585 - accuracy: 0.9326 - val_loss: 0.1564 - val_accuracy: 0.9372\n",
            "Epoch 3/33\n",
            "2559/2559 [==============================] - 149s 58ms/step - loss: 0.1364 - accuracy: 0.9431 - val_loss: 0.1558 - val_accuracy: 0.9352\n",
            "Epoch 4/33\n",
            "2559/2559 [==============================] - 146s 57ms/step - loss: 0.1178 - accuracy: 0.9505 - val_loss: 0.1594 - val_accuracy: 0.9354\n",
            "Epoch 5/33\n",
            "2559/2559 [==============================] - 145s 57ms/step - loss: 0.0980 - accuracy: 0.9589 - val_loss: 0.1600 - val_accuracy: 0.9405\n",
            "Epoch 6/33\n",
            "2559/2559 [==============================] - 142s 55ms/step - loss: 0.0803 - accuracy: 0.9670 - val_loss: 0.1695 - val_accuracy: 0.9411\n",
            "Epoch 7/33\n",
            "2559/2559 [==============================] - 145s 57ms/step - loss: 0.0626 - accuracy: 0.9745 - val_loss: 0.1676 - val_accuracy: 0.9368\n",
            "Epoch 8/33\n",
            "2559/2559 [==============================] - 144s 56ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 0.2003 - val_accuracy: 0.9425\n",
            "Epoch 9/33\n",
            "2559/2559 [==============================] - 144s 56ms/step - loss: 0.0426 - accuracy: 0.9835 - val_loss: 0.2154 - val_accuracy: 0.9455\n",
            "Epoch 10/33\n",
            "2559/2559 [==============================] - 150s 58ms/step - loss: 0.0354 - accuracy: 0.9866 - val_loss: 0.2604 - val_accuracy: 0.9418\n",
            "Epoch 11/33\n",
            "2559/2559 [==============================] - 148s 58ms/step - loss: 0.0319 - accuracy: 0.9877 - val_loss: 0.2356 - val_accuracy: 0.9422\n",
            "Epoch 12/33\n",
            "2559/2559 [==============================] - 153s 60ms/step - loss: 0.0271 - accuracy: 0.9898 - val_loss: 0.2856 - val_accuracy: 0.9407\n",
            "Epoch 13/33\n",
            "2559/2559 [==============================] - 150s 58ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.2690 - val_accuracy: 0.9390\n",
            "Epoch 14/33\n",
            "2559/2559 [==============================] - 148s 58ms/step - loss: 0.0228 - accuracy: 0.9914 - val_loss: 0.2863 - val_accuracy: 0.9452\n",
            "Epoch 15/33\n",
            "2559/2559 [==============================] - 149s 58ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.3131 - val_accuracy: 0.9393\n",
            "Epoch 16/33\n",
            "2559/2559 [==============================] - 145s 57ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.3233 - val_accuracy: 0.9433\n",
            "Epoch 17/33\n",
            "2559/2559 [==============================] - 143s 56ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.3472 - val_accuracy: 0.9411\n",
            "Epoch 18/33\n",
            "2559/2559 [==============================] - 144s 56ms/step - loss: 0.0175 - accuracy: 0.9935 - val_loss: 0.3418 - val_accuracy: 0.9383\n",
            "Epoch 19/33\n",
            "2559/2559 [==============================] - 145s 57ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.3691 - val_accuracy: 0.9420\n",
            "Epoch 20/33\n",
            "2559/2559 [==============================] - 151s 59ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.3294 - val_accuracy: 0.9427\n",
            "Epoch 21/33\n",
            "2559/2559 [==============================] - 153s 60ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.3816 - val_accuracy: 0.9423\n",
            "Epoch 22/33\n",
            "2559/2559 [==============================] - 152s 59ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.4184 - val_accuracy: 0.9385\n",
            "Epoch 23/33\n",
            "2559/2559 [==============================] - 151s 59ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.3115 - val_accuracy: 0.9448\n",
            "Epoch 24/33\n",
            "2559/2559 [==============================] - 152s 59ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.4166 - val_accuracy: 0.9430\n",
            "Epoch 25/33\n",
            "2559/2559 [==============================] - 156s 61ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.3955 - val_accuracy: 0.9431\n",
            "Epoch 26/33\n",
            "2559/2559 [==============================] - 147s 57ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.4476 - val_accuracy: 0.9436\n",
            "Epoch 27/33\n",
            "2559/2559 [==============================] - 149s 58ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.4858 - val_accuracy: 0.9390\n",
            "Epoch 28/33\n",
            "2559/2559 [==============================] - 147s 57ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.5240 - val_accuracy: 0.9418\n",
            "Epoch 29/33\n",
            "2559/2559 [==============================] - 144s 56ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.4022 - val_accuracy: 0.9399\n",
            "Epoch 30/33\n",
            "2559/2559 [==============================] - 146s 57ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.5093 - val_accuracy: 0.9414\n",
            "Epoch 31/33\n",
            " 588/2559 [=====>........................] - ETA: 1:50 - loss: 0.0106 - accuracy: 0.9967"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"TWOG122_8893.h5\")"
      ],
      "metadata": {
        "id": "f5bHaRPCKfI6"
      },
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "TWOG122.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}